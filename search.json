[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ovarian Cancer Histotypes: Report of Statistical Findings",
    "section": "",
    "text": "Preface\nThis report of statistical findings describes the classification of ovarian cancer histotypes using data from NanoString CodeSets.\nMarina Pavanello conducted the initial exploratory data analysis, Cathy Tang implemented class imbalance techniques, Derek Chiu conducted the normalization and statistical analysis, and Lauren Tindale and Aline Talhouk are the project leads.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "rsf/introduction.html",
    "href": "rsf/introduction.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Ovarian cancer has five major histotypes: high-grade serous carcinoma (HGSC), low-grade serous carcinoma (LGSC), endometrioid carcinoma (ENOC), mucinous carcinoma (MUC), and clear cell carcinoma (CCOC). A common problem with classifying these histotypes is that there is a class imbalance issue. HGSC dominates the distribution, commonly accounting for 70% of cases in many patient cohorts, while the other four histotypes are spread over the rest of the cases. Subsampling methods like up-sampling, down-sampling, and SMOTE can be used to mitigate this problem.\nThe supervised learning is performed under a consensus framework: we consider various classification algorithms and use evaluation metrics like accuracy, F1-score, and Kappa, to inform the decision of which methods to carry forward for prediction in confirmation and validation sets.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "rsf/methods.html",
    "href": "rsf/methods.html",
    "title": "2  Methods",
    "section": "",
    "text": "2.1 Pre-Processing",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "rsf/methods.html#pre-processing",
    "href": "rsf/methods.html#pre-processing",
    "title": "2  Methods",
    "section": "",
    "text": "2.1.1 Case Selection\nPrior to pre-processing, samples were split into a training, a confirmation, and a validation set.\n\nTraining\n\nCS1: MAYO, OOU, OOUE, VOA, MTL\nCS2: MAYO, OOU, OOUE, OVAR3, VOA, ICON7, JAPAN, MTL, POOL-CTRL\nCS3: OOU, OOUE, VOA, POOL-1, POOL-2, POOL-3\n\nConfirmation:\n\nCS3: TNCO\n\nValidation:\n\nCS3: DOVE4\n\n\n\n\n2.1.2 Quality Control\nBefore normalization, we calculated several quality control measures and excluded samples that failed to achieve sample quality in one or more of these measures.\n\nLinearity of positive control genes: If the R-squared from a linear model of positive controls and their concentrations is less than 0.95 or missing, then the sample is flagged.\nImaging quality: The sample is flagged if the field of view percentage is less than 75%.\nPositive Control flag: We consider the two smallest positive controls at concentrations 0.5 and 1. If these two controls are less than the lower limit of detection (defined as two standard deviations below the mean of the negative control expression), or if the mean negative control expression is 0, the sample is flagged.\nThe signal-to-noise ratio or percent of genes detected: These two measures are defined as the ratio of the average housekeeping gene expression over the upper limit of detection, defined as two standard deviations above the mean of the negative control expression (or 0 if this limit is less than 0.001), and the proportion of endogenous genes with expression greater than the upper limit of detection. These measures are flagged if they are below a pre-specified threshold, which is determined visually by considering their bivariate distribution in a scatterplot. In this case, we used 100 for the SNR threshold and 50% for the threshold for genes detected. Note: these thresholds were determined by examining the relationship in Section 3.3.2.\n\n\n\n2.1.3 Housekeeping Genes Normalization\nThe full training set (n=1243) comprised of data from three CodeSets (CS) 1, 2, and 3. Data normalization removes technical variation from high-throughput platforms to improve the validity of comparative analyses.\nEach CodeSet was first normalized to housekeeping genes: ACTB, RPL19, POLR1B, SDHA, and PGK1. Housekeeping genes encode proteins responsible for basic cell function and have consistent expression in all cells. All expression values were log2 transformed. Normalization to housekeeping genes corrects the viable RNA from each sample. This is achieved by subtracting the average log (base 2)-transformed expression of the housekeeping genes from the log (base 2)-transformed expression of each gene:\n\\[\nlog_2(\\text{endogenous gene expression}) - \\text{average(}log_2(\\text{housekeeping gene expresssion})) = \\text{relative expression}\n\\tag{2.1}\\]\n\n\n2.1.4 Between CodeSet and Site Normalization\nTo normalize between CodeSets, we randomly selected five specimens, one from each histotype, among specimens repeated in all three CodeSets. This formed the reference set (Random 1). We selected only one sample from each histotype to use as few samples as possible for normalization and retain the rest for analysis.\nA reference-based approach (Talhouk et al. (2016)) was used to normalize CS1 to CS3 and CS2 to CS3 across their common genes:\n\\[\n\\text{X-Norm}_{\\text{CS1}} = X_{\\text{CS1}} + {\\bar{R}_{\\text{CS3}}} - {\\bar{R}_{\\text{CS1}}} \\\\\n\\text{X-Norm}_{\\text{CS2}} = X_{\\text{CS2}} + {\\bar{R}_{\\text{CS3}}} - {\\bar{R}_{\\text{CS2}}}\n\\tag{2.2}\\]\nSamples in CS3 were processed at three different locations; we also had to normalize for “site” in this CodeSet. Finally, the CS3 expression samples were included in the training set without further normalization:\n\\[\n\\text{X-Norm}_{\\text{CS3-USC}} = X_{\\text{CS3-USC}} + {\\bar{R}_{\\text{CS3-VAN}}} - {\\bar{R}_{\\text{CS3-USC}}} \\\\\n\\text{X-Norm}_{\\text{CS3-AOC}} = X_{\\text{CS3-AOC}} + {\\bar{R}_{\\text{CS3-VAN}}} - {\\bar{R}_{\\text{CS3-AOC}}}\n\\tag{2.3}\\]\nFinally, the CS3 expression samples were included in the training set without further normalization. The initial training set is assembled by combining all four of the previously mentioned normalized datasets along with the two CS3 expression subsets not used in normalization:\n\\[\n\\begin{aligned}\n\\text{Training Set} &= \\text{X-Norm}_{\\text{CS1}} + \\text{X-Norm}_{\\text{CS2}} + \\text{X-Norm}_{\\text{CS3-USC}} + \\text{X-Norm}_{\\text{CS3-AOC}} + \\text{X-Norm}_{\\text{CS3}} + \\text{X-Norm}_{\\text{CS3-VAN}} \\\\\n                        &= \\text{X-Norm}_{\\text{CS1}} + \\text{X-Norm}_{\\text{CS2}} + \\text{X-Norm}_{\\text{CS3}}\n\\end{aligned}\n\\tag{2.4}\\]\n\n\n\n\n\n\n\n\nFigure 2.1: Venn diagram of common and unique gene targets covered by each CodeSet\n\n\n\n\n\n\n\n2.1.5 Final Processing\nWe map ovarian histotypes to all remaining samples and keep the major histotypes for building the predictive model: high-grade serous carcinoma (HGSC), clear cell ovarian carcinoma (CCOC), endometrioid ovarian carcinoma (ENOC), low-grade serous carcinoma (LGSC), mucinous carcinoma (MUC).\nDuplicate cases (two samples with the same ottaID) were removed before generating the final training set to use for fitting the classification models. All CS3 cases were preferred over CS1 and CS2, and CS3-Vancouver cases were preferred over CS3-AOC and CS3-USC when selecting duplicates.\nThe final training set used only genes that were common across all three CodeSets.\n\n\n\n\n\n\n\n\nFigure 2.2: Cohorts Selection",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "rsf/methods.html#classifiers",
    "href": "rsf/methods.html#classifiers",
    "title": "2  Methods",
    "section": "2.2 Classifiers",
    "text": "2.2 Classifiers\nWe use 4 classification algorithms in the supervised learning framework for the Training Set. The pipeline was run using SLURM batch jobs submitted to a partition on a CentOS 7 server. All resampling techniques, pre-processing, model specification, hyperparameter tuning, and evaluation metrics were implemented using the tidymodels suite of packages. The classifiers we used are:\n\nRandom Forest (rf)\nSupport Vector Machine (svm)\nXGBoost (xgb)\nRegularized Multinomial Regression (mr)\n\n\n2.2.1 Resampling of Training Set\nWe used a nested cross-validation design to assess each classifier while also performing hyperparameter tuning. An outer 5-fold CV stratified by histotype was used together with an inner 5-fold CV with 2 repeats stratified by histotype. This design was chosen such that the test sets of the inner resamples would still have a reasonable number of samples belonging to the smallest minority class.\nThe outer resampling method cannot be the bootstrap, because the inner training and inner test sets will likely contain the same samples as a result of sampling with replacement in the outer training set. This phenomenon might result in inflated performance as some observations are used both to train and evaluate the hyperparameter tuning in the inner loop.\n\n\n2.2.2 Hyperparameter Tuning\nThe following specifications for each classifier were used for tuning hyperparameters:\n\nrf and xgb: The number of trees were fixed at 500. Other hyperparameters were tuned across 10 randomly selected points in a latin hypercube design.\nsvm: Both the cost and sigma hyperparameters were tuned across 10 randomly selected points in a latin hypercube design. We tuned the cost parameter in the range [1, 8]. The range for tuning the sigma parameter was obtained from the 10% and 90% quantiles of the estimation using the kernlab::sigest() function.\nmr: We generated 10 randomly selected points in a latin hypercube design for the penalty (lambda) parameter. Then, we generated 10 evenly spaced points in [0, 1] for the mixture (alpha) parameter in the regularized multinomial regression model. These two sets of 10 points were crossed to generate a tuning grid of 100 points.\n\nThe hyperparameter combination that resulted in the highest average F1-score across the inner training sets was selected for each classifier to use as the model for assessing prediction performance in the outer training loop.\n\n\n2.2.3 Subsampling\nHere are the specifications of the subsampling methods used to handle class imbalance:\n\nNone: No subsampling is performed\nDown-sampling: All levels except the minority class are sampled down to the same frequency as the minority class\nUp-sampling: All levels except the majority class are sampled up to the same frequency as the majority class\nSMOTE: All levels except the majority class have synthetic data generated until they have the same frequency as the majority class\nHybrid: All levels except the majority class have synthetic data generated up to 50% of the frequency of the majority class, then the majority class is sampled down to the same frequency as the rest.\n\nThe figure below helps visualize how the distribution of classes changes when we apply subsampling techniques to handle class imbalance:\n\n\n\n\n\n\n\n\nFigure 2.3: Visualization of Subsampling Techniques\n\n\n\n\n\n\n\n2.2.4 Workflows\nThe 4 algorithms and 5 subsampling methods are crossed to create 20 different classification workflows. For example, the hybrid_xgb workflow is a classifier that first pre-processes a training set by applying a hybrid subsampling method, and then proceeds to use the XGBoost algorithm to classify ovarian histotypes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "rsf/methods.html#two-step-algorithm",
    "href": "rsf/methods.html#two-step-algorithm",
    "title": "2  Methods",
    "section": "2.3 Two-Step Algorithm",
    "text": "2.3 Two-Step Algorithm\nThe HGSC histotype comprises of approximately 80% of cases among ovarian carcinoma patients, while the remaining 20% of cases are relatively, evenly distributed among ENOC, CCOC, LGSC, and MUC histotypes. We can implement a two-step algorithm as such:\n\nStep 1: use binary classification for HGSC vs. non-HGSC\nStep 2: use multinomial classification for the remaining non-HGSC classes\n\nLet\n\\[\n\\begin{aligned}\n& X_k = \\text{Training data with k classes}  \\\\\n& C_k = \\text{Class with highest}\\;F_1\\;\\text{score from training}\\;X_k \\\\\n& W_k = \\text{Workflow associated with}\\;C_k\n\\end{aligned}\n\\tag{2.5}\\]\nFigure 2.4 shows how the two-step algorithm works:\n\n\n\n\n\n\n\n\nFigure 2.4: Two-Step Algorithm\n\n\n\n\n\n2.3.1 Aggregating Predictions\nThe aggregation for two-step predictions is quite straightforward:\n\nPredict HGSC vs. non-HGSC\nAmong all non-HGSC cases, predict CCOC vs. LGSC vs. MUC vs. ENOC\n\n\n\n\n\n\n\n\n\nFigure 2.5: Aggregating Predictions for Two-Step Algorithm",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "rsf/methods.html#sequential-algorithm",
    "href": "rsf/methods.html#sequential-algorithm",
    "title": "2  Methods",
    "section": "2.4 Sequential Algorithm",
    "text": "2.4 Sequential Algorithm\nInstead of training on k classes simultaneously using multinomial classifiers, we can use a sequential algorithm that performs k-1 one-vs-all binary classifications iteratively to obtain a final prediction of all cases. At each step in the sequence, we classify one class vs. all other classes, where the classes that make up the “other” class are those not equal to the current “one” class and excluding all “one” classes from previous steps. For example, if the “one” class in step 1 was HGSC, the “other” classes would include CCOC, ENOC, LGSC, and MUC. If the “one” class in step 2 was CCOC, the “other” classes include ENOC, LGSC, and MUC.\nThe order of classes and workflows to use at each step in the sequential algorithm must be determined using a retraining procedure. After removing the data associated with a particular class, we retrain using the remaining data using multinomial classifiers as described before. The class and workflow to use for the next step in the sequence is selected based on the best per-class evaluation metric value (e.g. F1-score).\nFigure 2.6 illustrates how the sequential algorithm works for K=5, using ovarian histotypes as an example for the classes.\n\n\n\n\n\n\n\n\nFigure 2.6: Sequential Algorithm\n\n\n\n\nThe subsampling method used in the first step of the sequential algorithm is used in all subsequent steps in order to maintain data pre-processing consistency. As a result, we are only comparing classification algorithms within one subsampling method across the entire sequential algorithm.\n\n2.4.1 Aggregating Predictions\nWe have to aggregate the one-vs-all predictions from each of the sequential algorithm workflows in order to obtain a final class prediction on a holdout test set. Each sequential workflow has to be assessed on every sample to ensure that cases classified into the “all” class from a previous step of the sequence are eventually assigned a predicted class. For example, say that based on certain class-specific metrics we determined that the order of classes in the sequential algorithm was to predict HGSC vs. non-HGSC, CCOC vs. non-CCOC, LGSC vs. non-LGSC, and then MUC vs. ENOC. Figure 2.7 illustrates how the final predictions are assigned:\n\n\n\n\n\n\n\n\nFigure 2.7: Aggregating Predictions for Sequential Algorithm",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "rsf/methods.html#performance-evaluation",
    "href": "rsf/methods.html#performance-evaluation",
    "title": "2  Methods",
    "section": "2.5 Performance Evaluation",
    "text": "2.5 Performance Evaluation\n\n2.5.1 Class Metrics\nWe use the accuracy, sensitivity, specificity, F1-score, kappa, balanced accuracy, and geometric mean, as class metrics to measure both training and test performance between different workflows. Multiclass extensions of these metrics can be calculated except for F1-score, where we use macro-averaging to obtain an overall metric. Class-specific metrics are calculated by recoding classes into one-vs-all categories for each class.\n\n2.5.1.1 Accuracy\nThe accuracy is defined as the proportion of correct predictions out of all cases:\n\\[\n\\text{accuracy} = \\frac{TP}{TP + FP + FN + TN}\n\\tag{2.6}\\]\n\n\n2.5.1.2 Sensitivity\nSensitivity is the proportional of correctly predicted positive cases, out of all cases that were truly positive\n\\[\n\\text{sensitivity} = \\frac{TP}{TP + FN}\n\\tag{2.7}\\]\n\n\n2.5.1.3 Specificity\nSpecificity is the proportional of correctly predicted negative cases, out of all cases that were truly negative.\n\\[\n\\text{specificity} = \\frac{TN}{TN + FP}\n\\tag{2.8}\\]\n\n\n2.5.1.4 F1-Score\nThe F-measure can be thought of as a harmonic mean between precision and recall:\n\\[\nF_{meas} = \\frac{(1 + \\beta^2) \\times precision \\times recall}{(\\beta^2 \\times precision) + recall}\n\\tag{2.9}\\]\nThe \\(\\beta\\) value can be adjusted to place more weight upon precision or recall. The most common value is \\(\\beta\\) is 1, which is also commonly known as the F1-score. A multiclass extension doesn’t exist for the F1-score, so we use macro-averaging to calculate this metric when there are more than two classes. For example, with \\(k\\) classes, the macro-averaged F1-score is equal to:\n\\[\n{F_1}_{macro} = \\frac{1}{k} \\sum_{i=1}^{k}{F_1}_{i}\n\\tag{2.10}\\]\nwhere each \\({F_1}_{i}\\) is the F1-score computed frrom recoding classes into \\(k=i\\) vs. \\(k \\neq i\\).\nIn situations where there is not at least one predicted case for each of the classes (e.g. for a poor classifier), \\({F_1}_{i}\\) is undefined because the per-class precision of class \\(i\\) is undefined. Those \\({F_1}_{i}\\) terms are removed from the \\({F_1}_{macro}\\) equation and the resulting value may be inflated. Interpreting the F1-score in such a case would be misleading.\n\n\n2.5.1.5 Balanced Accuracy\nBalanced accuracy is the arithmetic mean of sensitivity and specificity.\n\\[\n\\text{Balanced Accuracy} = \\frac{\\text{Sensitivity} + \\text{Specificity}}{2}\n\\tag{2.11}\\]\n\n\n2.5.1.6 Kappa\nKappa is the defined as:\n\\[\n\\text{kappa} = \\frac{p_0 - p_e}{1 - p_e}\n\\tag{2.12}\\]\nwhere \\(p_0\\) is the observed agreement among raters and \\(p_e\\) is the hypothetical probability of agreement due to random chance.\n\n\n\n2.5.2 AUC\nThe area under the receiver operating curve (AUC) is calculated by adding up the area under the curve formed by plotting sensitivity vs. 1 - specificity. The Hand-till method is used as a multiclass extension for the AUC.\nWe did not use AUC to measure class-specific training set performance because combining predicted probabilities in a one-vs-all fashion might be potentially misleading. The sum of probabilities that add up to the “other” class is not equivalent to the predicted probability of the “other” class when using a multiclass classifier.\nInstead, we only reported ROC curves and their associated AUCs for test set performance among the highest ranked algorithms.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "rsf/methods.html#rank-aggregation",
    "href": "rsf/methods.html#rank-aggregation",
    "title": "2  Methods",
    "section": "2.6 Rank Aggregation",
    "text": "2.6 Rank Aggregation\nTo select the best algorithm, we implemented a two-stage rank aggregation procedure using the Genetic Algorithm. First, we ranked all workflows based on per-class F1-scores, balanced accuracy, and kappa to see which workflows performed well in predicting all five histotypes. Then, we took the ranks from these three performance metrics and performed a second run of rank aggregation. The top 5 workflows were determined from the final rank aggregation result.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "rsf/methods.html#gene-optimization",
    "href": "rsf/methods.html#gene-optimization",
    "title": "2  Methods",
    "section": "2.7 Gene Optimization",
    "text": "2.7 Gene Optimization\nWe want to discover an optimal set of genes for the classifiers while including specific genes from other studies such as PrOTYPE and SPOT. A total of 72 genes are used in the classifier training set.\nThere are 16 genes in the classifier set that overlap with the PrOTYPE classifier: COL11A1, CD74, CD2, TIMP3, LUM, CYTIP, COL3A1, THBS2, TCF7L1, HMGA2, FN1, POSTN, COL1A2, COL5A2, PDZK1IP1, FBN1.\nThere are also 13 genes in the classifier set that overlap with the SPOT signature: HIF1A, CXCL10, DUSP4, SOX17, MITF, CDKN3, BRCA2, CEACAM5, ANXA4, SERPINE1, TCF7L1, CRABP2, DNAJC9.\nWe obtain a total of 28 genes from the union of PrOTYPE and SPOT genes that we want to include in the final classifier, regardless of model performance. We then incrementally add genes one at a time from the remaining 44 candidate genes based on a variable importance rank to the set of 28 base genes and recalculate performance metrics. The number of genes at which the performance peaks or starts to plateau may indicate an optimal gene set model for us to compare with the full set model.\nHere is the breakdown of genes used and whether they belong to the PrOTYPE and/or SPOT sets:\n\n\n\n\nTable 2.1: Gene Distribution\n\n\n\n\n \n  \n    Genes \n    PrOTYPE \n    SPOT \n  \n \n\n  \n    TCF7L1 \n    ✔ \n    ✔ \n  \n  \n    COL11A1 \n    ✔ \n     \n  \n  \n    CD74 \n    ✔ \n     \n  \n  \n    CD2 \n    ✔ \n     \n  \n  \n    TIMP3 \n    ✔ \n     \n  \n  \n    LUM \n    ✔ \n     \n  \n  \n    CYTIP \n    ✔ \n     \n  \n  \n    COL3A1 \n    ✔ \n     \n  \n  \n    THBS2 \n    ✔ \n     \n  \n  \n    HMGA2 \n    ✔ \n     \n  \n  \n    FN1 \n    ✔ \n     \n  \n  \n    POSTN \n    ✔ \n     \n  \n  \n    COL1A2 \n    ✔ \n     \n  \n  \n    COL5A2 \n    ✔ \n     \n  \n  \n    PDZK1IP1 \n    ✔ \n     \n  \n  \n    FBN1 \n    ✔ \n     \n  \n  \n    HIF1A \n     \n    ✔ \n  \n  \n    CXCL10 \n     \n    ✔ \n  \n  \n    DUSP4 \n     \n    ✔ \n  \n  \n    SOX17 \n     \n    ✔ \n  \n  \n    MITF \n     \n    ✔ \n  \n  \n    CDKN3 \n     \n    ✔ \n  \n  \n    BRCA2 \n     \n    ✔ \n  \n  \n    CEACAM5 \n     \n    ✔ \n  \n  \n    ANXA4 \n     \n    ✔ \n  \n  \n    SERPINE1 \n     \n    ✔ \n  \n  \n    CRABP2 \n     \n    ✔ \n  \n  \n    DNAJC9 \n     \n    ✔ \n  \n  \n    C10orf116 \n     \n     \n  \n  \n    GAD1 \n     \n     \n  \n  \n    TPX2 \n     \n     \n  \n  \n    KGFLP2 \n     \n     \n  \n  \n    EGFL6 \n     \n     \n  \n  \n    KLK7 \n     \n     \n  \n  \n    PBX1 \n     \n     \n  \n  \n    LIN28B \n     \n     \n  \n  \n    TFF3 \n     \n     \n  \n  \n    MUC5B \n     \n     \n  \n  \n    FUT3 \n     \n     \n  \n  \n    STC1 \n     \n     \n  \n  \n    BCL2 \n     \n     \n  \n  \n    PAX8 \n     \n     \n  \n  \n    GCNT3 \n     \n     \n  \n  \n    GPR64 \n     \n     \n  \n  \n    ADCYAP1R1 \n     \n     \n  \n  \n    IGKC \n     \n     \n  \n  \n    BRCA1 \n     \n     \n  \n  \n    IGJ \n     \n     \n  \n  \n    TFF1 \n     \n     \n  \n  \n    MET \n     \n     \n  \n  \n    CYP2C18 \n     \n     \n  \n  \n    CYP4B1 \n     \n     \n  \n  \n    SLC3A1 \n     \n     \n  \n  \n    EPAS1 \n     \n     \n  \n  \n    HNF1B \n     \n     \n  \n  \n    IL6 \n     \n     \n  \n  \n    ATP5G3 \n     \n     \n  \n  \n    DKK4 \n     \n     \n  \n  \n    SENP8 \n     \n     \n  \n  \n    CAPN2 \n     \n     \n  \n  \n    C1orf173 \n     \n     \n  \n  \n    CPNE8 \n     \n     \n  \n  \n    IGFBP1 \n     \n     \n  \n  \n    WT1 \n     \n     \n  \n  \n    TP53 \n     \n     \n  \n  \n    SEMA6A \n     \n     \n  \n  \n    SERPINA5 \n     \n     \n  \n  \n    ZBED1 \n     \n     \n  \n  \n    TSPAN8 \n     \n     \n  \n  \n    SCGB1D2 \n     \n     \n  \n  \n    LGALS4 \n     \n     \n  \n  \n    MAP1LC3A \n     \n     \n  \n\n\n\n\n\n\n\n\n\n2.7.1 Variable Importance\nVariable importance is calculated using either a model-based approach if it is available, or a permutation-based VI score otherwise. The variable importance scores are averaged across the outer training folds, and then ranked from highest to lowest.\nFor the sequential and two-step classifiers, we calculate an overall VI rank by taking the cumulative union of genes at each variable importance rank across all sequences, until all genes have been included.\nThe variable importance measures are:\n\nRandom Forest: impurity measure (Gini index)\nXGBoost: gain (fractional contribution of each feature to the model based on the total gain of the corresponding features’s splits)\nSVM: permutation based p-values\nMultinomial regression: absolute value of estimated coefficients at cross-validated lambda value\n\n\n\n\n\nTalhouk, Aline, Stefan Kommoss, Robertson Mackenzie, Martin Cheung, Samuel Leung, Derek S. Chiu, Steve E. Kalloger, et al. 2016. “Single-Patient Molecular Testing with NanoString nCounter Data Using a Reference-Based Strategy for Batch Effect Correction.” Edited by Benjamin Haibe-Kains. PLOS ONE 11 (4): e0153844. https://doi.org/10.1371/journal.pone.0153844.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Methods</span>"
    ]
  },
  {
    "objectID": "rsf/distributions.html",
    "href": "rsf/distributions.html",
    "title": "3  Distributions",
    "section": "",
    "text": "3.1 Histotype Distribution\nTable 3.1: Histotype Distribution in Training Set by Processing Stage\n\n\n\n\n \n  \n    Variable \n    Levels \n    CS1 \n    CS2 \n    CS3 \n    Total \n  \n \n\n  Selected Cohorts\n\n    Histotype \n    HGSC \n    126 (43%) \n    655 (73%) \n    1779 (72%) \n    2560 (70%) \n  \n  \n   \n    CCOC \n    48 (16%) \n    61 (7%) \n    181 (7%) \n    290 (8%) \n  \n  \n   \n    ENOC \n    60 (20%) \n    34 (4%) \n    268 (11%) \n    362 (10%) \n  \n  \n   \n    MUC \n    20 (7%) \n    62 (7%) \n    77 (3%) \n    159 (4%) \n  \n  \n   \n    LGSC \n    21 (7%) \n    21 (2%) \n    42 (2%) \n    84 (2%) \n  \n  \n   \n    Other \n    19 (6%) \n    70 (8%) \n    130 (5%) \n    219 (6%) \n  \n  \n    Total \n    N (%) \n    294 (8%) \n    903 (25%) \n    2477 (67%) \n    3674 (100%) \n  \n  QC\n\n    Histotype \n    HGSC \n    120 (42%) \n    641 (73%) \n    1636 (72%) \n    2397 (70%) \n  \n  \n   \n    CCOC \n    48 (17%) \n    61 (7%) \n    173 (8%) \n    282 (8%) \n  \n  \n   \n    ENOC \n    60 (21%) \n    32 (4%) \n    229 (10%) \n    321 (9%) \n  \n  \n   \n    MUC \n    19 (7%) \n    60 (7%) \n    69 (3%) \n    148 (4%) \n  \n  \n   \n    LGSC \n    20 (7%) \n    21 (2%) \n    40 (2%) \n    81 (2%) \n  \n  \n   \n    Other \n    19 (7%) \n    67 (8%) \n    126 (6%) \n    212 (6%) \n  \n  \n    Total \n    N (%) \n    286 (8%) \n    882 (26%) \n    2273 (66%) \n    3441 (100%) \n  \n  Main Histotypes\n\n    Histotype \n    HGSC \n    120 (45%) \n    641 (79%) \n    1636 (76%) \n    2397 (74%) \n  \n  \n   \n    CCOC \n    48 (18%) \n    61 (7%) \n    173 (8%) \n    282 (9%) \n  \n  \n   \n    ENOC \n    60 (22%) \n    32 (4%) \n    229 (11%) \n    321 (10%) \n  \n  \n   \n    MUC \n    19 (7%) \n    60 (7%) \n    69 (3%) \n    148 (5%) \n  \n  \n   \n    LGSC \n    20 (7%) \n    21 (3%) \n    40 (2%) \n    81 (3%) \n  \n  \n    Total \n    N (%) \n    267 (8%) \n    815 (25%) \n    2147 (66%) \n    3229 (100%) \n  \n  Removed Duplicates\n\n    Histotype \n    HGSC \n    117 (47%) \n    623 (79%) \n    1540 (77%) \n    2280 (75%) \n  \n  \n   \n    CCOC \n    45 (18%) \n    55 (7%) \n    159 (8%) \n    259 (9%) \n  \n  \n   \n    ENOC \n    56 (22%) \n    28 (4%) \n    216 (11%) \n    300 (10%) \n  \n  \n   \n    MUC \n    16 (6%) \n    58 (7%) \n    59 (3%) \n    133 (4%) \n  \n  \n   \n    LGSC \n    15 (6%) \n    20 (3%) \n    36 (2%) \n    71 (2%) \n  \n  \n    Total \n    N (%) \n    249 (8%) \n    784 (26%) \n    2010 (66%) \n    3043 (100%) \n  \n  Normalized and Recombined\n\n    Histotype \n    HGSC \n    116 (48%) \n    622 (80%) \n    451 (96%) \n    1189 (80%) \n  \n  \n   \n    CCOC \n    44 (18%) \n    54 (7%) \n    4 (1%) \n    102 (7%) \n  \n  \n   \n    ENOC \n    55 (23%) \n    27 (3%) \n    4 (1%) \n    86 (6%) \n  \n  \n   \n    MUC \n    15 (6%) \n    57 (7%) \n    5 (1%) \n    77 (5%) \n  \n  \n   \n    LGSC \n    14 (6%) \n    19 (2%) \n    4 (1%) \n    37 (2%) \n  \n  \n    Total \n    N (%) \n    244 (16%) \n    779 (52%) \n    468 (31%) \n    1491 (100%) \n  \n  Removed Replicates\n\n    Histotype \n    HGSC \n    9 (12%) \n    552 (79%) \n    451 (96%) \n    1012 (81%) \n  \n  \n   \n    CCOC \n    25 (32%) \n    52 (7%) \n    4 (1%) \n    81 (7%) \n  \n  \n   \n    ENOC \n    37 (48%) \n    25 (4%) \n    4 (1%) \n    66 (5%) \n  \n  \n   \n    MUC \n    3 (4%) \n    53 (8%) \n    5 (1%) \n    61 (5%) \n  \n  \n   \n    LGSC \n    3 (4%) \n    16 (2%) \n    4 (1%) \n    23 (2%) \n  \n  \n    Total \n    N (%) \n    77 (6%) \n    698 (56%) \n    468 (38%) \n    1243 (100%)\nTable 3.2: Histotype Distribution in Training, Confirmation, and Validation Sets\n\n\n\n\n \n  \n    Variable \n    Levels \n    Training \n    Confirmation \n    Validation \n  \n \n\n  \n    Histotype \n    HGSC \n    1012 (81%) \n    422 (66%) \n    666 (74%) \n  \n  \n   \n    CCOC \n    81 (7%) \n    75 (12%) \n    79 (9%) \n  \n  \n   \n    ENOC \n    66 (5%) \n    106 (16%) \n    105 (12%) \n  \n  \n   \n    MUC \n    61 (5%) \n    27 (4%) \n    26 (3%) \n  \n  \n   \n    LGSC \n    23 (2%) \n    13 (2%) \n    18 (2%) \n  \n  \n    Total \n    N (%) \n    1243 (45%) \n    643 (23%) \n    894 (32%)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distributions</span>"
    ]
  },
  {
    "objectID": "rsf/distributions.html#cohort-distribution",
    "href": "rsf/distributions.html#cohort-distribution",
    "title": "3  Distributions",
    "section": "3.2 Cohort Distribution",
    "text": "3.2 Cohort Distribution\n\n\n\n\nTable 3.3: Pre-QC Cohort Distribution by CodeSet\n\n\n\n\n \n  \n    CodeSet \n    CS1, N = 294 \n    CS2, N = 903 \n    CS3, N = 2,477 \n  \n \n\n  \n    Cohort \n     \n     \n     \n  \n  \n    OOU \n    108 (37%) \n    43 (4.8%) \n    19 (0.8%) \n  \n  \n    OOUE \n    32 (11%) \n    30 (3.3%) \n    11 (0.4%) \n  \n  \n    VOA \n    145 (49%) \n    122 (14%) \n    538 (22%) \n  \n  \n    OVAR3 \n    0 (0%) \n    150 (17%) \n    0 (0%) \n  \n  \n    ICON7 \n    0 (0%) \n    416 (46%) \n    0 (0%) \n  \n  \n    MAYO \n    6 (2.0%) \n    63 (7.0%) \n    0 (0%) \n  \n  \n    DOVE4 \n    0 (0%) \n    0 (0%) \n    1,160 (47%) \n  \n  \n    TNCO \n    0 (0%) \n    0 (0%) \n    691 (28%) \n  \n  \n    MTL \n    3 (1.0%) \n    59 (6.5%) \n    0 (0%) \n  \n  \n    JAPAN \n    0 (0%) \n    8 (0.9%) \n    0 (0%) \n  \n  \n    POOL-CTRL \n    0 (0%) \n    12 (1.3%) \n    0 (0%) \n  \n  \n    POOL-1 \n    0 (0%) \n    0 (0%) \n    31 (1.3%) \n  \n  \n    POOL-2 \n    0 (0%) \n    0 (0%) \n    14 (0.6%) \n  \n  \n    POOL-3 \n    0 (0%) \n    0 (0%) \n    13 (0.5%) \n  \n\n\n1 n (%)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distributions</span>"
    ]
  },
  {
    "objectID": "rsf/distributions.html#quality-control",
    "href": "rsf/distributions.html#quality-control",
    "title": "3  Distributions",
    "section": "3.3 Quality Control",
    "text": "3.3 Quality Control\n\n3.3.1 Failed Samples\nWe use an aggregated QCFlag that considers a sample to have failed QC if any of the following QC conditions are flagged:\n\nLinearity\nImaging\nSmallest Positive Control\nNormality\n\n\n\n\n\nTable 3.4: Quality Control Summary\n\n\n\n\n \n  \n    Quality Control Flag \n    CS1, N = 294 \n    CS2, N = 903 \n    CS3, N = 2,477 \n  \n \n\n  \n    Linearity \n     \n     \n     \n  \n  \n    Failed \n    0 (0%) \n    4 (0.4%) \n    0 (0%) \n  \n  \n    Passed \n    294 (100%) \n    899 (100%) \n    2,477 (100%) \n  \n  \n    Imaging \n     \n     \n     \n  \n  \n    Failed \n    3 (1.0%) \n    0 (0%) \n    4 (0.2%) \n  \n  \n    Passed \n    291 (99%) \n    903 (100%) \n    2,473 (100%) \n  \n  \n    Smallest Positive Control \n     \n     \n     \n  \n  \n    Failed \n    0 (0%) \n    2 (0.2%) \n    0 (0%) \n  \n  \n    Passed \n    294 (100%) \n    901 (100%) \n    2,477 (100%) \n  \n  \n    Normality \n     \n     \n     \n  \n  \n    Failed \n    5 (1.7%) \n    19 (2.1%) \n    200 (8.1%) \n  \n  \n    Passed \n    289 (98%) \n    884 (98%) \n    2,277 (92%) \n  \n  \n    Overall QC \n     \n     \n     \n  \n  \n    Failed \n    8 (2.7%) \n    21 (2.3%) \n    204 (8.2%) \n  \n  \n    Passed \n    286 (97%) \n    882 (98%) \n    2,273 (92%) \n  \n\n\n1 n (%)\n\n\n\n\n\n\n\n\n\n3.3.2 %GD vs. SNR\n\n\n\n\n\n\n\n\nFigure 3.1: % Genes Detected vs. Signal to Noise Ratio\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.2: % Genes Detected vs. Signal to Noise Ratio (Zoomed)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distributions</span>"
    ]
  },
  {
    "objectID": "rsf/distributions.html#pairwise-gene-expression",
    "href": "rsf/distributions.html#pairwise-gene-expression",
    "title": "3  Distributions",
    "section": "3.4 Pairwise Gene Expression",
    "text": "3.4 Pairwise Gene Expression\n\n\n\n\n\n\n\n\nFigure 3.3: Random1-Normalized CS1 vs. CS3 Gene Expression\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.4: Random1-Normalized CS2 vs. CS3 Gene Expression\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.5: HKgenes-Normalized CS1 vs. CS3 Gene Expression\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.6: HKgenes-Normalized CS2 vs. CS3 Gene Expression",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Distributions</span>"
    ]
  },
  {
    "objectID": "rsf/results.html",
    "href": "rsf/results.html",
    "title": "4  Results",
    "section": "",
    "text": "4.1 Training Set\nWe summarize cross-validated training performance of class metrics in the training set. The accuracy, F1-score, and kappa, are the metrics of interest. Workflows are ordered by their mean estimates across the outer folds of the nested CV for each metric.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "rsf/results.html#training-set",
    "href": "rsf/results.html#training-set",
    "title": "4  Results",
    "section": "",
    "text": "AccuracySensitivitySpecificityF1-ScoreBalanced AccuracyKappaG-mean\n\n\n\n\n\n\nTable 4.1: Training Set Mean Accuracy\n\n\n\n\n \n\n\nHistotypes\n\n  \n    Subsampling \n    Algorithms \n    Overall \n    HGSC \n    CCOC \n    ENOC \n    LGSC \n    MUC \n  \n \n\n  \n    none \n    rf \n    0.93 \n    0.947 \n    0.982 \n    0.965 \n    0.981 \n    0.985 \n  \n  \n   \n    svm \n    0.941 \n    0.961 \n    0.982 \n    0.97 \n    0.985 \n    0.985 \n  \n  \n   \n    xgb \n    0.823 \n    0.824 \n    0.943 \n    0.947 \n    0.982 \n    0.951 \n  \n  \n   \n    mr \n    0.814 \n    0.814 \n    0.935 \n    0.947 \n    0.982 \n    0.951 \n  \n  \n    down \n    rf \n    0.829 \n    0.861 \n    0.976 \n    0.945 \n    0.909 \n    0.968 \n  \n  \n   \n    svm \n    0.797 \n    0.831 \n    0.965 \n    0.924 \n    0.901 \n    0.973 \n  \n  \n   \n    xgb \n    0.206 \n    0.32 \n    0.583 \n    0.947 \n    0.79 \n    0.773 \n  \n  \n   \n    mr \n    0.817 \n    0.851 \n    0.969 \n    0.928 \n    0.92 \n    0.966 \n  \n  \n    up \n    rf \n    0.928 \n    0.949 \n    0.979 \n    0.969 \n    0.977 \n    0.982 \n  \n  \n   \n    svm \n    0.932 \n    0.959 \n    0.973 \n    0.963 \n    0.986 \n    0.982 \n  \n  \n   \n    xgb \n    0.937 \n    0.962 \n    0.982 \n    0.967 \n    0.982 \n    0.982 \n  \n  \n   \n    mr \n    0.889 \n    0.92 \n    0.974 \n    0.95 \n    0.961 \n    0.972 \n  \n  \n    smote \n    rf \n    0.94 \n    0.963 \n    0.981 \n    0.97 \n    0.981 \n    0.985 \n  \n  \n   \n    svm \n    0.932 \n    0.96 \n    0.974 \n    0.962 \n    0.986 \n    0.982 \n  \n  \n   \n    xgb \n    0.934 \n    0.957 \n    0.981 \n    0.967 \n    0.982 \n    0.981 \n  \n  \n   \n    mr \n    0.885 \n    0.914 \n    0.974 \n    0.956 \n    0.947 \n    0.979 \n  \n  \n    hybrid \n    rf \n    0.932 \n    0.957 \n    0.979 \n    0.969 \n    0.981 \n    0.978 \n  \n  \n   \n    svm \n    0.92 \n    0.948 \n    0.973 \n    0.957 \n    0.981 \n    0.982 \n  \n  \n   \n    xgb \n    0.928 \n    0.953 \n    0.978 \n    0.966 \n    0.978 \n    0.98 \n  \n  \n   \n    mr \n    0.885 \n    0.913 \n    0.978 \n    0.954 \n    0.949 \n    0.976 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.1: Training Set Mean Accuracy\n\n\n\n\n\n\n\n\n\n\n\nTable 4.2: Training Set Mean Sensitivity\n\n\n\n\n \n\n\nHistotypes\n\n  \n    Subsampling \n    Algorithms \n    Overall \n    HGSC \n    CCOC \n    ENOC \n    LGSC \n    MUC \n  \n \n\n  \n    none \n    rf \n    0.666 \n    0.991 \n    0.797 \n    0.585 \n    0.133 \n    0.822 \n  \n  \n   \n    svm \n    0.713 \n    0.993 \n    0.802 \n    0.695 \n    0.264 \n    0.81 \n  \n  \n   \n    xgb \n    0.241 \n    1 \n    0.203 \n    0 \n    0 \n    0 \n  \n  \n   \n    mr \n    0.2 \n    1 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    down \n    rf \n    0.805 \n    0.838 \n    0.816 \n    0.684 \n    0.865 \n    0.824 \n  \n  \n   \n    svm \n    0.814 \n    0.8 \n    0.743 \n    0.777 \n    0.971 \n    0.781 \n  \n  \n   \n    xgb \n    0.2 \n    0.2 \n    0.4 \n    0 \n    0.2 \n    0.2 \n  \n  \n   \n    mr \n    0.79 \n    0.826 \n    0.772 \n    0.683 \n    0.865 \n    0.804 \n  \n  \n    up \n    rf \n    0.695 \n    0.981 \n    0.805 \n    0.636 \n    0.28 \n    0.77 \n  \n  \n   \n    svm \n    0.725 \n    0.989 \n    0.748 \n    0.617 \n    0.528 \n    0.744 \n  \n  \n   \n    xgb \n    0.75 \n    0.98 \n    0.805 \n    0.715 \n    0.397 \n    0.854 \n  \n  \n   \n    mr \n    0.834 \n    0.91 \n    0.789 \n    0.766 \n    0.871 \n    0.833 \n  \n  \n    smote \n    rf \n    0.755 \n    0.984 \n    0.805 \n    0.762 \n    0.38 \n    0.841 \n  \n  \n   \n    svm \n    0.738 \n    0.988 \n    0.748 \n    0.661 \n    0.534 \n    0.76 \n  \n  \n   \n    xgb \n    0.796 \n    0.965 \n    0.84 \n    0.738 \n    0.596 \n    0.839 \n  \n  \n   \n    mr \n    0.806 \n    0.905 \n    0.792 \n    0.79 \n    0.703 \n    0.839 \n  \n  \n    hybrid \n    rf \n    0.775 \n    0.97 \n    0.801 \n    0.777 \n    0.47 \n    0.855 \n  \n  \n   \n    svm \n    0.811 \n    0.957 \n    0.783 \n    0.764 \n    0.763 \n    0.788 \n  \n  \n   \n    xgb \n    0.792 \n    0.96 \n    0.825 \n    0.727 \n    0.594 \n    0.854 \n  \n  \n   \n    mr \n    0.821 \n    0.903 \n    0.812 \n    0.782 \n    0.77 \n    0.839 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.2: Training Set Mean Sensitivity\n\n\n\n\n\n\n\n\n\n\n\nTable 4.3: Training Set Mean Specificity\n\n\n\n\n \n\n\nHistotypes\n\n  \n    Subsampling \n    Algorithms \n    Overall \n    HGSC \n    CCOC \n    ENOC \n    LGSC \n    MUC \n  \n \n\n  \n    none \n    rf \n    0.947 \n    0.761 \n    0.995 \n    0.988 \n    0.998 \n    0.993 \n  \n  \n   \n    svm \n    0.959 \n    0.821 \n    0.995 \n    0.986 \n    0.998 \n    0.994 \n  \n  \n   \n    xgb \n    0.811 \n    0.055 \n    0.999 \n    1 \n    1 \n    1 \n  \n  \n   \n    mr \n    0.8 \n    0 \n    1 \n    1 \n    1 \n    1 \n  \n  \n    down \n    rf \n    0.958 \n    0.961 \n    0.987 \n    0.958 \n    0.91 \n    0.975 \n  \n  \n   \n    svm \n    0.952 \n    0.963 \n    0.98 \n    0.933 \n    0.9 \n    0.984 \n  \n  \n   \n    xgb \n    0.8 \n    0.8 \n    0.6 \n    1 \n    0.8 \n    0.8 \n  \n  \n   \n    mr \n    0.955 \n    0.959 \n    0.983 \n    0.94 \n    0.92 \n    0.975 \n  \n  \n    up \n    rf \n    0.953 \n    0.803 \n    0.991 \n    0.987 \n    0.991 \n    0.992 \n  \n  \n   \n    svm \n    0.959 \n    0.833 \n    0.99 \n    0.984 \n    0.993 \n    0.995 \n  \n  \n   \n    xgb \n    0.968 \n    0.881 \n    0.995 \n    0.981 \n    0.993 \n    0.988 \n  \n  \n   \n    mr \n    0.971 \n    0.964 \n    0.987 \n    0.962 \n    0.963 \n    0.979 \n  \n  \n    smote \n    rf \n    0.966 \n    0.866 \n    0.993 \n    0.983 \n    0.993 \n    0.992 \n  \n  \n   \n    svm \n    0.96 \n    0.841 \n    0.991 \n    0.982 \n    0.994 \n    0.994 \n  \n  \n   \n    xgb \n    0.974 \n    0.923 \n    0.991 \n    0.979 \n    0.989 \n    0.988 \n  \n  \n   \n    mr \n    0.968 \n    0.95 \n    0.987 \n    0.965 \n    0.951 \n    0.986 \n  \n  \n    hybrid \n    rf \n    0.97 \n    0.903 \n    0.991 \n    0.981 \n    0.991 \n    0.985 \n  \n  \n   \n    svm \n    0.969 \n    0.91 \n    0.986 \n    0.97 \n    0.985 \n    0.992 \n  \n  \n   \n    xgb \n    0.971 \n    0.916 \n    0.989 \n    0.979 \n    0.985 \n    0.987 \n  \n  \n   \n    mr \n    0.968 \n    0.954 \n    0.99 \n    0.964 \n    0.952 \n    0.983 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.3: Training Set Mean Specificity\n\n\n\n\n\n\n\n\n\n\n\nTable 4.4: Training Set Mean F1-Score\n\n\n\n\n \n\n\nHistotypes\n\n  \n    Subsampling \n    Algorithms \n    Overall \n    HGSC \n    CCOC \n    ENOC \n    LGSC \n    MUC \n  \n \n\n  \n    none \n    rf \n    0.751 \n    0.968 \n    0.849 \n    0.622 \n    0.262 \n    0.838 \n  \n  \n   \n    svm \n    0.775 \n    0.976 \n    0.852 \n    0.695 \n    0.433 \n    0.837 \n  \n  \n   \n    xgb \n    0.841 \n    0.902 \n    0.611 \n    NaN \n    NaN \n    NaN \n  \n  \n   \n    mr \n    0.897 \n    0.897 \n    NaN \n    NaN \n    NaN \n    NaN \n  \n  \n    down \n    rf \n    0.648 \n    0.907 \n    0.813 \n    0.545 \n    0.255 \n    0.719 \n  \n  \n   \n    svm \n    0.623 \n    0.884 \n    0.728 \n    0.486 \n    0.275 \n    0.744 \n  \n  \n   \n    xgb \n    0.257 \n    0.91 \n    0.114 \n    NaN \n    0.04 \n    0.106 \n  \n  \n   \n    mr \n    0.622 \n    0.9 \n    0.76 \n    0.474 \n    0.273 \n    0.704 \n  \n  \n    up \n    rf \n    0.707 \n    0.969 \n    0.829 \n    0.657 \n    0.278 \n    0.803 \n  \n  \n   \n    svm \n    0.741 \n    0.975 \n    0.776 \n    0.612 \n    0.54 \n    0.802 \n  \n  \n   \n    xgb \n    0.747 \n    0.977 \n    0.855 \n    0.678 \n    0.408 \n    0.817 \n  \n  \n   \n    mr \n    0.706 \n    0.949 \n    0.804 \n    0.587 \n    0.448 \n    0.742 \n  \n  \n    smote \n    rf \n    0.748 \n    0.978 \n    0.837 \n    0.716 \n    0.37 \n    0.84 \n  \n  \n   \n    svm \n    0.751 \n    0.975 \n    0.783 \n    0.626 \n    0.566 \n    0.805 \n  \n  \n   \n    xgb \n    0.763 \n    0.973 \n    0.845 \n    0.663 \n    0.528 \n    0.806 \n  \n  \n   \n    mr \n    0.7 \n    0.945 \n    0.797 \n    0.631 \n    0.334 \n    0.793 \n  \n  \n    hybrid \n    rf \n    0.748 \n    0.974 \n    0.828 \n    0.698 \n    0.448 \n    0.791 \n  \n  \n   \n    svm \n    0.751 \n    0.967 \n    0.785 \n    0.622 \n    0.569 \n    0.81 \n  \n  \n   \n    xgb \n    0.753 \n    0.97 \n    0.829 \n    0.678 \n    0.484 \n    0.803 \n  \n  \n   \n    mr \n    0.708 \n    0.944 \n    0.829 \n    0.628 \n    0.367 \n    0.769 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.4: Training Set Mean F1-Score\n\n\n\n\n\n\n\n\n\n\n\nTable 4.5: Training Set Mean Balanced Accuracy\n\n\n\n\n \n\n\nHistotypes\n\n  \n    Subsampling \n    Algorithms \n    Overall \n    HGSC \n    CCOC \n    ENOC \n    LGSC \n    MUC \n  \n \n\n  \n    none \n    rf \n    0.806 \n    0.876 \n    0.896 \n    0.786 \n    0.566 \n    0.908 \n  \n  \n   \n    svm \n    0.836 \n    0.907 \n    0.898 \n    0.841 \n    0.631 \n    0.902 \n  \n  \n   \n    xgb \n    0.526 \n    0.528 \n    0.601 \n    0.5 \n    0.5 \n    0.5 \n  \n  \n   \n    mr \n    0.5 \n    0.5 \n    0.5 \n    0.5 \n    0.5 \n    0.5 \n  \n  \n    down \n    rf \n    0.882 \n    0.899 \n    0.902 \n    0.821 \n    0.887 \n    0.9 \n  \n  \n   \n    svm \n    0.883 \n    0.882 \n    0.862 \n    0.855 \n    0.936 \n    0.882 \n  \n  \n   \n    xgb \n    0.5 \n    0.5 \n    0.5 \n    0.5 \n    0.5 \n    0.5 \n  \n  \n   \n    mr \n    0.873 \n    0.892 \n    0.878 \n    0.812 \n    0.893 \n    0.889 \n  \n  \n    up \n    rf \n    0.824 \n    0.892 \n    0.898 \n    0.812 \n    0.636 \n    0.881 \n  \n  \n   \n    svm \n    0.842 \n    0.911 \n    0.869 \n    0.801 \n    0.761 \n    0.87 \n  \n  \n   \n    xgb \n    0.859 \n    0.931 \n    0.9 \n    0.848 \n    0.695 \n    0.921 \n  \n  \n   \n    mr \n    0.903 \n    0.937 \n    0.888 \n    0.864 \n    0.917 \n    0.906 \n  \n  \n    smote \n    rf \n    0.86 \n    0.925 \n    0.899 \n    0.872 \n    0.687 \n    0.917 \n  \n  \n   \n    svm \n    0.849 \n    0.915 \n    0.869 \n    0.822 \n    0.764 \n    0.877 \n  \n  \n   \n    xgb \n    0.885 \n    0.944 \n    0.915 \n    0.858 \n    0.792 \n    0.914 \n  \n  \n   \n    mr \n    0.887 \n    0.927 \n    0.889 \n    0.877 \n    0.827 \n    0.913 \n  \n  \n    hybrid \n    rf \n    0.872 \n    0.937 \n    0.896 \n    0.879 \n    0.731 \n    0.92 \n  \n  \n   \n    svm \n    0.89 \n    0.933 \n    0.885 \n    0.867 \n    0.874 \n    0.89 \n  \n  \n   \n    xgb \n    0.882 \n    0.938 \n    0.907 \n    0.853 \n    0.79 \n    0.92 \n  \n  \n   \n    mr \n    0.895 \n    0.928 \n    0.901 \n    0.873 \n    0.861 \n    0.911 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.5: Training Set Mean Balanced Accuracy\n\n\n\n\n\n\n\n\n\n\n\nTable 4.6: Training Set Mean Kappa\n\n\n\n\n \n\n\nHistotypes\n\n  \n    Subsampling \n    Algorithms \n    Overall \n    HGSC \n    CCOC \n    ENOC \n    LGSC \n    MUC \n  \n \n\n  \n    none \n    rf \n    0.767 \n    0.811 \n    0.84 \n    0.604 \n    0.154 \n    0.83 \n  \n  \n   \n    svm \n    0.808 \n    0.862 \n    0.843 \n    0.679 \n    0.342 \n    0.829 \n  \n  \n   \n    xgb \n    0.084 \n    0.083 \n    0.24 \n    0 \n    0 \n    0 \n  \n  \n   \n    mr \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    down \n    rf \n    0.597 \n    0.633 \n    0.8 \n    0.517 \n    0.232 \n    0.702 \n  \n  \n   \n    svm \n    0.547 \n    0.577 \n    0.709 \n    0.452 \n    0.252 \n    0.73 \n  \n  \n   \n    xgb \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n   \n    mr \n    0.574 \n    0.613 \n    0.744 \n    0.439 \n    0.251 \n    0.687 \n  \n  \n    up \n    rf \n    0.764 \n    0.819 \n    0.818 \n    0.641 \n    0.269 \n    0.793 \n  \n  \n   \n    svm \n    0.779 \n    0.859 \n    0.762 \n    0.593 \n    0.533 \n    0.793 \n  \n  \n   \n    xgb \n    0.804 \n    0.871 \n    0.845 \n    0.66 \n    0.399 \n    0.807 \n  \n  \n   \n    mr \n    0.706 \n    0.766 \n    0.79 \n    0.562 \n    0.434 \n    0.728 \n  \n  \n    smote \n    rf \n    0.806 \n    0.87 \n    0.827 \n    0.7 \n    0.363 \n    0.832 \n  \n  \n   \n    svm \n    0.783 \n    0.862 \n    0.77 \n    0.606 \n    0.56 \n    0.796 \n  \n  \n   \n    xgb \n    0.803 \n    0.862 \n    0.835 \n    0.646 \n    0.519 \n    0.796 \n  \n  \n   \n    mr \n    0.695 \n    0.747 \n    0.783 \n    0.608 \n    0.316 \n    0.782 \n  \n  \n    hybrid \n    rf \n    0.793 \n    0.858 \n    0.817 \n    0.682 \n    0.439 \n    0.78 \n  \n  \n   \n    svm \n    0.765 \n    0.831 \n    0.77 \n    0.601 \n    0.56 \n    0.801 \n  \n  \n   \n    xgb \n    0.786 \n    0.846 \n    0.817 \n    0.661 \n    0.475 \n    0.793 \n  \n  \n   \n    mr \n    0.696 \n    0.745 \n    0.818 \n    0.604 \n    0.349 \n    0.757 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.6: Training Set Mean Kappa\n\n\n\n\n\n\n\nDEPRECATED\n\n\n\n\nTable 4.7: Training Set Mean G-mean\n\n\n\n\n \n\n\nHistotypes\n\n  \n    Subsampling \n    Algorithms \n    Overall \n    HGSC \n    CCOC \n    ENOC \n    LGSC \n    MUC \n  \n \n\n  \n    none \n    rf \n    0.261 \n    0.868 \n    0.89 \n    0.755 \n    0.223 \n    0.903 \n  \n  \n   \n    svm \n    0.54 \n    0.903 \n    0.893 \n    0.827 \n    0.453 \n    0.897 \n  \n  \n   \n    xgb \n    0 \n    0.146 \n    0.271 \n    0 \n    0 \n    0 \n  \n  \n   \n    mr \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n    down \n    rf \n    0.798 \n    0.897 \n    0.897 \n    0.806 \n    0.884 \n    0.895 \n  \n  \n   \n    svm \n    0.809 \n    0.878 \n    0.853 \n    0.85 \n    0.934 \n    0.875 \n  \n  \n   \n    xgb \n    0 \n    0 \n    0 \n    0 \n    0 \n    0 \n  \n  \n   \n    mr \n    0.782 \n    0.89 \n    0.871 \n    0.796 \n    0.889 \n    0.884 \n  \n  \n    up \n    rf \n    0.421 \n    0.887 \n    0.893 \n    0.789 \n    0.403 \n    0.874 \n  \n  \n   \n    svm \n    0.699 \n    0.907 \n    0.859 \n    0.775 \n    0.715 \n    0.859 \n  \n  \n   \n    xgb \n    0.706 \n    0.929 \n    0.894 \n    0.836 \n    0.614 \n    0.918 \n  \n  \n   \n    mr \n    0.829 \n    0.936 \n    0.882 \n    0.858 \n    0.913 \n    0.903 \n  \n  \n    smote \n    rf \n    0.607 \n    0.923 \n    0.894 \n    0.864 \n    0.545 \n    0.913 \n  \n  \n   \n    svm \n    0.714 \n    0.911 \n    0.859 \n    0.799 \n    0.724 \n    0.867 \n  \n  \n   \n    xgb \n    0.778 \n    0.944 \n    0.912 \n    0.849 \n    0.759 \n    0.91 \n  \n  \n   \n    mr \n    0.801 \n    0.927 \n    0.884 \n    0.872 \n    0.814 \n    0.909 \n  \n  \n    hybrid \n    rf \n    0.749 \n    0.936 \n    0.891 \n    0.872 \n    0.676 \n    0.917 \n  \n  \n   \n    svm \n    0.804 \n    0.933 \n    0.878 \n    0.859 \n    0.863 \n    0.884 \n  \n  \n   \n    xgb \n    0.778 \n    0.938 \n    0.903 \n    0.842 \n    0.759 \n    0.918 \n  \n  \n   \n    mr \n    0.816 \n    0.928 \n    0.896 \n    0.868 \n    0.851 \n    0.907 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.7: Training Set Mean G-mean",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "rsf/results.html#rank-aggregation",
    "href": "rsf/results.html#rank-aggregation",
    "title": "4  Results",
    "section": "4.2 Rank Aggregation",
    "text": "4.2 Rank Aggregation\nMulti-step methods:\n\nsequential: sequential algorithm sequence of subsampling methods and algorithms used are:\n\nHGSC vs. non-HGSC using SMOTE subsampling and random forest\nCCOC vs. non-CCOC using hybrid subsampling and XGBoost\nENOC vs. non-ENOC using upsampling and support vector machine\nLGSC vs. MUC using hybrid subsampling and regularized multinomial regression\n\ntwo_step: two-step algorithm sequence of subsampling methods and algorithms used are:\n\nHGSC vs. non-HGSC using SMOTE subsampling and random forest\nCCOC vs. ENOC vs. MUC vs. LGSC using hybrid subsampling and support vector machine\n\n\nWe conduct rank aggregation using a two-stage nested appraoch:\n\nFirst we rank aggregate the per-class metrics for F1-score, balanced accuracy and kappa.\nThen we take the aggregated lists from the three metrics and perform a final rank aggregation.\nThe top workflows from the final rank aggregation are used for gene optimization in the confirmation set\n\n\n4.2.1 Across Classes\n\nF1-ScoreBalanced AccuracyKappa\n\n\n\n\n\n\nTable 4.8: F1-Score Rank Aggregation Summary\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 4.9: Balanced Accuracy Rank Aggregation Summary\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 4.10: Kappa Rank Aggregation Summary\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.2.2 Across Metrics\n\n\n\n\nTable 4.11: Rank Aggregation Comparison of Metrics Used\n\n\n\n\n \n  \n    Rank \n    F1 \n    Balanced Accuracy \n    Kappa \n  \n \n\n  \n    1 \n    sequential \n    sequential \n    sequential \n  \n  \n    2 \n    two_step \n    hybrid_xgb \n    smote_rf \n  \n  \n    3 \n    smote_rf \n    smote_xgb \n    up_xgb \n  \n  \n    4 \n    none_svm \n    hybrid_rf \n    none_svm \n  \n  \n    5 \n    up_xgb \n    smote_rf \n    two_step \n  \n  \n    6 \n    smote_xgb \n    up_xgb \n    smote_xgb \n  \n  \n    7 \n    hybrid_xgb \n    up_mr \n    hybrid_rf \n  \n  \n    8 \n    smote_svm \n    hybrid_mr \n    hybrid_xgb \n  \n  \n    9 \n    hybrid_rf \n    smote_mr \n    smote_svm \n  \n  \n    10 \n    up_rf \n    two_step \n    up_svm \n  \n  \n    11 \n    up_svm \n    hybrid_svm \n    hybrid_svm \n  \n  \n    12 \n    hybrid_mr \n    none_svm \n    up_rf \n  \n  \n    13 \n    hybrid_svm \n    smote_svm \n    none_rf \n  \n  \n    14 \n    none_rf \n    down_rf \n    hybrid_mr \n  \n  \n    15 \n    smote_mr \n    down_mr \n    smote_mr \n  \n  \n    16 \n    up_mr \n    down_svm \n    up_mr \n  \n  \n    17 \n    down_rf \n    up_rf \n    down_rf \n  \n  \n    18 \n    down_mr \n    up_svm \n    down_mr \n  \n  \n    19 \n    down_svm \n    none_rf \n    down_svm \n  \n  \n    20 \n    NA \n    down_xgb \n    down_xgb \n  \n  \n    21 \n    NA \n    none_mr \n    none_mr \n  \n  \n    22 \n    NA \n    none_xgb \n    none_xgb \n  \n\n\n\n\n\n\n\n\n\n\n\n\nTable 4.12: Top 5 Workflows from Final Rank Aggregation\n\n\n\n\n \n  \n    Rank \n    Workflow \n  \n \n\n  \n    1 \n    sequential \n  \n  \n    2 \n    smote_rf \n  \n  \n    3 \n    two_step \n  \n  \n    4 \n    none_svm \n  \n  \n    5 \n    up_xgb \n  \n\n\n\n\n\n\n\n\n\n\n4.2.3 Top Workflows\nWe look at the per-class evaluation metrics of the top 5 workflows.\n\n\n\n\n\n\n\n\nFigure 4.8: Top 5 Workflow Per-Class Evaluation Metrics by Metric\n\n\n\n\n\nMisclassified cases from a previous step of the sequence of classifiers are not included in subsequent steps of the training set CV folds. Thus, we cannot piece together the test set predictions from the sequential and two-step algorithms to obtain overall metrics.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "rsf/results.html#optimal-gene-sets",
    "href": "rsf/results.html#optimal-gene-sets",
    "title": "4  Results",
    "section": "4.3 Optimal Gene Sets",
    "text": "4.3 Optimal Gene Sets\n\n4.3.1 Sequential Algorithm\n\n\n\n\n\n\n\n\nFigure 4.9: Gene Optimization for Sequential Classifier\n\n\n\n\nIn the sequential algorithm, sequences 1, 2, and 4 have relatively flat average F1-scores across the number of genes added. However, we can observe in sequence 3, the F1-score stabilizes at around 0.88 when we reach 7 genes added, hence the optimal number of genes used will be n=28+7=35 The added genes are: CYP2C18, TFF3, TP53, HNF1B, WT1, MAP1LC3A and SLC3A1.\n\n\n\n\nTable 4.13: Gene Profile of Optimal Set in Sequential Algorithm\n\n\n\n\n \n  \n    Set \n    Genes \n    PrOTYPE \n    SPOT \n    Optimal Set \n    Candidate Rank \n  \n \n\n  \n    Base \n    COL11A1 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    CD74 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    CD2 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    TIMP3 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    LUM \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    CYTIP \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    COL3A1 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    THBS2 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    TCF7L1 \n    ✔ \n    ✔ \n    ◉ \n     \n  \n  \n   \n    HMGA2 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    FN1 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    POSTN \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    COL1A2 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    COL5A2 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    PDZK1IP1 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    FBN1 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    HIF1A \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    CXCL10 \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    DUSP4 \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    SOX17 \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    MITF \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    CDKN3 \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    BRCA2 \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    CEACAM5 \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    ANXA4 \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    SERPINE1 \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    CRABP2 \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    DNAJC9 \n     \n    ✔ \n    ◉ \n     \n  \n  \n    Candidates \n    CYP2C18 \n     \n     \n    ◉ \n    1 \n  \n  \n   \n    TFF3 \n     \n     \n    ◉ \n    2 \n  \n  \n   \n    TP53 \n     \n     \n    ◉ \n    3 \n  \n  \n   \n    HNF1B \n     \n     \n    ◉ \n    4 \n  \n  \n   \n    WT1 \n     \n     \n    ◉ \n    5 \n  \n  \n   \n    MAP1LC3A \n     \n     \n    ◉ \n    6 \n  \n  \n   \n    SLC3A1 \n     \n     \n    ◉ \n    7 \n  \n  \n   \n    EPAS1 \n     \n     \n    ◉ \n    8 \n  \n  \n   \n    EGFL6 \n     \n     \n    ◉ \n    9 \n  \n  \n   \n    IL6 \n     \n     \n    ◉ \n    10 \n  \n  \n   \n    TFF1 \n     \n     \n    ◉ \n    11 \n  \n  \n   \n    BRCA1 \n     \n     \n    ◉ \n    12 \n  \n  \n   \n    IGFBP1 \n     \n     \n    ◉ \n    13 \n  \n  \n   \n    ATP5G3 \n     \n     \n    ◉ \n    14 \n  \n  \n   \n    MUC5B \n     \n     \n    ◉ \n    15 \n  \n  \n   \n    SEMA6A \n     \n     \n    ◉ \n    16 \n  \n  \n   \n    FUT3 \n     \n     \n    ◉ \n    17 \n  \n  \n   \n    MET \n     \n     \n    ◉ \n    18 \n  \n  \n   \n    GPR64 \n     \n     \n    ◉ \n    19 \n  \n  \n   \n    ZBED1 \n     \n     \n    ◉ \n    20 \n  \n  \n   \n    CPNE8 \n     \n     \n    ◉ \n    21 \n  \n  \n   \n    SCGB1D2 \n     \n     \n    ◉ \n    22 \n  \n  \n   \n    PAX8 \n     \n     \n    ◉ \n    23 \n  \n  \n   \n    KLK7 \n     \n     \n    ◉ \n    24 \n  \n  \n   \n    STC1 \n     \n     \n    ◉ \n    25 \n  \n  \n   \n    CAPN2 \n     \n     \n    ◉ \n    26 \n  \n  \n   \n    TPX2 \n     \n     \n    ◉ \n    27 \n  \n  \n   \n    GAD1 \n     \n     \n    ◉ \n    28 \n  \n  \n   \n    DKK4 \n     \n     \n    ◉ \n    29 \n  \n  \n   \n    GCNT3 \n     \n     \n    ◉ \n    30 \n  \n  \n   \n    CYP4B1 \n     \n     \n    ◉ \n    31 \n  \n  \n   \n    LGALS4 \n     \n     \n    ◉ \n    32 \n  \n  \n   \n    C1orf173 \n     \n     \n    ◉ \n    33 \n  \n  \n   \n    C10orf116 \n     \n     \n    ◉ \n    34 \n  \n  \n   \n    PBX1 \n     \n     \n    ◉ \n    35 \n  \n  \n   \n    KGFLP2 \n     \n     \n    ◉ \n    36 \n  \n  \n   \n    SENP8 \n     \n     \n    ◉ \n    37 \n  \n  \n   \n    BCL2 \n     \n     \n    ◉ \n    38 \n  \n  \n   \n    ADCYAP1R1 \n     \n     \n    ◉ \n    39 \n  \n  \n   \n    TSPAN8 \n     \n     \n    ◉ \n    40 \n  \n  \n   \n    LIN28B \n     \n     \n    ◉ \n    41 \n  \n  \n   \n    SERPINA5 \n     \n     \n    ◉ \n    42 \n  \n  \n   \n    IGJ \n     \n     \n    ◉ \n    43 \n  \n  \n   \n    IGKC \n     \n     \n    ◉ \n    44 \n  \n\n\n\n\n\n\n\n\n\n\n4.3.2 SMOTE-Random Forest\n\n\n\n\n\n\n\n\nFigure 4.10: Gene Optimization for SMOTE-Random Forest Classifier\n\n\n\n\nIn the SMOTE-Random Forest classifier, the F1-score stabilizes at around 0.7 when we reach 18 genes added, hence the optimal number of genes used will be n=28+18=46 The added genes are: TFF1, HNF1B, TFF3, LGALS4, SLC3A1, WT1, KLK7, TPX2, CYP2C18, GAD1, IGFBP1, CAPN2, FUT3, DKK4, C1orf173, GCNT3, C10orf116 and MUC5B.\n\n\n\n\nTable 4.14: Gene Profile of Optimal Set in SMOTE-Random Forest Workflow\n\n\n\n\n \n  \n    Set \n    Genes \n    PrOTYPE \n    SPOT \n    Optimal Set \n    Candidate Rank \n  \n \n\n  \n    Base \n    COL11A1 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    CD74 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    CD2 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    TIMP3 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    LUM \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    CYTIP \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    COL3A1 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    THBS2 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    TCF7L1 \n    ✔ \n    ✔ \n    ◉ \n     \n  \n  \n   \n    HMGA2 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    FN1 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    POSTN \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    COL1A2 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    COL5A2 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    PDZK1IP1 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    FBN1 \n    ✔ \n     \n    ◉ \n     \n  \n  \n   \n    HIF1A \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    CXCL10 \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    DUSP4 \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    SOX17 \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    MITF \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    CDKN3 \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    BRCA2 \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    CEACAM5 \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    ANXA4 \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    SERPINE1 \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    CRABP2 \n     \n    ✔ \n    ◉ \n     \n  \n  \n   \n    DNAJC9 \n     \n    ✔ \n    ◉ \n     \n  \n  \n    Candidates \n    TFF1 \n     \n     \n    ◉ \n    1 \n  \n  \n   \n    HNF1B \n     \n     \n    ◉ \n    2 \n  \n  \n   \n    TFF3 \n     \n     \n    ◉ \n    3 \n  \n  \n   \n    LGALS4 \n     \n     \n    ◉ \n    4 \n  \n  \n   \n    SLC3A1 \n     \n     \n    ◉ \n    5 \n  \n  \n   \n    WT1 \n     \n     \n    ◉ \n    6 \n  \n  \n   \n    KLK7 \n     \n     \n    ◉ \n    7 \n  \n  \n   \n    TPX2 \n     \n     \n    ◉ \n    8 \n  \n  \n   \n    CYP2C18 \n     \n     \n    ◉ \n    9 \n  \n  \n   \n    GAD1 \n     \n     \n    ◉ \n    10 \n  \n  \n   \n    IGFBP1 \n     \n     \n    ◉ \n    11 \n  \n  \n   \n    CAPN2 \n     \n     \n    ◉ \n    12 \n  \n  \n   \n    FUT3 \n     \n     \n    ◉ \n    13 \n  \n  \n   \n    DKK4 \n     \n     \n    ◉ \n    14 \n  \n  \n   \n    C1orf173 \n     \n     \n    ◉ \n    15 \n  \n  \n   \n    GCNT3 \n     \n     \n    ◉ \n    16 \n  \n  \n   \n    C10orf116 \n     \n     \n    ◉ \n    17 \n  \n  \n   \n    MUC5B \n     \n     \n    ◉ \n    18 \n  \n  \n   \n    ATP5G3 \n     \n     \n    ◉ \n    19 \n  \n  \n   \n    PAX8 \n     \n     \n    ◉ \n    20 \n  \n  \n   \n    IL6 \n     \n     \n    ◉ \n    21 \n  \n  \n   \n    GPR64 \n     \n     \n    ◉ \n    22 \n  \n  \n   \n    CPNE8 \n     \n     \n    ◉ \n    23 \n  \n  \n   \n    PBX1 \n     \n     \n    ◉ \n    24 \n  \n  \n   \n    STC1 \n     \n     \n    ◉ \n    25 \n  \n  \n   \n    MET \n     \n     \n    ◉ \n    26 \n  \n  \n   \n    IGKC \n     \n     \n    ◉ \n    27 \n  \n  \n   \n    EPAS1 \n     \n     \n    ◉ \n    28 \n  \n  \n   \n    TSPAN8 \n     \n     \n    ◉ \n    29 \n  \n  \n   \n    SEMA6A \n     \n     \n    ◉ \n    30 \n  \n  \n   \n    EGFL6 \n     \n     \n    ◉ \n    31 \n  \n  \n   \n    TP53 \n     \n     \n    ◉ \n    32 \n  \n  \n   \n    CYP4B1 \n     \n     \n    ◉ \n    33 \n  \n  \n   \n    KGFLP2 \n     \n     \n    ◉ \n    34 \n  \n  \n   \n    BRCA1 \n     \n     \n    ◉ \n    35 \n  \n  \n   \n    LIN28B \n     \n     \n    ◉ \n    36 \n  \n  \n   \n    SERPINA5 \n     \n     \n    ◉ \n    37 \n  \n  \n   \n    BCL2 \n     \n     \n    ◉ \n    38 \n  \n  \n   \n    SCGB1D2 \n     \n     \n    ◉ \n    39 \n  \n  \n   \n    ZBED1 \n     \n     \n    ◉ \n    40 \n  \n  \n   \n    SENP8 \n     \n     \n    ◉ \n    41 \n  \n  \n   \n    ADCYAP1R1 \n     \n     \n    ◉ \n    42 \n  \n  \n   \n    MAP1LC3A \n     \n     \n    ◉ \n    43 \n  \n  \n   \n    IGJ \n     \n     \n    ◉ \n    44",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "rsf/results.html#test-set-performance",
    "href": "rsf/results.html#test-set-performance",
    "title": "4  Results",
    "section": "4.4 Test Set Performance",
    "text": "4.4 Test Set Performance\nNow we’d like to see how our best methods perform in the confirmation and validation sets. The class-specific F1-scores will be used.\nThe top 2 methods are the sequential and SMOTE-Random Forest classifiers. We can test 2 additional methods by using either the full set of genes or the optimal set of genes for both of these classifiers.\n\n4.4.1 Confirmation Set\n\n\n\n\nTable 4.15: Evaluation Metrics on Confirmation Set Models\n\n\n\n\n \n\n\nHistotypes\n\n  \n    Method \n    Metric \n    Overall \n    HGSC \n    CCOC \n    ENOC \n    LGSC \n    MUC \n  \n \n\n  \n    Sequential, Full Set \n    Accuracy \n    0.834 \n    0.869 \n    0.960 \n    0.894 \n    0.977 \n    0.967 \n  \n  \n   \n    Sensitivity \n    0.655 \n    0.948 \n    0.853 \n    0.462 \n    0.308 \n    0.704 \n  \n  \n   \n    Specificity \n    0.928 \n    0.719 \n    0.974 \n    0.980 \n    0.990 \n    0.979 \n  \n  \n   \n    F1-Score \n    0.664 \n    0.905 \n    0.831 \n    0.590 \n    0.348 \n    0.644 \n  \n  \n   \n    Balanced Accuracy \n    0.792 \n    0.834 \n    0.913 \n    0.721 \n    0.649 \n    0.841 \n  \n  \n   \n    Kappa \n    0.665 \n    0.697 \n    0.808 \n    0.535 \n    0.336 \n    0.627 \n  \n  \n    Sequential, Optimal Set \n    Accuracy \n    0.821 \n    0.865 \n    0.949 \n    0.879 \n    0.983 \n    0.967 \n  \n  \n   \n    Sensitivity \n    0.633 \n    0.953 \n    0.840 \n    0.396 \n    0.385 \n    0.593 \n  \n  \n   \n    Specificity \n    0.923 \n    0.697 \n    0.963 \n    0.974 \n    0.995 \n    0.984 \n  \n  \n   \n    F1-Score \n    0.659 \n    0.902 \n    0.792 \n    0.519 \n    0.476 \n    0.604 \n  \n  \n   \n    Balanced Accuracy \n    0.778 \n    0.825 \n    0.902 \n    0.685 \n    0.690 \n    0.788 \n  \n  \n   \n    Kappa \n    0.635 \n    0.684 \n    0.763 \n    0.457 \n    0.468 \n    0.587 \n  \n  \n    SMOTE-Random Forest, Full Set \n    Accuracy \n    0.843 \n    0.871 \n    0.969 \n    0.896 \n    0.980 \n    0.970 \n  \n  \n   \n    Sensitivity \n    0.659 \n    0.962 \n    0.867 \n    0.453 \n    0.308 \n    0.704 \n  \n  \n   \n    Specificity \n    0.928 \n    0.697 \n    0.982 \n    0.983 \n    0.994 \n    0.982 \n  \n  \n   \n    F1-Score \n    0.682 \n    0.907 \n    0.867 \n    0.589 \n    0.381 \n    0.667 \n  \n  \n   \n    Balanced Accuracy \n    0.793 \n    0.829 \n    0.925 \n    0.718 \n    0.651 \n    0.843 \n  \n  \n   \n    Kappa \n    0.677 \n    0.697 \n    0.849 \n    0.535 \n    0.371 \n    0.651 \n  \n  \n    SMOTE-Random Forest, Optimal Set \n    Accuracy \n    0.851 \n    0.876 \n    0.966 \n    0.904 \n    0.981 \n    0.975 \n  \n  \n   \n    Sensitivity \n    0.695 \n    0.957 \n    0.853 \n    0.500 \n    0.385 \n    0.778 \n  \n  \n   \n    Specificity \n    0.932 \n    0.719 \n    0.981 \n    0.983 \n    0.994 \n    0.984 \n  \n  \n   \n    F1-Score \n    0.715 \n    0.910 \n    0.853 \n    0.631 \n    0.455 \n    0.724 \n  \n  \n   \n    Balanced Accuracy \n    0.813 \n    0.838 \n    0.917 \n    0.742 \n    0.689 \n    0.881 \n  \n  \n   \n    Kappa \n    0.697 \n    0.710 \n    0.834 \n    0.580 \n    0.445 \n    0.711 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.11: Confusion Matrices for Confirmation Set Models\n\n\n\n\n\n\nSequential, FullSequential, OptimalSMOTE-Random Forest, FullSMOTE-Random Forest, Optimal\n\n\n\n\n\n\n\n\n\n\nFigure 4.12: ROC Curves for Sequential Full Model in Confirmation Set\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.13: ROC Curves for Sequential, Optimal Model in Confirmation Set\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.14: ROC Curves for SMOTE-Random Forest, Full Set Model in Confirmation Set\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.15: ROC Curves for SMOTE-Random Forest, Optimal Set Model in Confirmation Set\n\n\n\n\n\n\n\n\n\n\n4.4.2 Validation Set\n\n\n\n\nTable 4.16: Evaluation Metrics on Validation Set Model, SMOTE-Random Forest, Optimal Set\n\n\n\n\n \n\n\nHistotypes\n\n  \n    Metric \n    Overall \n    HGSC \n    CCOC \n    ENOC \n    LGSC \n    MUC \n  \n \n\n  \n    Accuracy \n    0.890 \n    0.907 \n    0.971 \n    0.952 \n    0.972 \n    0.979 \n  \n  \n    Sensitivity \n    0.774 \n    0.926 \n    0.937 \n    0.714 \n    0.444 \n    0.846 \n  \n  \n    Specificity \n    0.955 \n    0.851 \n    0.974 \n    0.984 \n    0.983 \n    0.983 \n  \n  \n    F1-Score \n    0.731 \n    0.937 \n    0.851 \n    0.777 \n    0.390 \n    0.698 \n  \n  \n    Balanced Accuracy \n    0.864 \n    0.889 \n    0.955 \n    0.849 \n    0.714 \n    0.914 \n  \n  \n    Kappa \n    0.748 \n    0.761 \n    0.835 \n    0.750 \n    0.376 \n    0.688 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.16: Confusion Matrix for Validation Set Model\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.17: ROC Curves for SMOTE-Random Forest, Optimal Set Model in Validation Set\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.18: Subtype Prediction Summary among Predicted HGSC Samples",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "rsf/references.html",
    "href": "rsf/references.html",
    "title": "References",
    "section": "",
    "text": "Talhouk, Aline, Stefan Kommoss, Robertson Mackenzie, Martin Cheung,\nSamuel Leung, Derek S. Chiu, Steve E. Kalloger, et al. 2016.\n“Single-Patient Molecular Testing with NanoString nCounter Data\nUsing a Reference-Based Strategy for Batch Effect Correction.”\nEdited by Benjamin Haibe-Kains. PLOS ONE 11 (4): e0153844. https://doi.org/10.1371/journal.pone.0153844.",
    "crumbs": [
      "References"
    ]
  }
]