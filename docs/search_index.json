[["index.html", "Ovarian Cancer Histotypes: Report of Statistical Findings Preface", " Ovarian Cancer Histotypes: Report of Statistical Findings Derek Chiu 2022-05-20 Preface This report of statistical findings describes the classification of ovarian cancer histotypes using data from NanoString CodeSets. Marina Pavanello conducted the initial exploratory data analysis, Cathy Tang implemented class imbalance techniques, Derek Chiu conducted the normalization and statistical analysis, and Lauren Tindale and Aline Talhouk are the project leads. "],["introduction.html", "1 Introduction", " 1 Introduction Ovarian cancer has five major histotypes: high-grade serous carcinoma (HGSC), low-grade serous carcinoma (LGSC), endometrioid carcinoma (ENOC), mucinous carcinoma (MUC), and clear cell carcinoma (CCOC). A common problem with classifying these histotypes is that there is a class imbalance issue. HGSC dominates the distribution, commonly accounting for 70% of cases in many patient cohorts, while the other four histotypes are spread over the rest of the cases. Subsampling methods like up-sampling, down-sampling, and SMOTE can be used to mitigate this problem. The supervised learning is performed under a consensus framework: we consider various classification algorithms and use evaluation metrics like accuracy, F1-score, Kappa, and G-mean to inform the decision of which methods to carry forward for prediction in confirmation and validation sets. "],["methods.html", "2 Methods", " 2 Methods We use 5 classification algorithms and 4 subsampling methods across 500 repetitions in the supervised learning framework for the Training Set, CS1 and CS2. The pipeline was run using SLURM batch jobs submitted to a partition on a CentOS 7 server. Implementations of the techniques below were called from the splendid package. Classifiers: Random Forest SVM Adaboost Multinomial Regression Model with Ridge Penalty Multinomial Regression Model with LASSO Penalty Subsampling: None Down-sampling Up-sampling SMOTE "],["distributions.html", "3 Distributions 3.1 Full Data 3.2 Training Set 3.3 Common Samples 3.4 Histotypes in Classifier Data", " 3 Distributions 3.1 Full Data The histotype distributions on the full data are shown below. Table 3.1: All CodeSet Histotype Groups Histotype Group CS1 CS2 CS3 HGSC 123 646 1644 non-HGSC 162 219 587 Table 3.2: All CodeSet Major Reviewed Histotypes Reviewed Histotype CS1 CS2 CS3 CS1 % CS2 % CS3 % CCOC 48 60 172 18.0 7.3 8.0 ENOC 60 33 237 22.6 4.0 11.0 HGSC 123 646 1644 46.2 78.7 76.0 LGSC 19 21 40 7.1 2.6 1.9 MUC 16 61 69 6.0 7.4 3.2 Table 3.3: All CodeSet Reviewed Histotypes Reviewed Histotype CS1 CS2 CS3 CARCINOMA-NOS 0 1 23 CCOC 48 60 172 CTRL 0 12 0 ENOC 60 33 237 HGSC 123 646 1644 LGSC 19 21 40 MBOT 0 19 3 MIXED (ENOC/CCOC) 0 0 1 MIXED (ENOC/LGSC) 0 0 1 MIXED (HGSC/CCOC) 0 0 1 MMMT 0 0 29 MUC 16 61 69 Other/Exclude 0 0 8 SBOT 19 12 2 serous LMP 0 0 1 Table 3.4: CS1 Histotypes CodeSet Reviewed Histotype n CS1 CCOC 48 CS1 ENOC 60 CS1 HGSC 123 CS1 LGSC 19 CS1 MUC 16 CS1 SBOT 19 Table 3.5: CS2 Histotypes CodeSet Reviewed Histotype n CS2 CARCINOMA-NOS 1 CS2 CCOC 60 CS2 CTRL 12 CS2 ENOC 33 CS2 HGSC 646 CS2 LGSC 21 CS2 MBOT 19 CS2 MUC 61 CS2 SBOT 12 Table 3.6: CS3 Histotypes CodeSet Reviewed Histotype n CS3 CARCINOMA-NOS 23 CS3 CCOC 172 CS3 ENOC 237 CS3 HGSC 1644 CS3 LGSC 40 CS3 MBOT 3 CS3 MIXED (ENOC/CCOC) 1 CS3 MIXED (ENOC/LGSC) 1 CS3 MIXED (HGSC/CCOC) 1 CS3 MMMT 29 CS3 MUC 69 CS3 Other/Exclude 8 CS3 SBOT 2 CS3 serous LMP 1 Table 3.7: Common Summary ID CodeSet Histotypes Reviewed Histotype CS1 CS2 CS3 CCOC 3 4 9 ENOC 4 4 9 HGSC 57 62 94 LGSC 7 5 8 MUC 7 5 11 3.2 Training Set The training set distributions for CS1 and CS2 are shown below. Table 3.8: CS1 Training Set Histotypes Histotype n % CCC 57 18.8% ENOCa 59 19.4% HGSC 156 51.3% LGSC 16 5.3% MUC 16 5.3% Table 3.9: CS2 Training Set Histotypes Histotype n % CCOC 68 7.2% ENOC 30 3.2% HGSC 757 80.1% LGSC 29 3.1% MUC 61 6.5% 3.3 Common Samples Table 3.10: All Common Samples Histotype Distribution revHist CS1 CS2 CS3 CCOC 3 4 3 ENOC 4 4 3 HGSC 55 58 70 LGSC 7 5 4 MUC 7 5 5 Table 3.11: Distinct Common Samples Histotype Distribution revHist CS1 CS2 CS3 CCOC 3 3 3 ENOC 3 3 3 HGSC 53 53 53 LGSC 4 4 4 MUC 5 5 5 Table 3.12: Distinct Common CS2 and CS3 Samples Histotype Distribution revHist CS2 CS3 CCOC 3 3 ENOC 3 3 HGSC 71 71 LGSC 4 4 MUC 5 5 Table 3.13: Common Samples Across Sites Histotype Distribution revHist AOC USC Vancouver CCOC 3 3 3 ENOC 3 3 3 HGSC 13 13 26 LGSC 2 2 2 MUC 3 3 3 Table 3.14: Distinct Common Samples Across Sites Histotype Distribution revHist AOC USC Vancouver CCOC 3 3 3 ENOC 3 3 3 HGSC 13 13 13 LGSC 2 2 2 MUC 3 3 3 Table 3.15: CS3/CS4/CS5 Common Samples Histotype Distribution revHist CS3 CS4 CS5 HGSC 46 46 46 NA 26 26 26 Table 3.16: CS3/CS4/CS5 Pools Distribution Pool CS3 CS4 CS5 Pool1 12 5 4 Pool2 5 5 4 Pool3 5 5 4 Pool4 NA 2 1 Pool5 NA 2 1 Pool6 NA 2 0 Pool7 NA 2 1 Pool8 NA 2 1 Pool9 NA 2 1 Pool10 NA 2 1 Pool11 NA 2 1 3.4 Histotypes in Classifier Data Table 3.17: Full Training Set Histotype Distribution by CodeSet Variable Levels CS1 CS2 CS3 Total Histotype HGSC 119 (49%) 625 (80%) 474 (94%) 1218 (80%) CCOC 44 (18%) 53 (7%) 8 (2%) 105 (7%) ENOC 55 (23%) 28 (4%) 8 (2%) 91 (6%) MUC 12 (5%) 58 (7%) 9 (2%) 79 (5%) LGSC 13 (5%) 19 (2%) 6 (1%) 38 (2%) Total N (%) 243 (16%) 783 (51%) 505 (33%) 1531 (100%) Table 3.18: Histotype Distribution by CodeSet/Datasets Variable Levels CS1 All CS2 All Confirmation Validation Histotype HGSC 122 (47%) 645 (79%) 422 (66%) 675 (74%) CCOC 47 (18%) 59 (7%) 74 (12%) 79 (9%) ENOC 58 (22%) 31 (4%) 106 (17%) 113 (12%) MUC 15 (6%) 60 (7%) 27 (4%) 26 (3%) LGSC 17 (7%) 20 (2%) 13 (2%) 18 (2%) Total N (%) 259 (10%) 815 (31%) 642 (24%) 911 (35%) "],["results.html", "4 Results 4.1 Training Set 4.2 Two-Step Training Set 4.3 CS1 Set 4.4 CS2 Set 4.5 SMOTE Kappa Summary 4.6 Overlap with SPOT 4.7 Rank Aggregation 4.8 Test Set Performance", " 4 Results We show internal validation summaries for the combined classifier training set, as well as the CS1 and CS2 sets with duplicates included. The F1-scores, kappa, and G-mean are the measures of interest. Algorithms are sorted by descending value based on the overallaccuracy of the training set. The point ranges show the median, 5th and 95th percentiles, coloured by subsampling methods. 4.1 Training Set 4.1.1 Accuracy Figure 4.1: Training Set Accuracy Table 4.1: Training Set Accuracy by Algorithm and Subsampling Method sampling rf svm adaboost mlr_ridge mlr_lasso none 0.937 0.942 0.926 0.939 0.936 up 0.942 0.94 0.945 0.899 0.907 down 0.877 0.873 0.869 0.858 0.835 smote 0.944 0.936 0.935 0.914 0.91 Figure 4.2: Training Set Class-Specific Accuracy Table 4.2: Training Set Class-Specific Accuracy by Algorithm and Subsampling Method sampling histotype rf svm adaboost mlr_ridge mlr_lasso none CCOC 0.984 0.982 0.982 0.984 0.982 none ENOC 0.972 0.975 0.969 0.973 0.97 none HGSC 0.951 0.955 0.937 0.953 0.954 none LGSC 0.981 0.984 0.977 0.979 0.98 none MUC 0.987 0.988 0.986 0.989 0.986 up CCOC 0.984 0.979 0.984 0.978 0.971 up ENOC 0.976 0.973 0.973 0.955 0.953 up HGSC 0.956 0.953 0.962 0.919 0.933 up LGSC 0.984 0.988 0.986 0.963 0.977 up MUC 0.988 0.988 0.986 0.985 0.982 down CCOC 0.978 0.968 0.977 0.976 0.972 down ENOC 0.95 0.946 0.944 0.945 0.94 down HGSC 0.899 0.897 0.894 0.881 0.862 down LGSC 0.954 0.961 0.954 0.937 0.925 down MUC 0.978 0.98 0.973 0.982 0.977 smote CCOC 0.982 0.978 0.981 0.979 0.975 smote ENOC 0.972 0.97 0.968 0.963 0.956 smote HGSC 0.963 0.952 0.955 0.934 0.933 smote LGSC 0.987 0.986 0.984 0.968 0.972 smote MUC 0.984 0.987 0.982 0.986 0.984 4.1.2 F1-Score Figure 4.3: Training Set F1-Score Table 4.3: Training Set Macro-Averaged F1-Score by Algorithm and Subsampling Method sampling rf svm adaboost mlr_ridge mlr_lasso none 0.763 0.827 0.725 0.772 0.783 up 0.804 0.827 0.829 0.772 0.765 down 0.736 0.731 0.722 0.723 0.69 smote 0.835 0.824 0.817 0.788 0.775 Figure 4.4: Training Set Class-Specific F1-Score Table 4.4: Training Set Class-Specific F1-Score by Algorithm and Subsampling Method sampling histotype rf svm adaboost mlr_ridge mlr_lasso none CCOC 0.873 0.857 0.857 0.871 0.862 none ENOC 0.733 0.776 0.679 0.758 0.737 none HGSC 0.97 0.972 0.962 0.971 0.972 none LGSC 0.375 0.667 0.182 0.381 0.5 none MUC 0.868 0.875 0.852 0.887 0.857 up CCOC 0.868 0.831 0.87 0.842 0.795 up ENOC 0.772 0.75 0.769 0.675 0.636 up HGSC 0.973 0.971 0.977 0.947 0.957 up LGSC 0.538 0.72 0.667 0.542 0.621 up MUC 0.877 0.867 0.862 0.853 0.825 down CCOC 0.842 0.782 0.833 0.826 0.804 down ENOC 0.657 0.632 0.619 0.629 0.602 down HGSC 0.934 0.931 0.93 0.92 0.906 down LGSC 0.476 0.522 0.473 0.407 0.364 down MUC 0.8 0.808 0.768 0.828 0.791 smote CCOC 0.87 0.831 0.857 0.847 0.827 smote ENOC 0.767 0.754 0.735 0.714 0.667 smote HGSC 0.976 0.97 0.972 0.958 0.957 smote LGSC 0.727 0.714 0.703 0.571 0.588 smote MUC 0.848 0.868 0.833 0.863 0.841 4.1.3 Kappa Figure 4.5: Training Set Kappa Table 4.5: Training Set Kappa by Algorithm and Subsampling Method sampling rf svm adaboost mlr_ridge mlr_lasso none 0.805 0.828 0.758 0.813 0.811 up 0.823 0.817 0.84 0.75 0.754 down 0.705 0.694 0.689 0.671 0.632 smote 0.84 0.816 0.819 0.778 0.765 Figure 4.6: Training Set Class-Specific Kappa Table 4.6: Training Set Class-Specific Kappa by Algorithm and Subsampling Method sampling histotype rf svm adaboost mlr_ridge mlr_lasso none CCOC 0.864 0.847 0.848 0.861 0.853 none ENOC 0.719 0.763 0.663 0.743 0.721 none HGSC 0.834 0.855 0.781 0.845 0.854 none LGSC 0.37 0.658 0.13 0.371 0.49 none MUC 0.861 0.87 0.845 0.88 0.852 up CCOC 0.86 0.82 0.861 0.83 0.779 up ENOC 0.759 0.737 0.754 0.651 0.613 up HGSC 0.851 0.847 0.882 0.778 0.803 up LGSC 0.529 0.714 0.662 0.525 0.611 up MUC 0.871 0.859 0.855 0.845 0.815 down CCOC 0.831 0.764 0.822 0.813 0.787 down ENOC 0.629 0.604 0.589 0.599 0.57 down HGSC 0.732 0.721 0.718 0.689 0.654 down LGSC 0.459 0.506 0.451 0.384 0.34 down MUC 0.786 0.798 0.753 0.817 0.78 smote CCOC 0.861 0.82 0.848 0.835 0.814 smote ENOC 0.751 0.74 0.718 0.695 0.647 smote HGSC 0.885 0.848 0.864 0.812 0.806 smote LGSC 0.72 0.707 0.693 0.555 0.572 smote MUC 0.839 0.861 0.825 0.856 0.833 4.1.4 G-mean Figure 4.7: Training Set G-mean Table 4.7: Training Set G-mean by Algorithm and Subsampling Method sampling rf svm adaboost mlr_ridge mlr_lasso none 0.639 0.79 0.482 0.672 0.725 up 0.719 0.776 0.805 0.875 0.806 down 0.859 0.85 0.848 0.863 0.84 smote 0.837 0.808 0.839 0.866 0.843 Figure 4.8: Training Set Class-Specific G-mean Table 4.8: Training Set Class-Specific G-mean by Algorithm and Subsampling Method sampling histotype rf svm adaboost mlr_ridge mlr_lasso none CCOC 0.903 0.899 0.887 0.908 0.913 none ENOC 0.806 0.853 0.75 0.841 0.83 none HGSC 0.879 0.91 0.836 0.895 0.909 none LGSC 0.499 0.796 0.267 0.521 0.645 none MUC 0.922 0.914 0.906 0.932 0.922 up CCOC 0.898 0.871 0.909 0.925 0.893 up ENOC 0.837 0.831 0.87 0.879 0.825 up HGSC 0.892 0.895 0.932 0.934 0.922 up LGSC 0.632 0.815 0.792 0.944 0.874 up MUC 0.924 0.901 0.935 0.943 0.91 down CCOC 0.923 0.912 0.917 0.917 0.914 down ENOC 0.883 0.877 0.862 0.88 0.857 down HGSC 0.921 0.916 0.918 0.91 0.898 down LGSC 0.921 0.932 0.918 0.937 0.919 down MUC 0.927 0.914 0.928 0.934 0.919 smote CCOC 0.924 0.888 0.919 0.924 0.919 smote ENOC 0.878 0.865 0.866 0.879 0.853 smote HGSC 0.944 0.915 0.942 0.938 0.933 smote LGSC 0.85 0.85 0.875 0.932 0.905 smote MUC 0.93 0.909 0.931 0.935 0.926 4.2 Two-Step Training Set 4.2.1 Accuracy Figure 4.9: Training Set Step 1 Accuracy Figure 4.10: Training Set Step 2 Accuracy Table 4.9: Training Set Step 1 Accuracy by Algorithm and Subsampling Method sampling rf svm adaboost mlr_ridge mlr_lasso none 0.959 0.957 0.951 0.948 0.947 up 0.958 0.957 0.957 0.939 0.936 down 0.944 0.943 0.941 0.935 0.93 smote 0.957 0.955 0.952 0.945 0.942 Table 4.10: Training Set Step 2 Accuracy by Algorithm and Subsampling Method sampling rf svm mlr_ridge adaboost mlr_lasso none 0.889 0.881 0.882 0.884 0.872 up 0.89 0.879 0.878 0.881 0.868 down 0.87 0.869 0.867 0.857 0.855 smote 0.883 0.88 0.877 0.875 0.87 Figure 4.11: Training Set Step 1 Class-Specific Accuracy Figure 4.12: Training Set Step 2 Class-Specific Accuracy Table 4.11: Training Set Step 1 Class-Specific Accuracy by Algorithm and Subsampling Method sampling histotype rf svm mlr_ridge adaboost mlr_lasso none HGSC 0.959 0.957 0.948 0.951 0.947 none non-HGSC 0.959 0.957 0.948 0.951 0.947 up HGSC 0.958 0.957 0.939 0.957 0.936 up non-HGSC 0.958 0.957 0.939 0.957 0.936 down HGSC 0.944 0.943 0.935 0.941 0.93 down non-HGSC 0.944 0.943 0.935 0.941 0.93 smote HGSC 0.957 0.955 0.945 0.952 0.942 smote non-HGSC 0.957 0.955 0.945 0.952 0.942 Table 4.12: Training Set Step 2 Class-Specific Accuracy by Algorithm and Subsampling Method sampling histotype rf svm mlr_ridge adaboost mlr_lasso none CCOC 0.95 0.929 0.932 0.949 0.93 none ENOC 0.908 0.91 0.9 0.902 0.897 none LGSC 0.973 0.983 0.978 0.974 0.967 none MUC 0.95 0.943 0.957 0.946 0.945 up CCOC 0.949 0.928 0.932 0.947 0.93 up ENOC 0.91 0.909 0.901 0.903 0.897 up LGSC 0.973 0.982 0.973 0.973 0.966 up MUC 0.949 0.943 0.955 0.944 0.941 down CCOC 0.939 0.92 0.93 0.936 0.932 down ENOC 0.899 0.897 0.897 0.887 0.891 down LGSC 0.966 0.982 0.965 0.967 0.964 down MUC 0.938 0.938 0.946 0.925 0.926 smote CCOC 0.946 0.927 0.932 0.94 0.933 smote ENOC 0.908 0.907 0.902 0.896 0.898 smote LGSC 0.972 0.982 0.967 0.973 0.966 smote MUC 0.948 0.942 0.955 0.941 0.942 4.2.2 F1-Score Figure 4.13: Training Set Step 1 F1-Score Figure 4.14: Training Set Step 2 F1-Score Table 4.13: Training Set Step 1 Macro-Averaged F1-Score by Algorithm and Subsampling Method sampling rf svm mlr_ridge adaboost mlr_lasso none 0.975 0.973 0.968 0.97 0.967 up 0.974 0.973 0.961 0.973 0.959 down 0.964 0.963 0.958 0.962 0.955 smote 0.973 0.972 0.965 0.97 0.963 Table 4.14: Training Set Step 2 Macro-Averaged F1-Score by Algorithm and Subsampling Method sampling rf svm mlr_ridge adaboost mlr_lasso none 0.887 0.886 0.886 0.884 0.87 up 0.886 0.885 0.879 0.879 0.867 down 0.868 0.875 0.867 0.859 0.852 smote 0.881 0.884 0.876 0.874 0.868 Figure 4.15: Training Set Step 1 Class-Specific F1-Score Figure 4.16: Training Set Step 2 Class-Specific F1-Score 4.2.3 Kappa Figure 4.17: Training Set Step 1 Kappa Figure 4.18: Training Set Step 2 Kappa Table 4.15: Training Set Step 1 Kappa by Algorithm and Subsampling Method sampling rf svm mlr_ridge adaboost mlr_lasso none 0.868 0.866 0.836 0.839 0.833 up 0.865 0.865 0.82 0.866 0.811 down 0.834 0.834 0.81 0.826 0.798 smote 0.867 0.862 0.832 0.851 0.826 Table 4.16: Training Set Step 2 Kappa by Algorithm and Subsampling Method sampling rf svm mlr_ridge adaboost mlr_lasso none 0.847 0.835 0.837 0.841 0.822 up 0.848 0.832 0.833 0.836 0.818 down 0.821 0.819 0.817 0.803 0.8 smote 0.839 0.834 0.83 0.827 0.821 Figure 4.19: Training Set Step 1 Class-Specific Kappa Figure 4.20: Training Set Step 2 Class-Specific Kappa Table 4.17: Training Set Step 1 Class-Specific Kappa by Algorithm and Subsampling Method sampling histotype rf svm mlr_ridge adaboost mlr_lasso none HGSC 0.868 0.866 0.836 0.839 0.833 none non-HGSC 0.868 0.866 0.836 0.839 0.833 up HGSC 0.865 0.865 0.82 0.866 0.811 up non-HGSC 0.865 0.865 0.82 0.866 0.811 down HGSC 0.834 0.834 0.81 0.826 0.798 down non-HGSC 0.834 0.834 0.81 0.826 0.798 smote HGSC 0.867 0.862 0.832 0.851 0.826 smote non-HGSC 0.867 0.862 0.832 0.851 0.826 Table 4.18: Training Set Step 2 Class-Specific Kappa by Algorithm and Subsampling Method sampling histotype rf svm mlr_ridge adaboost mlr_lasso none CCOC 0.887 0.841 0.849 0.885 0.844 none ENOC 0.777 0.78 0.762 0.762 0.75 none LGSC 0.867 0.919 0.899 0.881 0.855 none MUC 0.865 0.844 0.884 0.854 0.852 up CCOC 0.885 0.84 0.847 0.879 0.841 up ENOC 0.783 0.78 0.761 0.767 0.747 up LGSC 0.866 0.913 0.867 0.874 0.851 up MUC 0.863 0.842 0.877 0.847 0.844 down CCOC 0.863 0.82 0.84 0.851 0.845 down ENOC 0.755 0.754 0.749 0.728 0.734 down LGSC 0.854 0.913 0.847 0.863 0.832 down MUC 0.833 0.829 0.855 0.803 0.803 smote CCOC 0.878 0.837 0.844 0.863 0.849 smote ENOC 0.78 0.778 0.763 0.75 0.753 smote LGSC 0.864 0.913 0.861 0.866 0.848 smote MUC 0.857 0.842 0.879 0.845 0.849 4.2.4 G-mean Figure 4.21: Training Set Step 1 G-mean Figure 4.22: Training Set Step 2 G-mean Table 4.19: Training Set Step 1 G-mean by Algorithm and Subsampling Method sampling rf svm mlr_ridge adaboost mlr_lasso none 0.915 0.927 0.903 0.89 0.903 up 0.913 0.921 0.929 0.926 0.924 down 0.935 0.938 0.929 0.931 0.927 smote 0.929 0.926 0.92 0.921 0.919 Table 4.20: Training Set Step 2 G-mean by Algorithm and Subsampling Method sampling rf svm mlr_ridge adaboost mlr_lasso none 0.891 0.884 0.889 0.886 0.873 up 0.893 0.879 0.887 0.885 0.875 down 0.877 0.874 0.876 0.867 0.864 smote 0.89 0.881 0.885 0.879 0.877 Figure 4.23: Training Set Step 1 Class-Specific G-mean Figure 4.24: Training Set Step 2 Class-Specific G-mean Table 4.21: Training Set Step 1 Class-Specific G-mean by Algorithm and Subsampling Method sampling histotype rf svm mlr_ridge adaboost mlr_lasso none HGSC 0.915 0.927 0.903 0.89 0.903 none non-HGSC 0.915 0.927 0.903 0.89 0.903 up HGSC 0.913 0.921 0.929 0.926 0.924 up non-HGSC 0.913 0.921 0.929 0.926 0.924 down HGSC 0.935 0.938 0.929 0.931 0.927 down non-HGSC 0.935 0.938 0.929 0.931 0.927 smote HGSC 0.929 0.926 0.92 0.921 0.919 smote non-HGSC 0.929 0.926 0.92 0.921 0.919 Table 4.22: Training Set Step 2 Class-Specific G-mean by Algorithm and Subsampling Method sampling histotype rf svm mlr_ridge adaboost mlr_lasso none CCOC 0.941 0.926 0.921 0.942 0.919 none ENOC 0.893 0.889 0.884 0.885 0.875 none LGSC 0.95 0.959 0.956 0.948 0.939 none MUC 0.925 0.913 0.939 0.922 0.929 up CCOC 0.939 0.926 0.917 0.934 0.916 up ENOC 0.896 0.892 0.883 0.889 0.869 up LGSC 0.951 0.956 0.959 0.95 0.951 up MUC 0.924 0.909 0.934 0.917 0.926 down CCOC 0.923 0.912 0.911 0.918 0.916 down ENOC 0.879 0.88 0.875 0.86 0.863 down LGSC 0.953 0.961 0.957 0.956 0.956 down MUC 0.912 0.904 0.926 0.904 0.902 smote CCOC 0.933 0.92 0.915 0.922 0.919 smote ENOC 0.892 0.892 0.883 0.877 0.873 smote LGSC 0.952 0.957 0.956 0.952 0.952 smote MUC 0.924 0.914 0.938 0.924 0.929 4.3 CS1 Set 4.3.1 Accuracy Figure 4.25: CS1 Set Accuracy Table 4.23: CS1 Set Accuracy by Algorithm and Subsampling Method sampling rf svm mlr_ridge adaboost mlr_lasso none 0.838 0.852 0.845 0.813 0.832 up 0.862 0.843 0.842 0.844 0.826 down 0.809 0.811 0.783 0.773 0.764 smote 0.856 0.842 0.837 0.842 0.823 Figure 4.26: CS1 Set Class-Specific Accuracy Table 4.24: CS1 Set Class-Specific Accuracy by Algorithm and Subsampling Method sampling histotype rf svm mlr_ridge adaboost mlr_lasso none CCOC 0.941 0.939 0.936 0.937 0.935 none ENOC 0.897 0.909 0.897 0.895 0.895 none HGSC 0.907 0.908 0.91 0.883 0.899 none LGSC 0.958 0.978 0.969 0.947 0.959 none MUC 0.978 0.978 0.98 0.971 0.98 up CCOC 0.943 0.937 0.93 0.94 0.918 up ENOC 0.906 0.901 0.898 0.898 0.879 up HGSC 0.926 0.903 0.911 0.912 0.907 up LGSC 0.969 0.979 0.968 0.967 0.967 up MUC 0.98 0.978 0.979 0.979 0.98 down CCOC 0.936 0.933 0.939 0.929 0.925 down ENOC 0.883 0.882 0.88 0.865 0.868 down HGSC 0.885 0.879 0.859 0.862 0.854 down LGSC 0.943 0.966 0.922 0.929 0.923 down MUC 0.978 0.971 0.971 0.97 0.968 smote CCOC 0.941 0.937 0.932 0.939 0.927 smote ENOC 0.896 0.899 0.896 0.89 0.888 smote HGSC 0.925 0.904 0.906 0.915 0.898 smote LGSC 0.969 0.978 0.968 0.969 0.959 smote MUC 0.979 0.977 0.979 0.978 0.979 4.3.2 F1-Score Figure 4.27: CS1 Set F1-Score Table 4.25: CS1 Set Macro-Averaged F1-Score by Algorithm and Subsampling Method sampling rf svm mlr_ridge adaboost mlr_lasso none 0.76 0.812 0.806 0.725 0.784 up 0.812 0.8 0.809 0.791 0.793 down 0.771 0.775 0.752 0.734 0.723 smote 0.818 0.797 0.808 0.807 0.794 Figure 4.28: CS1 Set Class-Specific F1-Score Table 4.26: CS1 Set Class-Specific F1-Score by Algorithm and Subsampling Method sampling histotype rf svm mlr_ridge adaboost mlr_lasso none CCOC 0.828 0.824 0.819 0.821 0.813 none ENOC 0.779 0.791 0.769 0.762 0.766 none HGSC 0.907 0.905 0.907 0.887 0.897 none LGSC 0.545 0.8 0.727 0.4 0.667 none MUC 0.769 0.769 0.8 0.667 0.8 up CCOC 0.839 0.812 0.811 0.829 0.774 up ENOC 0.792 0.777 0.766 0.773 0.739 up HGSC 0.925 0.903 0.903 0.911 0.9 up LGSC 0.714 0.8 0.778 0.667 0.75 up MUC 0.833 0.75 0.8 0.8 0.8 down CCOC 0.824 0.812 0.828 0.811 0.791 down ENOC 0.75 0.75 0.744 0.699 0.711 down HGSC 0.87 0.866 0.833 0.841 0.829 down LGSC 0.667 0.75 0.6 0.615 0.586 down MUC 0.8 0.75 0.75 0.75 0.727 smote CCOC 0.833 0.824 0.812 0.831 0.8 smote ENOC 0.783 0.783 0.769 0.768 0.756 smote HGSC 0.92 0.901 0.897 0.909 0.886 smote LGSC 0.75 0.8 0.769 0.75 0.714 smote MUC 0.8 0.727 0.8 0.8 0.8 4.3.3 Kappa Figure 4.29: CS1 Set Kappa Table 4.27: CS1 Set Kappa by Algorithm and Subsampling Method sampling rf svm mlr_ridge adaboost mlr_lasso none 0.755 0.78 0.767 0.714 0.752 up 0.796 0.763 0.77 0.768 0.748 down 0.731 0.73 0.702 0.682 0.67 smote 0.789 0.767 0.765 0.769 0.747 Figure 4.30: CS1 Set Class-Specific Kappa Table 4.28: CS1 Set Class-Specific Kappa by Algorithm and Subsampling Method sampling histotype rf svm mlr_ridge adaboost mlr_lasso none CCOC 0.794 0.787 0.777 0.782 0.775 none ENOC 0.71 0.733 0.701 0.695 0.697 none HGSC 0.814 0.815 0.819 0.767 0.798 none LGSC 0.521 0.789 0.712 0.311 0.64 none MUC 0.753 0.752 0.795 0.657 0.795 up CCOC 0.804 0.775 0.767 0.795 0.72 up ENOC 0.733 0.713 0.699 0.708 0.659 up HGSC 0.852 0.807 0.82 0.824 0.813 up LGSC 0.693 0.795 0.756 0.651 0.728 up MUC 0.823 0.738 0.79 0.79 0.795 down CCOC 0.785 0.771 0.794 0.763 0.747 down ENOC 0.671 0.672 0.667 0.611 0.621 down HGSC 0.767 0.756 0.713 0.722 0.702 down LGSC 0.627 0.727 0.56 0.572 0.542 down MUC 0.788 0.739 0.74 0.739 0.711 smote CCOC 0.798 0.785 0.769 0.794 0.754 smote ENOC 0.712 0.714 0.699 0.696 0.681 smote HGSC 0.849 0.809 0.81 0.828 0.794 smote LGSC 0.74 0.784 0.754 0.74 0.694 smote MUC 0.79 0.71 0.789 0.788 0.79 4.3.4 G-mean Figure 4.31: CS1 Set G-mean Table 4.29: CS1 Set G-mean by Algorithm and Subsampling Method sampling rf svm mlr_ridge adaboost mlr_lasso none 0.67 0.769 0.761 0.555 0.742 up 0.766 0.741 0.818 0.741 0.798 down 0.811 0.786 0.807 0.785 0.773 smote 0.806 0.751 0.819 0.795 0.806 Figure 4.32: CS1 Set Class-Specific G-mean Table 4.30: CS1 Set Class-Specific G-mean by Algorithm and Subsampling Method sampling histotype rf svm mlr_ridge adaboost mlr_lasso none CCOC 0.888 0.885 0.883 0.876 0.882 none ENOC 0.859 0.862 0.845 0.838 0.846 none HGSC 0.908 0.909 0.91 0.883 0.899 none LGSC 0.612 0.845 0.786 0.446 0.745 none MUC 0.816 0.816 0.866 0.77 0.866 up CCOC 0.891 0.882 0.889 0.888 0.87 up ENOC 0.869 0.845 0.844 0.851 0.828 up HGSC 0.927 0.905 0.908 0.913 0.905 up LGSC 0.756 0.841 0.925 0.707 0.907 up MUC 0.889 0.775 0.889 0.866 0.882 down CCOC 0.899 0.882 0.899 0.89 0.878 down ENOC 0.837 0.847 0.838 0.802 0.813 down HGSC 0.878 0.874 0.846 0.853 0.842 down LGSC 0.908 0.907 0.938 0.909 0.882 down MUC 0.894 0.861 0.884 0.888 0.886 smote CCOC 0.896 0.891 0.895 0.897 0.885 smote ENOC 0.875 0.861 0.856 0.859 0.845 smote HGSC 0.923 0.905 0.902 0.913 0.894 smote LGSC 0.859 0.816 0.915 0.856 0.897 smote MUC 0.889 0.775 0.889 0.883 0.89 4.4 CS2 Set 4.4.1 Accuracy Figure 4.33: CS2 Set Accuracy Table 4.31: CS2 Set Accuracy by Algorithm and Subsampling Method sampling rf svm mlr_ridge adaboost mlr_lasso none 0.924 0.926 0.936 0.908 0.928 up 0.927 0.925 0.919 0.931 0.92 down 0.857 0.844 0.812 0.841 0.814 smote 0.925 0.922 0.912 0.923 0.899 Figure 4.34: CS2 Set Class-Specific Accuracy Table 4.32: CS2 Set Class-Specific Accuracy by Algorithm and Subsampling Method sampling histotype rf svm mlr_ridge adaboost mlr_lasso none CCOC 0.986 0.983 0.987 0.983 0.984 none ENOC 0.973 0.98 0.977 0.966 0.974 none HGSC 0.93 0.936 0.949 0.911 0.944 none LGSC 0.977 0.976 0.977 0.976 0.975 none MUC 0.983 0.979 0.983 0.981 0.98 up CCOC 0.986 0.981 0.987 0.986 0.984 up ENOC 0.977 0.98 0.967 0.979 0.967 up HGSC 0.931 0.933 0.938 0.941 0.939 up LGSC 0.977 0.979 0.971 0.977 0.971 up MUC 0.983 0.98 0.977 0.98 0.977 down CCOC 0.98 0.959 0.976 0.979 0.97 down ENOC 0.958 0.955 0.951 0.957 0.943 down HGSC 0.878 0.869 0.839 0.865 0.843 down LGSC 0.948 0.955 0.922 0.94 0.921 down MUC 0.953 0.96 0.943 0.948 0.961 smote CCOC 0.986 0.98 0.984 0.984 0.98 smote ENOC 0.974 0.978 0.964 0.974 0.96 smote HGSC 0.94 0.933 0.931 0.939 0.922 smote LGSC 0.977 0.98 0.969 0.978 0.964 smote MUC 0.973 0.975 0.977 0.971 0.974 4.4.2 F1-Score Figure 4.35: CS2 Set F1-Score Table 4.33: CS2 Set Macro-Averaged F1-Score by Algorithm and Subsampling Method sampling rf svm mlr_ridge adaboost mlr_lasso none 0.725 0.762 0.755 0.748 0.739 up 0.722 0.752 0.773 0.739 0.757 down 0.696 0.673 0.649 0.675 0.647 smote 0.773 0.754 0.761 0.766 0.733 Figure 4.36: CS2 Set Class-Specific F1-Score Table 4.34: CS2 Set Class-Specific F1-Score by Algorithm and Subsampling Method sampling histotype rf svm mlr_ridge adaboost mlr_lasso none CCOC 0.889 0.865 0.905 0.872 0.884 none ENOC 0.5 0.7 0.667 0.267 0.615 none HGSC 0.957 0.96 0.968 0.947 0.965 none LGSC 0.25 0.462 0.4 0.268 0.375 none MUC 0.884 0.84 0.878 0.864 0.868 up CCOC 0.895 0.857 0.913 0.898 0.894 up ENOC 0.571 0.667 0.593 0.667 0.593 up HGSC 0.958 0.959 0.96 0.963 0.961 up LGSC 0.25 0.462 0.583 0.286 0.5 up MUC 0.872 0.84 0.846 0.87 0.842 down CCOC 0.872 0.76 0.84 0.857 0.8 down ENOC 0.552 0.517 0.486 0.522 0.452 down HGSC 0.918 0.911 0.888 0.908 0.892 down LGSC 0.435 0.444 0.341 0.387 0.333 down MUC 0.727 0.744 0.692 0.714 0.755 smote CCOC 0.902 0.85 0.898 0.898 0.867 smote ENOC 0.667 0.64 0.571 0.632 0.543 smote HGSC 0.962 0.959 0.955 0.961 0.949 smote LGSC 0.533 0.5 0.556 0.545 0.5 smote MUC 0.826 0.821 0.843 0.816 0.83 4.4.3 Kappa Figure 4.37: CS2 Set Kappa Table 4.35: CS2 Set Kappa by Algorithm and Subsampling Method sampling rf svm mlr_ridge adaboost mlr_lasso none 0.756 0.777 0.81 0.691 0.79 up 0.763 0.766 0.79 0.792 0.782 down 0.67 0.64 0.595 0.639 0.595 smote 0.793 0.762 0.773 0.786 0.744 Figure 4.38: CS2 Set Class-Specific Kappa Table 4.36: CS2 Set Class-Specific Kappa by Algorithm and Subsampling Method sampling histotype rf svm mlr_ridge adaboost mlr_lasso none CCOC 0.88 0.856 0.898 0.863 0.875 none ENOC 0.483 0.689 0.654 0.177 0.599 none HGSC 0.762 0.792 0.838 0.68 0.822 none LGSC 0.158 0.451 0.386 0 0.357 none MUC 0.875 0.826 0.869 0.853 0.856 up CCOC 0.888 0.844 0.905 0.889 0.885 up ENOC 0.563 0.658 0.574 0.654 0.574 up HGSC 0.764 0.773 0.822 0.805 0.816 up LGSC 0.214 0.439 0.566 0.246 0.49 up MUC 0.862 0.826 0.832 0.858 0.831 down CCOC 0.862 0.74 0.826 0.847 0.785 down ENOC 0.53 0.494 0.459 0.498 0.425 down HGSC 0.683 0.661 0.609 0.655 0.614 down LGSC 0.41 0.429 0.314 0.363 0.304 down MUC 0.703 0.725 0.664 0.688 0.731 smote CCOC 0.893 0.839 0.889 0.889 0.856 smote ENOC 0.653 0.625 0.552 0.621 0.521 smote HGSC 0.82 0.78 0.803 0.82 0.78 smote LGSC 0.522 0.494 0.542 0.539 0.486 smote MUC 0.81 0.808 0.831 0.799 0.815 4.4.4 G-mean Figure 4.39: CS2 Set G-mean Table 4.37: CS2 Set G-mean by Algorithm and Subsampling Method sampling rf svm mlr_ridge adaboost mlr_lasso none 0.169 0.683 0.648 0 0.652 up 0.496 0.643 0.828 0.572 0.764 down 0.828 0.798 0.798 0.807 0.79 smote 0.761 0.674 0.821 0.752 0.797 Figure 4.40: CS2 Set Class-Specific G-mean Table 4.38: CS2 Set Class-Specific G-mean by Algorithm and Subsampling Method sampling histotype rf svm mlr_ridge adaboost mlr_lasso none CCOC 0.911 0.892 0.934 0.888 0.924 none ENOC 0.577 0.773 0.735 0.316 0.732 none HGSC 0.827 0.864 0.891 0.764 0.89 none LGSC 0.302 0.651 0.547 0 0.574 none MUC 0.918 0.883 0.927 0.894 0.928 up CCOC 0.909 0.866 0.96 0.931 0.938 up ENOC 0.639 0.739 0.797 0.707 0.786 up HGSC 0.825 0.837 0.938 0.869 0.918 up LGSC 0.354 0.602 0.9 0.408 0.769 up MUC 0.903 0.873 0.934 0.932 0.921 down CCOC 0.958 0.937 0.929 0.947 0.919 down ENOC 0.821 0.813 0.781 0.8 0.789 down HGSC 0.903 0.888 0.878 0.892 0.877 down LGSC 0.893 0.878 0.886 0.881 0.889 down MUC 0.913 0.881 0.912 0.914 0.895 smote CCOC 0.957 0.88 0.957 0.953 0.938 smote ENOC 0.798 0.734 0.802 0.782 0.795 smote HGSC 0.919 0.857 0.931 0.915 0.92 smote LGSC 0.74 0.666 0.883 0.739 0.853 smote MUC 0.929 0.882 0.929 0.927 0.915 4.5 SMOTE Kappa Summary Figure 4.41: SMOTE Kappa by Algorithm and Dataset Table 4.39: SMOTE Kappa by Algorithm and Dataset dataset rf svm mlr_ridge adaboost mlr_lasso Training 0.84 0.816 0.778 0.819 0.765 CS1 0.789 0.767 0.765 0.769 0.747 CS2 0.793 0.762 0.773 0.786 0.744 Figure 4.42: SMOTE Class-Specific Kappa by Algorithm and Dataset 4.6 Overlap with SPOT There are 13 genes out of the 72 classifier set that overlap with the SPOT signature: HIF1A, CXCL10, DUSP4, SOX17, MITF, CDKN3, BRCA2, CEACAM5, ANXA4, SERPINE1, TCF7L1, CRABP2, DNAJC9. 4.7 Rank Aggregation The 44 methods (algorithm-sampling combinations) are ordered in the table by their aggregated ranks using the Genetic Algorithm. We see that the best performing methods involve the 2-stage and sequential algorithms. 4.8 Test Set Performance Now wed like to see how our best methods perform in the confirmation and validation sets. The class-specific F1-scores will be used. The top 4 methods are: sequential-none: sequential algorithm with no subsampling. The sequence of models and algorithms used are: HGSC vs. non-HGSC using SVM MUC vs. non-MUC using ridge regression CCOC vs. non-CCOC using random forest ENOC vs. LGSC using SVM 2S-rf-none: 2-step method using random forest algorithm with no subsampling 2S-rf-up: 2-step method using random forest algorithm with upsampling sequential-smote: sequential algorithm with SMOTE subsampling. The sequence of models and algorithms used are: HGSC vs. non-HGSC using random forest CCOC vs. non-CCOC using random forest MUC vs. non-MUC using SVM ENOC vs. LGSC using random forest As a comparison we also show the F1-scores from the rf-none to see how the best methods improve from it. 4.8.1 Confirmation Set Table 4.40: Class-specific F1-scores on Confirmation Sets method HGSC CCOC ENOC LGSC MUC 2S-rf-none 0.914 0.872 0.772 0.439 0.717 sequential-none 0.903 0.915 0.922 0.500 0.711 2S-rf-smote 0.903 0.871 0.749 0.392 0.691 sequential-smote 0.903 0.922 0.911 0.500 0.745 rf-none 0.901 0.879 0.553 0.133 0.760 In the confirmation set, 2S-rf-none improves drastically in LGSC classification compard to rf-none, with moderate improvement in ENOC, and minor improvement in HGSC and CCOC. There is a decrease in MUC performance. sequential-none improves on 2S-rf-none in all classes except for marginal decrease in HGSC performance. 4.8.2 Validation Set Table 4.41: Class-specific F1-scores on Validation Sets method HGSC CCOC ENOC LGSC MUC 2S-rf-none 0.940 0.946 0.892 0.811 0.764 sequential-none 0.950 0.944 0.964 0.789 0.800 2S-rf-smote 0.934 0.945 0.877 0.780 0.750 sequential-smote 0.940 0.949 0.955 0.750 0.767 rf-none 0.933 0.867 0.628 0.182 0.778 Similarly in the validation set, 2S-rf-none improves drastically in LGSC classification compared to rf-none, with large improvement in ENOC, and minor improvement in HGSC and CCOC. There is a decrease in MUC performance. sequential-none improves on 2S-rf-none in all classes except for a small decrease in CCOC performance and same performance for LGSC. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
