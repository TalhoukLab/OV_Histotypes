[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"report statistical findings describes classification ovarian cancer histotypes using data NanoString CodeSets.Marina Pavanello conducted initial exploratory data analysis, Cathy Tang implemented class imbalance techniques, Derek Chiu conducted normalization statistical analysis, Lauren Tindale Aline Talhouk project leads.","code":""},{"path":"introduction.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"Ovarian cancer five major histotypes: high-grade serous carcinoma (HGSC), low-grade serous carcinoma (LGSC), endometrioid carcinoma (ENOC), mucinous carcinoma (MUC), clear cell carcinoma (CCOC). common problem classifying histotypes class imbalance issue. HGSC dominates distribution, commonly accounting 70% cases many patient cohorts, four histotypes spread rest cases. Subsampling methods like -sampling, -sampling, SMOTE can used mitigate problem.supervised learning performed consensus framework: consider various classification algorithms use evaluation metrics like accuracy, F1-score, Kappa, G-mean inform decision methods carry forward prediction confirmation validation sets.","code":""},{"path":"methods.html","id":"methods","chapter":"2 Methods","heading":"2 Methods","text":"use 5 classification algorithms 4 subsampling methods across 500 repetitions supervised learning framework Training Set, CS1 CS2. pipeline run using SLURM batch jobs submitted partition CentOS 7 server. Implementations techniques called splendid package.Classifiers:\nRandom Forest\nSVM\nAdaboost\nMultinomial Regression Model Ridge Penalty\nMultinomial Regression Model LASSO Penalty\nClassifiers:Random ForestSVMAdaboostMultinomial Regression Model Ridge PenaltyMultinomial Regression Model LASSO PenaltySubsampling:\nNone\n-sampling\n-sampling\nSMOTE\nSubsampling:NoneDown-samplingUp-samplingSMOTE","code":""},{"path":"distributions.html","id":"distributions","chapter":"3 Distributions","heading":"3 Distributions","text":"","code":""},{"path":"distributions.html","id":"full-data","chapter":"3 Distributions","heading":"3.1 Full Data","text":"histotype distributions full data shown .Table 3.1: CodeSet Histotype GroupsTable 3.2: CodeSet Major Reviewed HistotypesTable 3.3: CodeSet Reviewed HistotypesTable 3.4: CS1 HistotypesTable 3.5: CS2 HistotypesTable 3.6: CS3 HistotypesTable 3.7: Common Summary ID CodeSet Histotypes","code":""},{"path":"distributions.html","id":"training-sets","chapter":"3 Distributions","heading":"3.2 Training Sets","text":"","code":""},{"path":"distributions.html","id":"cs1-training-set-generation","chapter":"3 Distributions","heading":"3.2.1 CS1 Training Set Generation","text":"use reference method normalize CS1 CS3.CS1 reference set: duplicate samples CS1\nSamples = 16\nGenes = 72\nCS1 reference set: duplicate samples CS1Samples = 16Genes = 72CS3 reference set: corresponding samples CS3 also found CS1 reference set\nSamples = 9\nGenes = 72\nCS3 reference set: corresponding samples CS3 also found CS1 reference setSamples = 9Genes = 72CS1 validation set: remaining CS1 samples reference set removed\nSamples = 270\nGenes = 72\nCS1 validation set: remaining CS1 samples reference set removedSamples = 270Genes = 72The final CS1 training set 251 samples 72 genes normalization keeping major histotypes interest.Table 3.8: CS1 Training Set Histotypes","code":""},{"path":"distributions.html","id":"cs2-training-set-generation","chapter":"3 Distributions","heading":"3.2.2 CS2 Training Set Generation","text":"use pool method normalize CS2 CS3 can consistent PrOType normalization available pools.CS2 pools:\nSamples = 12 (Pool 1 = 4, Pool 2 = 4, Pool 3 = 4)\nGenes = 365\nCS2 pools:Samples = 12 (Pool 1 = 4, Pool 2 = 4, Pool 3 = 4)Genes = 365CS3 pools:\nSamples = 22 (Pool 1 = 12, Pool 2 = 5, Pool 3 = 5)\nGenes = 513\nCS3 pools:Samples = 22 (Pool 1 = 12, Pool 2 = 5, Pool 3 = 5)Genes = 513CS2 validation set: CS2 samples pools removed\nSamples = 879\nGenes = 365\nCS2 validation set: CS2 samples pools removedSamples = 879Genes = 365The final CS2 training set 819 samples 136 (common) genes normalization keeping major histotypes interest.Table 3.9: CS2 Training Set Histotypes","code":""},{"path":"distributions.html","id":"common-samples","chapter":"3 Distributions","heading":"3.3 Common Samples","text":"Table 3.10: Common Samples Histotype DistributionTable 3.11: Distinct Common Samples Histotype DistributionTable 3.12: Distinct Common CS2 CS3 Samples Histotype DistributionTable 3.13: Common Samples Across Sites Histotype DistributionTable 3.14: Distinct Common Samples Across Sites Histotype DistributionTable 3.15: CS3/CS4/CS5 Common Samples Histotype DistributionTable 3.16: CS3/CS4/CS5 Pools Distribution","code":""},{"path":"distributions.html","id":"histotypes-in-classifier-data","chapter":"3 Distributions","heading":"3.4 Histotypes in Classifier Data","text":"Table 3.17: Pre-QC Training Set Histotype Distribution CodeSetTable 3.18: Full Training Set Histotype Distribution CodeSetTable 3.19: Histotype Distribution CodeSet/Datasets","code":""},{"path":"distributions.html","id":"quality-control","chapter":"3 Distributions","heading":"3.5 Quality Control","text":"","code":""},{"path":"distributions.html","id":"failed-samples","chapter":"3 Distributions","heading":"3.5.1 Failed Samples","text":"Table 3.20: Number failed sampled CodeSet","code":""},{"path":"distributions.html","id":"gd-vs.-snr","chapter":"3 Distributions","heading":"3.5.2 %GD vs. SNR","text":"\nFigure 3.1: % Genes Detected vs. Signal Noise Ratio\n\nFigure 3.2: % Genes Detected vs. Signal Noise Ratio (Zoomed)\n","code":""},{"path":"results.html","id":"results","chapter":"4 Results","heading":"4 Results","text":"show internal validation summaries combined classifier training set, well CS1 CS2 sets duplicates included. F1-scores, kappa, G-mean measures interest. Algorithms sorted descending value based overallaccuracy training set. point ranges show median, 5th 95th percentiles, coloured subsampling methods.","code":""},{"path":"results.html","id":"training-set","chapter":"4 Results","heading":"4.1 Training Set","text":"","code":""},{"path":"results.html","id":"accuracy","chapter":"4 Results","heading":"4.1.1 Accuracy","text":"\nFigure 4.1: Training Set Accuracy\n\nTable 4.1: Training Set Accuracy Algorithm Subsampling Method\n\nFigure 4.2: Training Set Class-Specific Accuracy\n\nTable 4.2: Training Set Class-Specific Accuracy Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"f1-score","chapter":"4 Results","heading":"4.1.2 F1-Score","text":"\nFigure 4.3: Training Set F1-Score\n\nTable 4.3: Training Set Macro-Averaged F1-Score Algorithm Subsampling Method\n\nFigure 4.4: Training Set Class-Specific F1-Score\n\nTable 4.4: Training Set Class-Specific F1-Score Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"kappa","chapter":"4 Results","heading":"4.1.3 Kappa","text":"\nFigure 4.5: Training Set Kappa\n\nTable 4.5: Training Set Kappa Algorithm Subsampling Method\n\nFigure 4.6: Training Set Class-Specific Kappa\n\nTable 4.6: Training Set Class-Specific Kappa Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"g-mean","chapter":"4 Results","heading":"4.1.4 G-mean","text":"\nFigure 4.7: Training Set G-mean\n\nTable 4.7: Training Set G-mean Algorithm Subsampling Method\n\nFigure 4.8: Training Set Class-Specific G-mean\n\nTable 4.8: Training Set Class-Specific G-mean Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"cs1-set","chapter":"4 Results","heading":"4.2 CS1 Set","text":"","code":""},{"path":"results.html","id":"accuracy-1","chapter":"4 Results","heading":"4.2.1 Accuracy","text":"\nFigure 4.9: CS1 Set Accuracy\n\nTable 4.9: CS1 Set Accuracy Algorithm Subsampling Method\n\nFigure 4.10: CS1 Set Class-Specific Accuracy\n\nTable 4.10: CS1 Set Class-Specific Accuracy Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"f1-score-1","chapter":"4 Results","heading":"4.2.2 F1-Score","text":"\nFigure 4.11: CS1 Set F1-Score\n\nTable 4.11: CS1 Set Macro-Averaged F1-Score Algorithm Subsampling Method\n\nFigure 4.12: CS1 Set Class-Specific F1-Score\n\nTable 4.12: CS1 Set Class-Specific F1-Score Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"kappa-1","chapter":"4 Results","heading":"4.2.3 Kappa","text":"\nFigure 4.13: CS1 Set Kappa\n\nTable 4.13: CS1 Set Kappa Algorithm Subsampling Method\n\nFigure 4.14: CS1 Set Class-Specific Kappa\n\nTable 4.14: CS1 Set Class-Specific Kappa Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"g-mean-1","chapter":"4 Results","heading":"4.2.4 G-mean","text":"\nFigure 4.15: CS1 Set G-mean\n\nTable 4.15: CS1 Set G-mean Algorithm Subsampling Method\n\nFigure 4.16: CS1 Set Class-Specific G-mean\n\nTable 4.16: CS1 Set Class-Specific G-mean Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"cs2-set","chapter":"4 Results","heading":"4.3 CS2 Set","text":"","code":""},{"path":"results.html","id":"accuracy-2","chapter":"4 Results","heading":"4.3.1 Accuracy","text":"\nFigure 4.17: CS2 Set Accuracy\n\nTable 4.17: CS2 Set Accuracy Algorithm Subsampling Method\n\nFigure 4.18: CS2 Set Class-Specific Accuracy\n\nTable 4.18: CS2 Set Class-Specific Accuracy Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"f1-score-2","chapter":"4 Results","heading":"4.3.2 F1-Score","text":"\nFigure 4.19: CS2 Set F1-Score\n\nTable 4.19: CS2 Set Macro-Averaged F1-Score Algorithm Subsampling Method\n\nFigure 4.20: CS2 Set Class-Specific F1-Score\n\nTable 4.20: CS2 Set Class-Specific F1-Score Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"kappa-2","chapter":"4 Results","heading":"4.3.3 Kappa","text":"\nFigure 4.21: CS2 Set Kappa\n\nTable 4.21: CS2 Set Kappa Algorithm Subsampling Method\n\nFigure 4.22: CS2 Set Class-Specific Kappa\n\nTable 4.22: CS2 Set Class-Specific Kappa Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"g-mean-2","chapter":"4 Results","heading":"4.3.4 G-mean","text":"\nFigure 4.23: CS2 Set G-mean\n\nTable 4.23: CS2 Set G-mean Algorithm Subsampling Method\n\nFigure 4.24: CS2 Set Class-Specific G-mean\n\nTable 4.24: CS2 Set Class-Specific G-mean Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"smote-kappa-summary","chapter":"4 Results","heading":"4.4 SMOTE Kappa Summary","text":"\nFigure 4.25: SMOTE Kappa Algorithm Dataset\n\nTable 4.25: SMOTE Kappa Algorithm Dataset\n\nFigure 4.26: SMOTE Class-Specific Kappa Algorithm Dataset\n","code":""},{"path":"results.html","id":"gene-optimization","chapter":"4 Results","heading":"4.5 Gene Optimization","text":"","code":""},{"path":"results.html","id":"overlap-with-other-sets","chapter":"4 Results","heading":"4.5.1 Overlap with Other Sets","text":"16 genes 72 common classifier set overlap PrOTYPE classifier: COL11A1, CD74, CD2, TIMP3, LUM, CYTIP, COL3A1, THBS2, TCF7L1, HMGA2, FN1, POSTN, COL1A2, COL5A2, PDZK1IP1, FBN1There 13 genes 72 classifier set overlap SPOT signature: HIF1A, CXCL10, DUSP4, SOX17, MITF, CDKN3, BRCA2, CEACAM5, ANXA4, SERPINE1, TCF7L1, CRABP2, DNAJC9.","code":""},{"path":"results.html","id":"optimal-gene-set","chapter":"4 Results","heading":"4.5.2 Optimal Gene Set","text":"28 unique genes combined PrOTYPE SPOT lists want use final classifier. incrementally add genes remaining 44 candidates based variable importance scores list recalculate performance metrics. number genes performance starts plateau may indicate optimal gene set us carry forward particular model.Variable importance calculated using either model-based approach available, SHAP-based VI score otherwise (e.g. SVM). sequential two-step classifiers, calculate overall VI scores aggregating base classifier VI scores using rank aggregation.\nFigure 4.27: Gene Optimization Sequential Classifier\nsequential classifier, use per-class median F1-scores pertaining histotype best performance retraining, sort number genes added. instance, sequence 2, look CCOC F1-scores CCOC best performance retraining HGSC removed.can observe sequence 3, F1-score stabilizes around 0.93 reach 34 genes added, hence optimal number genes used n=28+34=62. added genes : SEMA6A, GPR64, KGFLP2, BCL2, ATP5G3, C1orf173, ZBED1, PBX1, FUT3, KLK7, IGFBP1, STC1, MET, CPNE8, C10orf116, MAP1LC3A, EPAS1, SLC3A1, TPX2, TFF1, CAPN2, WT1, CYP4B1, SERPINA5, HNF1B, EGFL6, LGALS4, TSPAN8, BRCA1, LIN28B, DKK4, ADCYAP1R1, TFF3 MUC5B.\nFigure 4.28: Gene Optimization Two-Step Classifier\nSince second step classifier fits multinomial model, use macro F1-score measure analyze gene entry. two-step classifier, see Step 2, F1-score stabilizes around 0.88 reach 24 added. optimal number genes used n=28+24=52. added genes : PBX1, LGALS4, HNF1B, IGFBP1, TFF3, C10orf116, PAX8, GPR64, FUT3, CYP4B1, DKK4, GAD1, KLK7, EPAS1, CPNE8, BRCA1, ZBED1, IL6, SERPINA5, TPX2, CAPN2, TSPAN8, LIN28B SLC3A1.","code":""},{"path":"results.html","id":"rank-aggregation","chapter":"4 Results","heading":"4.6 Rank Aggregation","text":"22 methods (algorithm-sampling combinations) ordered table aggregated ranks using Genetic Algorithm. see best performing methods involve 2-stage sequential algorithms.","code":""},{"path":"results.html","id":"top-4-model-summary","chapter":"4 Results","heading":"4.7 Top 4 Model Summary","text":"","code":""},{"path":"results.html","id":"overall-metrics","chapter":"4 Results","heading":"4.7.1 Overall Metrics","text":"\nFigure 4.29: Top 4 Model Evaluation Metrics\n","code":""},{"path":"results.html","id":"per-class-metrics","chapter":"4 Results","heading":"4.7.2 Per-Class Metrics","text":"\nFigure 4.30: Top 4 Model Per-Class Evaluation Metrics\n\nFigure 4.31: Top 4 Model Per-Class F1-Scores\n","code":""},{"path":"results.html","id":"test-set-performance","chapter":"4 Results","heading":"4.8 Test Set Performance","text":"Now ’d like see best methods perform confirmation validation sets. class-specific F1-scores used.top 2 methods :sequential: sequential algorithm upsampling every step. sequence algorithms used :\nHGSC vs. non-HGSC using adaboost\nCCOC vs. non-CCOC using random forest\nENOC vs. non-ENOC using ridge regression\nMUC vs. LGSC using adaboost\nHGSC vs. non-HGSC using adaboostCCOC vs. non-CCOC using random forestENOC vs. non-ENOC using ridge regressionMUC vs. LGSC using adaboosttwo_step: two-step algorithm upsampling steps. sequence algorithms used :\nHGSC vs. non-HGSC using adaboost\nCCOC vs. ENOC vs. MUC vs. LGSC using random forest\nHGSC vs. non-HGSC using adaboostCCOC vs. ENOC vs. MUC vs. LGSC using random forestWe can test 2 additional methods using either full set genes optimal set genes methods.","code":""},{"path":"results.html","id":"confirmation-set","chapter":"4 Results","heading":"4.8.1 Confirmation Set","text":"\nTable 4.26: Class-specific F1-scores Confirmation Set Models\nconfirmation set, sequential_full sequential_optimal similar. sequential algorithms moderate improvement LGSC MUC classification. select sequential_optimal model test validation set.","code":""},{"path":"results.html","id":"validation-set","chapter":"4 Results","heading":"4.8.2 Validation Set","text":"\nTable 4.27: Class-specific F1-scores Validation Set Model\nPer-class F1-scores validation set 0.9.","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
