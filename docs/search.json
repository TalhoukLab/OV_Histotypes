[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"report statistical findings describes classification ovarian cancer histotypes using data NanoString CodeSets.Marina Pavanello conducted initial exploratory data analysis, Cathy Tang implemented class imbalance techniques, Derek Chiu conducted normalization statistical analysis, Lauren Tindale Aline Talhouk project leads.","code":""},{"path":"introduction.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"Ovarian cancer five major histotypes: high-grade serous carcinoma (HGSC), low-grade serous carcinoma (LGSC), endometrioid carcinoma (ENOC), mucinous carcinoma (MUC), clear cell carcinoma (CCOC). common problem classifying histotypes class imbalance issue. HGSC dominates distribution, commonly accounting 70% cases many patient cohorts, four histotypes spread rest cases. Subsampling methods like -sampling, -sampling, SMOTE can used mitigate problem.supervised learning performed consensus framework: consider various classification algorithms use evaluation metrics like accuracy, F1-score, Kappa, G-mean inform decision methods carry forward prediction confirmation validation sets.","code":""},{"path":"methods.html","id":"methods","chapter":"2 Methods","heading":"2 Methods","text":"","code":""},{"path":"methods.html","id":"normalization","chapter":"2 Methods","heading":"2.1 Normalization","text":"full training set comprised data CodeSet (CS) 1, 2, 3. CodeSets first normalized housekeeping genes, different approach taken CodeSets.CS1 normalized CS3 using “Random1” reference samples. reference samples common samples CS1 CS3, randomly selected obtain one five histotypes. use reference method normalize CS1 CS3.Similarly, CS2 normalized CS3 using “Random1” reference samples using five common samples CS2 CS3 one histotype.CS3, first split dataset site: Vancouver, USC, AOC. use CS3-Vancouver subset “reference standard”, normalized CS3-USC CS3-AOC CS3-Vancouver using “Random1” reference method reference samples common USC Vancouver, AOC Vancouver. CS3-Vancouver also included without normalization.","code":""},{"path":"methods.html","id":"case-selection","chapter":"2 Methods","heading":"2.2 Case Selection","text":"Duplicate cases (two samples ottaID) removed training set fitting classification models. CS3 cases preferred CS1 CS2, CS3-Vancouver preferred CS3-AOC CS3-USC.training, confirmation, validation sets used different set cohorts.","code":""},{"path":"methods.html","id":"classification","chapter":"2 Methods","heading":"2.3 Classification","text":"use 5 classification algorithms 4 subsampling methods across 500 repetitions supervised learning framework Training Set, CS1 CS2. pipeline run using SLURM batch jobs submitted partition CentOS 7 server. Implementations techniques called splendid package.Classifiers:\nRandom Forest\nSupport Vector Machine\nXGBoost\nRegularized Multinomial Regression Model\nClassifiers:Random ForestSupport Vector MachineXGBoostRegularized Multinomial Regression ModelSubsampling:\nNone\n-sampling\n-sampling\nSMOTE\nHybrid (using SMOTE -sampling)\nSubsampling:NoneDown-samplingUp-samplingSMOTEHybrid (using SMOTE -sampling)","code":""},{"path":"methods.html","id":"subsampling","chapter":"2 Methods","heading":"2.4 Subsampling","text":"specifications subsampling methods used handle class imbalance:-sampling: levels except minority class sampled frequency minority classUp-sampling: levels except majority class sampled frequency majority classSMOTE: levels except majority class synthetic data generated frequency majority classHybrid: levels except majority class synthetic data generated 50% frequency majority class, majority class sampled frequency rest.figure helps visualize distribution classes changes apply subsampling techniques handle class imbalance:\nFigure 2.1: Visualization Subsampling Techniques\n","code":""},{"path":"distributions.html","id":"distributions","chapter":"3 Distributions","heading":"3 Distributions","text":"","code":""},{"path":"distributions.html","id":"histotypes-in-classifier-data","chapter":"3 Distributions","heading":"3.1 Histotypes in Classifier Data","text":"Table 3.1: Pre-QC Training Set Histotype Distribution CodeSetTable 3.2: Full Training Set Histotype Distribution CodeSetTable 3.3: Histotype Distribution Confirmation Validation Sets","code":""},{"path":"distributions.html","id":"cohorts-in-classifier-data","chapter":"3 Distributions","heading":"3.2 Cohorts in Classifier Data","text":"Table 3.4: Cohort Distribution Training, Confirmation, Validation Sets","code":""},{"path":"distributions.html","id":"quality-control","chapter":"3 Distributions","heading":"3.3 Quality Control","text":"","code":""},{"path":"distributions.html","id":"failed-samples","chapter":"3 Distributions","heading":"3.3.1 Failed Samples","text":"Table 3.5: Number failed sampled CodeSet","code":""},{"path":"distributions.html","id":"gd-vs.-snr","chapter":"3 Distributions","heading":"3.3.2 %GD vs. SNR","text":"\nFigure 3.1: % Genes Detected vs. Signal Noise Ratio\n\nFigure 3.2: % Genes Detected vs. Signal Noise Ratio (Zoomed)\n","code":""},{"path":"distributions.html","id":"pairwise-gene-expression","chapter":"3 Distributions","heading":"3.4 Pairwise Gene Expression","text":"\nFigure 3.3: Random1-Normalized CS1 vs. CS3 Gene Expression\n\nFigure 3.4: Random1-Normalized CS2 vs. CS3 Gene Expression\n\nFigure 3.5: HKgenes-Normalized CS1 vs. CS3 Gene Expression\n\nFigure 3.6: HKgenes-Normalized CS2 vs. CS3 Gene Expression\n","code":""},{"path":"results.html","id":"results","chapter":"4 Results","heading":"4 Results","text":"show internal validation summaries combined classifier training set, well CS1 CS2 sets duplicates included. F1-scores, kappa, G-mean measures interest. Algorithms sorted descending value based overallaccuracy training set. point ranges show median, 5th 95th percentiles, coloured subsampling methods.","code":""},{"path":"results.html","id":"training-set","chapter":"4 Results","heading":"4.1 Training Set","text":"","code":""},{"path":"results.html","id":"accuracy","chapter":"4 Results","heading":"4.1.1 Accuracy","text":"\nFigure 4.1: Training Set Accuracy\n\nTable 4.1: Training Set Accuracy Algorithm Subsampling Method\n\nFigure 4.2: Training Set Class-Specific Accuracy\n\nTable 4.2: Training Set Class-Specific Accuracy Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"f1-score","chapter":"4 Results","heading":"4.1.2 F1-Score","text":"\nFigure 4.3: Training Set F1-Score\n\nTable 4.3: Training Set Macro-Averaged F1-Score Algorithm Subsampling Method\n\nFigure 4.4: Training Set Class-Specific F1-Score\n\nTable 4.4: Training Set Class-Specific F1-Score Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"kappa","chapter":"4 Results","heading":"4.1.3 Kappa","text":"\nFigure 4.5: Training Set Kappa\n\nTable 4.5: Training Set Kappa Algorithm Subsampling Method\n\nFigure 4.6: Training Set Class-Specific Kappa\n\nTable 4.6: Training Set Class-Specific Kappa Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"g-mean","chapter":"4 Results","heading":"4.1.4 G-mean","text":"\nFigure 4.7: Training Set G-mean\n\nTable 4.7: Training Set G-mean Algorithm Subsampling Method\n\nFigure 4.8: Training Set Class-Specific G-mean\n\nTable 4.8: Training Set Class-Specific G-mean Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"cs1-set","chapter":"4 Results","heading":"4.2 CS1 Set","text":"","code":""},{"path":"results.html","id":"accuracy-1","chapter":"4 Results","heading":"4.2.1 Accuracy","text":"\nFigure 4.9: CS1 Set Accuracy\n\nTable 4.9: CS1 Set Accuracy Algorithm Subsampling Method\n\nFigure 4.10: CS1 Set Class-Specific Accuracy\n\nTable 4.10: CS1 Set Class-Specific Accuracy Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"f1-score-1","chapter":"4 Results","heading":"4.2.2 F1-Score","text":"\nFigure 4.11: CS1 Set F1-Score\n\nTable 4.11: CS1 Set Macro-Averaged F1-Score Algorithm Subsampling Method\n\nFigure 4.12: CS1 Set Class-Specific F1-Score\n\nTable 4.12: CS1 Set Class-Specific F1-Score Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"kappa-1","chapter":"4 Results","heading":"4.2.3 Kappa","text":"\nFigure 4.13: CS1 Set Kappa\n\nTable 4.13: CS1 Set Kappa Algorithm Subsampling Method\n\nFigure 4.14: CS1 Set Class-Specific Kappa\n\nTable 4.14: CS1 Set Class-Specific Kappa Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"g-mean-1","chapter":"4 Results","heading":"4.2.4 G-mean","text":"\nFigure 4.15: CS1 Set G-mean\n\nTable 4.15: CS1 Set G-mean Algorithm Subsampling Method\n\nFigure 4.16: CS1 Set Class-Specific G-mean\n\nTable 4.16: CS1 Set Class-Specific G-mean Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"cs2-set","chapter":"4 Results","heading":"4.3 CS2 Set","text":"","code":""},{"path":"results.html","id":"accuracy-2","chapter":"4 Results","heading":"4.3.1 Accuracy","text":"\nFigure 4.17: CS2 Set Accuracy\n\nTable 4.17: CS2 Set Accuracy Algorithm Subsampling Method\n\nFigure 4.18: CS2 Set Class-Specific Accuracy\n\nTable 4.18: CS2 Set Class-Specific Accuracy Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"f1-score-2","chapter":"4 Results","heading":"4.3.2 F1-Score","text":"\nFigure 4.19: CS2 Set F1-Score\n\nTable 4.19: CS2 Set Macro-Averaged F1-Score Algorithm Subsampling Method\n\nFigure 4.20: CS2 Set Class-Specific F1-Score\n\nTable 4.20: CS2 Set Class-Specific F1-Score Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"kappa-2","chapter":"4 Results","heading":"4.3.3 Kappa","text":"\nFigure 4.21: CS2 Set Kappa\n\nTable 4.21: CS2 Set Kappa Algorithm Subsampling Method\n\nFigure 4.22: CS2 Set Class-Specific Kappa\n\nTable 4.22: CS2 Set Class-Specific Kappa Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"g-mean-2","chapter":"4 Results","heading":"4.3.4 G-mean","text":"\nFigure 4.23: CS2 Set G-mean\n\nTable 4.23: CS2 Set G-mean Algorithm Subsampling Method\n\nFigure 4.24: CS2 Set Class-Specific G-mean\n\nTable 4.24: CS2 Set Class-Specific G-mean Algorithm Subsampling Method\n","code":""},{"path":"results.html","id":"smote-kappa-summary","chapter":"4 Results","heading":"4.4 SMOTE Kappa Summary","text":"\nFigure 4.25: SMOTE Kappa Algorithm Dataset\n\nTable 4.25: SMOTE Kappa Algorithm Dataset\n\nFigure 4.26: SMOTE Class-Specific Kappa Algorithm Dataset\n","code":""},{"path":"results.html","id":"gene-optimization","chapter":"4 Results","heading":"4.5 Gene Optimization","text":"","code":""},{"path":"results.html","id":"overlap-with-other-sets","chapter":"4 Results","heading":"4.5.1 Overlap with Other Sets","text":"16 genes 72 common classifier set overlap PrOTYPE classifier: COL11A1, CD74, CD2, TIMP3, LUM, CYTIP, COL3A1, THBS2, TCF7L1, HMGA2, FN1, POSTN, COL1A2, COL5A2, PDZK1IP1, FBN1There 13 genes 72 classifier set overlap SPOT signature: HIF1A, CXCL10, DUSP4, SOX17, MITF, CDKN3, BRCA2, CEACAM5, ANXA4, SERPINE1, TCF7L1, CRABP2, DNAJC9.","code":""},{"path":"results.html","id":"optimal-gene-set","chapter":"4 Results","heading":"4.5.2 Optimal Gene Set","text":"28 unique genes combined PrOTYPE SPOT lists want use final classifier. incrementally add genes remaining 44 candidates based variable importance scores list recalculate performance metrics. number genes performance starts plateau may indicate optimal gene set us carry forward particular model.Variable importance calculated using either model-based approach available, SHAP-based VI score otherwise (e.g. SVM). sequential two-step classifiers, calculate overall VI scores aggregating base classifier VI scores using rank aggregation.\nFigure 4.27: Gene Optimization Sequential Classifier\nsequential classifier, use per-class median F1-scores pertaining histotype best performance retraining, sort number genes added. instance, sequence 2, look CCOC F1-scores CCOC best performance retraining HGSC removed.can observe sequence 3, F1-score stabilizes around 0.93 reach 34 genes added, hence optimal number genes used n=28+34=62. added genes : SEMA6A, GPR64, KGFLP2, BCL2, ATP5G3, C1orf173, ZBED1, PBX1, FUT3, KLK7, IGFBP1, STC1, MET, CPNE8, C10orf116, MAP1LC3A, EPAS1, SLC3A1, TPX2, TFF1, CAPN2, WT1, CYP4B1, SERPINA5, HNF1B, EGFL6, LGALS4, TSPAN8, BRCA1, LIN28B, DKK4, ADCYAP1R1, TFF3 MUC5B.\nFigure 4.28: Gene Optimization Two-Step Classifier\nSince second step classifier fits multinomial model, use macro F1-score measure analyze gene entry. two-step classifier, see Step 2, F1-score stabilizes around 0.88 reach 24 added. optimal number genes used n=28+24=52. added genes : PBX1, LGALS4, HNF1B, IGFBP1, TFF3, C10orf116, PAX8, GPR64, FUT3, CYP4B1, DKK4, GAD1, KLK7, EPAS1, CPNE8, BRCA1, ZBED1, IL6, SERPINA5, TPX2, CAPN2, TSPAN8, LIN28B SLC3A1.","code":""},{"path":"results.html","id":"rank-aggregation","chapter":"4 Results","heading":"4.6 Rank Aggregation","text":"22 methods (algorithm-sampling combinations) ordered table aggregated ranks using Genetic Algorithm. see best performing methods involve 2-stage sequential algorithms.","code":""},{"path":"results.html","id":"top-4-model-summary","chapter":"4 Results","heading":"4.7 Top 4 Model Summary","text":"","code":""},{"path":"results.html","id":"overall-metrics","chapter":"4 Results","heading":"4.7.1 Overall Metrics","text":"\nFigure 4.29: Top 4 Model Evaluation Metrics\n","code":""},{"path":"results.html","id":"per-class-metrics","chapter":"4 Results","heading":"4.7.2 Per-Class Metrics","text":"\nFigure 4.30: Top 4 Model Per-Class Evaluation Metrics\n\nFigure 4.31: Top 4 Model Per-Class F1-Scores\n","code":""},{"path":"results.html","id":"test-set-performance","chapter":"4 Results","heading":"4.8 Test Set Performance","text":"Now ’d like see best methods perform confirmation validation sets. class-specific F1-scores used.top 2 methods :sequential: sequential algorithm upsampling every step. sequence algorithms used :\nHGSC vs. non-HGSC using adaboost\nCCOC vs. non-CCOC using random forest\nENOC vs. non-ENOC using ridge regression\nMUC vs. LGSC using adaboost\nHGSC vs. non-HGSC using adaboostCCOC vs. non-CCOC using random forestENOC vs. non-ENOC using ridge regressionMUC vs. LGSC using adaboosttwo_step: two-step algorithm upsampling steps. sequence algorithms used :\nHGSC vs. non-HGSC using adaboost\nCCOC vs. ENOC vs. MUC vs. LGSC using random forest\nHGSC vs. non-HGSC using adaboostCCOC vs. ENOC vs. MUC vs. LGSC using random forestWe can test 2 additional methods using either full set genes optimal set genes methods.","code":""},{"path":"results.html","id":"confirmation-set","chapter":"4 Results","heading":"4.8.1 Confirmation Set","text":"\nTable 4.26: Class-specific Evaluation Metrics Confirmation Set Models\nconfirmation set, sequential_full sequential_optimal similar. sequential algorithms moderate improvement LGSC MUC classification. select sequential_optimal model test validation set.\nTable 4.27: Overall Evaluation Metrics Confirmation Set Models\n","code":""},{"path":"results.html","id":"validation-set","chapter":"4 Results","heading":"4.8.2 Validation Set","text":"\nTable 4.28: Class-specific Evaluation Metrics Validation Set Model\nPer-class F1-scores validation set 0.9.\nTable 4.29: Overall valuation Metrics Validation Set Model\n","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
