[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"report statistical findings describes classification ovarian cancer histotypes using data NanoString CodeSets.Marina Pavanello conducted initial exploratory data analysis, Cathy Tang implemented class imbalance techniques, Derek Chiu conducted normalization statistical analysis, Lauren Tindale Aline Talhouk project leads.","code":""},{"path":"introduction.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"Ovarian cancer five major histotypes: high-grade serous carcinoma (HGSC), low-grade serous carcinoma (LGSC), endometrioid carcinoma (ENOC), mucinous carcinoma (MUC), clear cell carcinoma (CCOC). common problem classifying histotypes class imbalance issue. HGSC dominates distribution, commonly accounting 70% cases many patient cohorts, four histotypes spread rest cases. Subsampling methods like -sampling, -sampling, SMOTE can used mitigate problem.supervised learning performed consensus framework: consider various classification algorithms use evaluation metrics like accuracy, F1-score, Kappa, G-mean inform decision methods carry forward prediction confirmation validation sets.","code":""},{"path":"methods.html","id":"methods","chapter":"2 Methods","heading":"2 Methods","text":"","code":""},{"path":"methods.html","id":"normalization","chapter":"2 Methods","heading":"2.1 Normalization","text":"full training set comprised data CodeSet (CS) 1, 2, 3. CodeSets first normalized housekeeping genes, different approach taken CodeSets.CS1 normalized CS3 using “Random1” reference samples. reference samples common samples CS1 CS3, randomly selected obtain one five histotypes. use reference method normalize CS1 CS3.Similarly, CS2 normalized CS3 using “Random1” reference samples using five common samples CS2 CS3 one histotype.CS3, first split dataset site: Vancouver, USC, AOC. use CS3-Vancouver subset “reference standard”, normalized CS3-USC CS3-AOC CS3-Vancouver using “Random1” reference method reference samples common USC Vancouver, AOC Vancouver. CS3-Vancouver also included without normalization.","code":""},{"path":"methods.html","id":"case-selection","chapter":"2 Methods","heading":"2.2 Case Selection","text":"Duplicate cases (two samples ottaID) removed training set fitting classification models. CS3 cases preferred CS1 CS2, CS3-Vancouver preferred CS3-AOC CS3-USC.training, confirmation, validation sets used different set cohorts.","code":""},{"path":"methods.html","id":"classifiers","chapter":"2 Methods","heading":"2.3 Classifiers","text":"use 4 classification algorithms supervised learning framework Training Set. pipeline run using SLURM batch jobs submitted partition CentOS 7 server. resampling techniques, pre-processing, model specification, hyperparameter tuning, evaluation metrics implemented using tidymodels suite packages. classifiers used :Random Forest (rf)Support Vector Machine (svm)XGBoost (xgb)Regularized Multinomial Regression (mr)","code":""},{"path":"methods.html","id":"resampling-of-training-set","chapter":"2 Methods","heading":"2.3.1 Resampling of Training Set","text":"used nested cross-validation design assess classifier also performing hyperparameter tuning. outer 5-fold CV stratified histotype used together inner 5-fold CV 2 repeats stratified histotype. design chosen test sets inner resamples still reasonable number samples belonging smallest minority class.","code":""},{"path":"methods.html","id":"hyperparameter-tuning","chapter":"2 Methods","heading":"2.3.2 Hyperparameter Tuning","text":"following specifications classifier used tuning hyperparameters:rf xgb: number trees fixed 500. hyperparameters tuned across 10 randomly selected points latin hypercube design.svm: cost sigma hyperparameters tuned across 10 randomly selected points latin hypercube design within ranges (transformed scale) [0, 2] [-3, 0], respectively.mr: generated 10 randomly selected points latin hypercube design penalty (lambda) parameter. , generated 10 evenly spaced points [0, 1] mixture (alpha) parameter regularized multinomial regression model. two sets 10 points crossed generate tuning grid 100 points.","code":""},{"path":"methods.html","id":"subsampling","chapter":"2 Methods","heading":"2.3.3 Subsampling","text":"specifications subsampling methods used handle class imbalance:None: subsampling performedDown-sampling: levels except minority class sampled frequency minority classUp-sampling: levels except majority class sampled frequency majority classSMOTE: levels except majority class synthetic data generated frequency majority classHybrid: levels except majority class synthetic data generated 50% frequency majority class, majority class sampled frequency rest.figure helps visualize distribution classes changes apply subsampling techniques handle class imbalance:\nFigure 2.1: Visualization Subsampling Techniques\n","code":""},{"path":"methods.html","id":"sequential-algorithm","chapter":"2 Methods","heading":"2.4 Sequential Algorithm","text":"Instead training k classes simultaneously using multinomial classifiers, can use sequential algorithm performs k-1 one-vs-binary classifications iteratively obtain final prediction cases. step sequence, classify one class vs. classes, classes make “” class equal current “one” class excluding “one” classes previous steps. example, “one” class step 1 HGSC, “” classes include CCOC, ENOC, LGSC, MUC. “one” class step 2 CCOC, “” classes include ENOC, LGSC, MUC.order classes workflows use step sequential algorithm must determined using retraining procedure. removing data associated particular class, retrain using remaining data using multinomial classifiers described . class workflow use next step sequence selected based best per-class evaluation metric value (e.g. F1-score).Let\\[\n\\begin{aligned}\n& X_k = \\text{Training data k classes}  \\\\\n& C_k = \\text{Class highest}\\;F_1\\;\\text{score training}\\;X_k \\\\\n& W_k = \\text{Workflow associated }\\;C_k\n\\end{aligned}\n\\tag{2.1}\n\\]Figure 2.2 illustrates sequential algorithm works K=5, using ovarian histotypes example classes.\nFigure 2.2: Sequential Algorithm\n","code":""},{"path":"methods.html","id":"subsampling-1","chapter":"2 Methods","heading":"2.4.1 Subsampling","text":"subsampling method used first step sequential algorithm used subsequent steps order maintain data pre-processing consistency. result, comparing classification algorithms within one subsampling method across entire sequential algorithm.","code":""},{"path":"methods.html","id":"two-step-algorithm","chapter":"2 Methods","heading":"2.5 Two-Step Algorithm","text":"two-step algorithm can thought special case sequential algorithm, specific classifying ovarian histotypes. HGSC histotype comprises approximately 80% cases among ovarian carcinoma patients, remaining 20% cases relatively evenly distributed among ENOC, CCOC, LGSC, MUC histotypes. Thus, can implement two-step algorithm :Step 1: use binary classification HGSC vs. non-HGSC (step step 1 sequential algorithm )Step 2: use multinomial classification remaining non-HGSC classesUsing notation Equation (2.1), flowchart similar Figure 2.2 can show two-step algorithm works:\nFigure 2.3: Two-Step Algorithm\n","code":""},{"path":"distributions.html","id":"distributions","chapter":"3 Distributions","heading":"3 Distributions","text":"","code":""},{"path":"distributions.html","id":"histotypes-in-classifier-data","chapter":"3 Distributions","heading":"3.1 Histotypes in Classifier Data","text":"\nTable 3.1: Pre-QC Training Set Histotype Distribution CodeSet\n\nTable 3.2: Training Set (duplicates) Histotype Distribution CodeSet\n\nTable 3.3: Final Training Set Histotype Distribution CodeSet\n\nTable 3.4: Histotype Distribution Confirmation Validation Sets\n","code":""},{"path":"distributions.html","id":"cohort-counts","chapter":"3 Distributions","heading":"3.2 Cohort Counts","text":"\nTable 3.5: Training Set counts CodeSet Processing Stage\n","code":""},{"path":"distributions.html","id":"cohorts-in-classifier-data","chapter":"3 Distributions","heading":"3.3 Cohorts in Classifier Data","text":"\nTable 3.6: Cohort Distribution Training, Confirmation, Validation Sets\n","code":""},{"path":"distributions.html","id":"quality-control","chapter":"3 Distributions","heading":"3.4 Quality Control","text":"","code":""},{"path":"distributions.html","id":"failed-samples","chapter":"3 Distributions","heading":"3.4.1 Failed Samples","text":"use aggregated QCFlag considers sample failed QC following conditions true:linFlag: linearity positive controls positive control concentrations less 0.95, linearity measures unknownimagingFlag: percent field view less 75%spcFlag: smallest positive control less lower limit detection (negative control average expression less two times negative control standard deviation), negative control average expression equals zeronormFlag: signal noise ratio less 100, percent genes detected less 50. Note: thresholds determined examining %GD vs. SNR relationship .\nTable 3.7: Number failed samples CodeSet fail condition\n","code":""},{"path":"distributions.html","id":"gd-vs.-snr","chapter":"3 Distributions","heading":"3.4.2 %GD vs. SNR","text":"\nFigure 3.1: % Genes Detected vs. Signal Noise Ratio\n\nFigure 3.2: % Genes Detected vs. Signal Noise Ratio (Zoomed)\n","code":""},{"path":"distributions.html","id":"pairwise-gene-expression","chapter":"3 Distributions","heading":"3.5 Pairwise Gene Expression","text":"\nFigure 3.3: Random1-Normalized CS1 vs. CS3 Gene Expression\n\nFigure 3.4: Random1-Normalized CS2 vs. CS3 Gene Expression\n\nFigure 3.5: HKgenes-Normalized CS1 vs. CS3 Gene Expression\n\nFigure 3.6: HKgenes-Normalized CS2 vs. CS3 Gene Expression\n","code":""},{"path":"results.html","id":"results","chapter":"4 Results","heading":"4 Results","text":"summarize cross-validated training performance class metrics training set. accuracy, F1-score, kappa, G-mean metrics interest. Workflows ordered mean estimates across outer folds nested CV metric.","code":""},{"path":"results.html","id":"training-set","chapter":"4 Results","heading":"4.1 Training Set","text":"","code":""},{"path":"results.html","id":"accuracy","chapter":"4 Results","heading":"4.1.1 Accuracy","text":"\nFigure 4.1: Training Set Mean Accuracy\n\nTable 4.1: Training Set Mean Accuracy\n\nFigure 4.2: Training Set Class-Specific Mean Accuracy\n\nTable 4.2: Training Set Class-Specific Mean Accuracy\n","code":""},{"path":"results.html","id":"f1-score","chapter":"4 Results","heading":"4.1.2 F1-Score","text":"\nFigure 4.3: Training Set Mean F1-Score\n\nTable 4.3: Training Set Mean F1-Score\n\nFigure 4.4: Training Set Class-Specific Mean F1-Score\n\nTable 4.4: Cross-Validated Training Set Class-Specific Mean F1-Score\n","code":""},{"path":"results.html","id":"kappa","chapter":"4 Results","heading":"4.1.3 Kappa","text":"\nFigure 4.5: Training Set Mean Kappa\n\nTable 4.5: Training Set Mean Kappa\n\nFigure 4.6: Training Set Class-Specific Mean Kappa\n\nTable 4.6: Training Set Class-Specific Mean Kappa\n","code":""},{"path":"results.html","id":"g-mean","chapter":"4 Results","heading":"4.1.4 G-mean","text":"\nFigure 4.7: Training Set Mean G-mean\n\nTable 4.7: Training Set Mean G-mean\n\nFigure 4.8: Training Set Class-Specific Mean G-mean\n\nTable 4.8: Training Set Class-Specific Mean G-mean\n","code":""},{"path":"results.html","id":"gene-optimization","chapter":"4 Results","heading":"4.2 Gene Optimization","text":"","code":""},{"path":"results.html","id":"overlap-with-other-sets","chapter":"4 Results","heading":"4.2.1 Overlap with Other Sets","text":"16 genes 72 common classifier set overlap PrOTYPE classifier: COL11A1, CD74, CD2, TIMP3, LUM, CYTIP, COL3A1, THBS2, TCF7L1, HMGA2, FN1, POSTN, COL1A2, COL5A2, PDZK1IP1, FBN1There 13 genes 72 classifier set overlap SPOT signature: HIF1A, CXCL10, DUSP4, SOX17, MITF, CDKN3, BRCA2, CEACAM5, ANXA4, SERPINE1, TCF7L1, CRABP2, DNAJC9.","code":""},{"path":"results.html","id":"optimal-gene-set","chapter":"4 Results","heading":"4.2.2 Optimal Gene Set","text":"28 unique genes combined PrOTYPE SPOT lists want use final classifier. incrementally add genes remaining 44 candidates based variable importance scores list recalculate performance metrics. number genes performance starts plateau may indicate optimal gene set us carry forward particular model.Variable importance calculated using either model-based approach available, permutation-based VI score otherwise (e.g. SVM). sequential two-step classifiers, calculate overall VI scores taking cumulative union variable importance ranks across sequences variables included.\nFigure 4.9: Gene Optimization Sequential Classifier\nsequential algorithm, sequences 1, 2, 4 relatively flat average F1-scores across number genes added. However, can observe sequence 3, F1-score stabilizes around 0.9 reach 27 genes added, hence optimal number genes used n=28+27=55 added genes : CYP2C18, HNF1B, ATP5G3, TP53, SLC3A1, CPNE8, C1orf173, WT1, MUC5B, MAP1LC3A, EGFL6, ZBED1, GPR64, STC1, MET, IGJ, SERPINA5, KLK7, DKK4, BCL2, SENP8, GCNT3, IGKC, IGFBP1, CAPN2, GAD1 SCGB1D2.\nFigure 4.10: Gene Optimization Two-Step Classifier\nSince second step classifier fits multinomial model, use macro F1-score measure analyze gene entry. two-step classifier, see Step 2, F1-score stabilizes around 0.85 reach 12 added. optimal number genes used n=28+12=40. added genes : CYP2C18, MUC5B, HNF1B, SLC3A1, WT1, TSPAN8, EGFL6, TFF1, TFF3, MET, CAPN2 KLK7.","code":""},{"path":"results.html","id":"rank-aggregation","chapter":"4 Results","heading":"4.3 Rank Aggregation","text":"14 workflows ordered table aggregated ranks using Genetic Algorithm. see best performing methods involve sequential two-step algorithms.","code":""},{"path":"results.html","id":"top-workflows","chapter":"4 Results","heading":"4.3.1 Top Workflows","text":"look per-class evaluation metrics top 4 workflows.\nFigure 4.11: Top 4 Workflow Per-Class Evaluation Metrics\n\nFigure 4.12: Top 4 Workflow Per-Class F1-Scores\nMisclassified cases previous step sequence classifiers included subsequent steps training set CV folds. Thus, piece together test set predictions sequential two-step algorithms obtain overall metrics.","code":""},{"path":"results.html","id":"test-set-performance","chapter":"4 Results","heading":"4.4 Test Set Performance","text":"Now ’d like see best methods perform confirmation validation sets. class-specific F1-scores used.top 2 methods :sequential: sequential algorithm hybrid subsampling every step. sequence algorithms used :\nHGSC vs. non-HGSC using random forest\nCCOC vs. non-CCOC using support vector machine\nLGSC vs. non-LGSC using support vector machine\nENOC vs. MUC using regularized multinomial regression\nHGSC vs. non-HGSC using random forestCCOC vs. non-CCOC using support vector machineLGSC vs. non-LGSC using support vector machineENOC vs. MUC using regularized multinomial regressiontwo_step: two-step algorithm hybrid subsampling steps. sequence algorithms used :\nHGSC vs. non-HGSC using random forest\nCCOC vs. ENOC vs. MUC vs. LGSC support vector machine\nHGSC vs. non-HGSC using random forestCCOC vs. ENOC vs. MUC vs. LGSC support vector machineWe can test 2 additional methods using either full set genes optimal set genes methods.","code":""},{"path":"results.html","id":"confirmation-set","chapter":"4 Results","heading":"4.4.1 Confirmation Set","text":"\nTable 4.9: Overall Evaluation Metrics Confirmation Set Models\n\nTable 4.10: Per-Class Eevaluation Metrics Confirmation Set Model\n","code":""},{"path":"results.html","id":"validation-set","chapter":"4 Results","heading":"4.4.2 Validation Set","text":"\nTable 4.11: Overall Evaluation Metrics Validation Set Model\n\nTable 4.12: Per-Class Eevaluation Metrics Validation Set Model\n","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
