[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"report statistical findings describes classification ovarian cancer histotypes using data NanoString CodeSets.Marina Pavanello conducted initial exploratory data analysis, Cathy Tang implemented class imbalance techniques, Derek Chiu conducted normalization statistical analysis, Lauren Tindale Aline Talhouk project leads.","code":""},{"path":"introduction.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"Ovarian cancer five major histotypes: high-grade serous carcinoma (HGSC), low-grade serous carcinoma (LGSC), endometrioid carcinoma (ENOC), mucinous carcinoma (MUC), clear cell carcinoma (CCOC). common problem classifying histotypes class imbalance issue. HGSC dominates distribution, commonly accounting 70% cases many patient cohorts, four histotypes spread rest cases. Subsampling methods like -sampling, -sampling, SMOTE can used mitigate problem.supervised learning performed consensus framework: consider various classification algorithms use evaluation metrics like accuracy, F1-score, Kappa, G-mean inform decision methods carry forward prediction confirmation validation sets.","code":""},{"path":"methods.html","id":"methods","chapter":"2 Methods","heading":"2 Methods","text":"","code":""},{"path":"methods.html","id":"normalization","chapter":"2 Methods","heading":"2.1 Normalization","text":"full training set comprised data CodeSet (CS) 1, 2, 3. CodeSets first normalized housekeeping genes, different approach taken CodeSets.CS1 normalized CS3 using “Random1” reference samples. reference samples common samples CS1 CS3, randomly selected obtain one five histotypes. use reference method normalize CS1 CS3.Similarly, CS2 normalized CS3 using “Random1” reference samples using five common samples CS2 CS3 one histotype.CS3, first split dataset site: Vancouver, USC, AOC. use CS3-Vancouver subset “reference standard”, normalized CS3-USC CS3-AOC CS3-Vancouver using “Random1” reference method reference samples common USC Vancouver, AOC Vancouver. CS3-Vancouver also included without normalization.","code":""},{"path":"methods.html","id":"case-selection","chapter":"2 Methods","heading":"2.2 Case Selection","text":"Duplicate cases (two samples ottaID) removed training set fitting classification models. CS3 cases preferred CS1 CS2, CS3-Vancouver preferred CS3-AOC CS3-USC.training, confirmation, validation sets used different set cohorts.","code":""},{"path":"methods.html","id":"classifiers","chapter":"2 Methods","heading":"2.3 Classifiers","text":"use 4 classification algorithms supervised learning framework Training Set. pipeline run using SLURM batch jobs submitted partition CentOS 7 server. resampling techniques, pre-processing, model specification, hyperparameter tuning, evaluation metrics implemented using tidymodels suite packages. classifiers used :Random Forest (rf)Support Vector Machine (svm)XGBoost (xgb)Regularized Multinomial Regression (mr)","code":""},{"path":"methods.html","id":"resampling-of-training-set","chapter":"2 Methods","heading":"2.3.1 Resampling of Training Set","text":"used nested cross-validation design assess classifier also performing hyperparameter tuning. outer 5-fold CV stratified histotype used together inner 5-fold CV 2 repeats stratified histotype. design chosen test sets inner resamples still reasonable number samples belonging smallest minority class.","code":""},{"path":"methods.html","id":"hyperparameter-tuning","chapter":"2 Methods","heading":"2.3.2 Hyperparameter Tuning","text":"following specifications classifier used tuning hyperparameters:rf xgb: number trees fixed 500. hyperparameters tuned across 10 randomly selected points latin hypercube design.svm: cost sigma hyperparameters tuned across 10 randomly selected points latin hypercube design. tuned cost parameter range [1, 8]. range tuning sigma parameter obtained 10% 90% quantiles estimation using kernlab::sigest() function.mr: generated 10 randomly selected points latin hypercube design penalty (lambda) parameter. , generated 10 evenly spaced points [0, 1] mixture (alpha) parameter regularized multinomial regression model. two sets 10 points crossed generate tuning grid 100 points.","code":""},{"path":"methods.html","id":"subsampling","chapter":"2 Methods","heading":"2.3.3 Subsampling","text":"specifications subsampling methods used handle class imbalance:None: subsampling performedDown-sampling: levels except minority class sampled frequency minority classUp-sampling: levels except majority class sampled frequency majority classSMOTE: levels except majority class synthetic data generated frequency majority classHybrid: levels except majority class synthetic data generated 50% frequency majority class, majority class sampled frequency rest.figure helps visualize distribution classes changes apply subsampling techniques handle class imbalance:\nFigure 2.1: Visualization Subsampling Techniques\n","code":""},{"path":"methods.html","id":"workflows","chapter":"2 Methods","heading":"2.3.4 Workflows","text":"4 algorithms 5 subsampling methods crossed create 20 different classification workflows. example, hybrid_xgb workflow classifier first pre-processes training set applying hybrid subsampling method, proceeds use XGBoost algorithm classify ovarian histotypes.","code":""},{"path":"methods.html","id":"two-step-algorithm","chapter":"2 Methods","heading":"2.4 Two-Step Algorithm","text":"HGSC histotype comprises approximately 80% cases among ovarian carcinoma patients, remaining 20% cases relatively, evenly distributed among ENOC, CCOC, LGSC, MUC histotypes. can implement two-step algorithm :Step 1: use binary classification HGSC vs. non-HGSCStep 2: use multinomial classification remaining non-HGSC classesLet\\[\n\\begin{aligned}\n& X_k = \\text{Training data k classes}  \\\\\n& C_k = \\text{Class highest}\\;F_1\\;\\text{score training}\\;X_k \\\\\n& W_k = \\text{Workflow associated }\\;C_k\n\\end{aligned}\n\\tag{2.1}\n\\]Figure 2.2 shows two-step algorithm works:\nFigure 2.2: Two-Step Algorithm\nAlthough class imbalance problem mostly eliminated Step 2 removing HGSC cases, still use subsampling method Step 2 used Step 1 keep algorithm consistent.","code":""},{"path":"methods.html","id":"sequential-algorithm","chapter":"2 Methods","heading":"2.5 Sequential Algorithm","text":"Instead training k classes simultaneously using multinomial classifiers, can use sequential algorithm performs k-1 one-vs-binary classifications iteratively obtain final prediction cases. step sequence, classify one class vs. classes, classes make “” class equal current “one” class excluding “one” classes previous steps. example, “one” class step 1 HGSC, “” classes include CCOC, ENOC, LGSC, MUC. “one” class step 2 CCOC, “” classes include ENOC, LGSC, MUC.order classes workflows use step sequential algorithm must determined using retraining procedure. removing data associated particular class, retrain using remaining data using multinomial classifiers described . class workflow use next step sequence selected based best per-class evaluation metric value (e.g. F1-score).Figure 2.3 illustrates sequential algorithm works K=5, using ovarian histotypes example classes.\nFigure 2.3: Sequential Algorithm\nsubsampling method used first step sequential algorithm used subsequent steps order maintain data pre-processing consistency. result, comparing classification algorithms within one subsampling method across entire sequential algorithm.","code":""},{"path":"methods.html","id":"aggregating-predictions","chapter":"2 Methods","heading":"2.5.1 Aggregating Predictions","text":"aggregate one-vs-predictions sequential algorithm workflows order obtain final class prediction holdout test set. sequential workflow assessed every sample ensure cases classified “” class previous step sequence eventually assigned predicted class. example, say based certain class-specific metrics determined order classes sequential algorithm predict HGSC vs. non-HGSC, CCOC vs. non-CCOC, LGSC vs. non-LGSC, MUC vs. ENOC. Figure 2.4 illustrates final predictions assigned:\nFigure 2.4: Aggregating Predictions Sequential Algorithm\n","code":""},{"path":"methods.html","id":"gene-optimization","chapter":"2 Methods","heading":"2.6 Gene Optimization","text":"want discover optimal set genes classifiers including specific genes studies. total 72 genes used classifier training set.16 genes classifier set overlap PrOTYPE classifier: COL11A1, CD74, CD2, TIMP3, LUM, CYTIP, COL3A1, THBS2, TCF7L1, HMGA2, FN1, POSTN, COL1A2, COL5A2, PDZK1IP1, FBN1There also 13 genes classifier set overlap SPOT signature: HIF1A, CXCL10, DUSP4, SOX17, MITF, CDKN3, BRCA2, CEACAM5, ANXA4, SERPINE1, TCF7L1, CRABP2, DNAJC9.Taking union PrOTYPE SPOT genes obtain total 28 unique genes want use final classifier, regardless model performance. incrementally add genes remaining 44 candidate genes based overall variable importance rank list recalculate performance metrics. number genes performance peaks starts plateau may indicate optimal gene set model us compare full set model.","code":""},{"path":"methods.html","id":"variable-importance","chapter":"2 Methods","heading":"2.6.1 Variable Importance","text":"Variable importance calculated using either model-based approach available, permutation-based VI score otherwise (e.g. SVM). variable importance scores averaged across outer training folds, ranked highest lowest.sequential two-step classifiers, calculate overall VI rank taking cumulative union genes variable importance rank across sequences, genes included.","code":""},{"path":"methods.html","id":"evaluation-metrics","chapter":"2 Methods","heading":"2.7 Evaluation Metrics","text":"use accuracy, kappa, F1-score, area ROC (AUC), geometric mean evaluation metrics compare training performance different workflows. Multiclass extensions metrics can calculated except F1-score, use macro-averaging obtain overall metric. Class-specific metrics calculated recoding classes one-vs-categories class, except AUC potentially misleading combine predicted probabilities one-vs-fashion.","code":""},{"path":"methods.html","id":"accuracy","chapter":"2 Methods","heading":"2.7.1 Accuracy","text":"accuracy defined proportion correct predictions cases:\\[\n\\text{accuracy} = \\frac{TP}{TP + FP + FN + TN}\n\\tag{2.2}\n\\]","code":""},{"path":"methods.html","id":"kappa","chapter":"2 Methods","heading":"2.7.2 Kappa","text":"Kappa defined :\\[\n\\text{kappa} = \\frac{p_0 - p_e}{1 - p_e}\n\\tag{2.3}\n\\]\\(p_0\\) observed agreement among raters \\(p_e\\) hypothetical probability agreement due random chance.","code":""},{"path":"methods.html","id":"auc","chapter":"2 Methods","heading":"2.7.3 AUC","text":"area receiver operating curve (AUC) calculated adding area curve formed plotting sensitivity vs. 1 - specificity. Hand-till method used multiclass extension AUC.","code":""},{"path":"methods.html","id":"f1-score","chapter":"2 Methods","heading":"2.7.4 F1-Score","text":"F-measure can thought harmonic mean precision recall:\\[\nF_{meas} = \\frac{(1 + \\beta^2) \\times precision \\times recall}{(\\beta^2 \\times precision) + recall}\n\\tag{2.4}\n\\]\\(\\beta\\) value can adjusted place weight upon precision recall. common value \\(\\beta\\) 1, also commonly known F1-score. multiclass extension doesn’t exist F1-score, use macro-averaging calculate metric two classes. example, \\(k\\) classes, macro-averaged F1-score equal :\\[\n{F_1}_{macro} = \\frac{1}{k} \\sum_{=1}^{k}{F_1}_{}\n\\tag{2.5}\n\\]\n\\({F_1}_{}\\) F1-score computed frrom recoding classes \\(k=\\) vs. \\(k \\neq \\).situations least one predicted case classes (e.g. poor classifier), \\({F_1}_{}\\) undefined per-class precision class \\(\\) undefined. \\({F_1}_{}\\) terms removed \\({F_1}_{macro}\\) equation resulting value may inflated. Interpreting F1-score case misleading.","code":""},{"path":"methods.html","id":"geometric-mean","chapter":"2 Methods","heading":"2.7.5 Geometric Mean","text":"geometric mean (G-mean) \\(k^{th}\\) root product class-specific sensitivities \\(k\\) classes:\\[\n\\text{G-mean} = \\sqrt[k]{\\prod_{=1}^{k}{\\text{Sensitivity}_k}}\n\\tag{2.6}\n\\]\nG-mean generalizes easily multiclass scenario.","code":""},{"path":"distributions.html","id":"distributions","chapter":"3 Distributions","heading":"3 Distributions","text":"","code":""},{"path":"distributions.html","id":"histotypes-in-classifier-data","chapter":"3 Distributions","heading":"3.1 Histotypes in Classifier Data","text":"\nTable 3.1: Pre-QC Training Set Histotype Distribution CodeSet\n\nTable 3.2: Training Set (duplicates) Histotype Distribution CodeSet\n\nTable 3.3: Final Training Set Histotype Distribution CodeSet\n\nTable 3.4: Histotype Distribution Confirmation Validation Sets\n","code":""},{"path":"distributions.html","id":"cohort-counts","chapter":"3 Distributions","heading":"3.2 Cohort Counts","text":"\nTable 3.5: Training Set counts CodeSet Processing Stage\n","code":""},{"path":"distributions.html","id":"cohorts-in-classifier-data","chapter":"3 Distributions","heading":"3.3 Cohorts in Classifier Data","text":"\nTable 3.6: Cohort Distribution Training, Confirmation, Validation Sets\n","code":""},{"path":"distributions.html","id":"quality-control","chapter":"3 Distributions","heading":"3.4 Quality Control","text":"","code":""},{"path":"distributions.html","id":"failed-samples","chapter":"3 Distributions","heading":"3.4.1 Failed Samples","text":"use aggregated QCFlag considers sample failed QC following conditions true:linFlag: linearity positive controls positive control concentrations less 0.95, linearity measures unknownimagingFlag: percent field view less 75%spcFlag: smallest positive control less lower limit detection (negative control average expression less two times negative control standard deviation), negative control average expression equals zeronormFlag: signal noise ratio less 100, percent genes detected less 50. Note: thresholds determined examining %GD vs. SNR relationship .\nTable 3.7: Number failed samples CodeSet fail condition\n","code":""},{"path":"distributions.html","id":"gd-vs.-snr","chapter":"3 Distributions","heading":"3.4.2 %GD vs. SNR","text":"\nFigure 3.1: % Genes Detected vs. Signal Noise Ratio\n\nFigure 3.2: % Genes Detected vs. Signal Noise Ratio (Zoomed)\n","code":""},{"path":"distributions.html","id":"pairwise-gene-expression","chapter":"3 Distributions","heading":"3.5 Pairwise Gene Expression","text":"\nFigure 3.3: Random1-Normalized CS1 vs. CS3 Gene Expression\n\nFigure 3.4: Random1-Normalized CS2 vs. CS3 Gene Expression\n\nFigure 3.5: HKgenes-Normalized CS1 vs. CS3 Gene Expression\n\nFigure 3.6: HKgenes-Normalized CS2 vs. CS3 Gene Expression\n","code":""},{"path":"results.html","id":"results","chapter":"4 Results","heading":"4 Results","text":"summarize cross-validated training performance class metrics training set. accuracy, F1-score, kappa, G-mean metrics interest. Workflows ordered mean estimates across outer folds nested CV metric.","code":""},{"path":"results.html","id":"training-set","chapter":"4 Results","heading":"4.1 Training Set","text":"","code":""},{"path":"results.html","id":"accuracy-1","chapter":"4 Results","heading":"4.1.1 Accuracy","text":"\nFigure 4.1: Training Set Mean Accuracy\n\nTable 4.1: Training Set Mean Accuracy\n\nFigure 4.2: Training Set Class-Specific Mean Accuracy\n\nTable 4.2: Training Set Class-Specific Mean Accuracy\n","code":""},{"path":"results.html","id":"f1-score-1","chapter":"4 Results","heading":"4.1.2 F1-Score","text":"\nFigure 4.3: Training Set Mean F1-Score\n\nTable 4.3: Training Set Mean F1-Score\n\nFigure 4.4: Training Set Class-Specific Mean F1-Score\n\nTable 4.4: Cross-Validated Training Set Class-Specific Mean F1-Score\n","code":""},{"path":"results.html","id":"kappa-1","chapter":"4 Results","heading":"4.1.3 Kappa","text":"\nFigure 4.5: Training Set Mean Kappa\n\nTable 4.5: Training Set Mean Kappa\n\nFigure 4.6: Training Set Class-Specific Mean Kappa\n\nTable 4.6: Training Set Class-Specific Mean Kappa\n","code":""},{"path":"results.html","id":"g-mean","chapter":"4 Results","heading":"4.1.4 G-mean","text":"\nFigure 4.7: Training Set Mean G-mean\n\nTable 4.7: Training Set Mean G-mean\n\nFigure 4.8: Training Set Class-Specific Mean G-mean\n\nTable 4.8: Training Set Class-Specific Mean G-mean\n","code":""},{"path":"results.html","id":"optimal-gene-sets","chapter":"4 Results","heading":"4.2 Optimal Gene Sets","text":"","code":""},{"path":"results.html","id":"sequential-algorithm-1","chapter":"4 Results","heading":"4.2.1 Sequential Algorithm","text":"\nFigure 4.9: Gene Optimization Sequential Classifier\nsequential algorithm, sequences 1, 2, 4 relatively flat average F1-scores across number genes added. However, can observe sequence 3, F1-score stabilizes around 0.9 reach 13 genes added, hence optimal number genes used n=28+13=41 added genes : CYP2C18, TFF3, KLK7, HNF1B, IL6, IGFBP1, SLC3A1, SERPINA5, WT1, CPNE8, EGFL6, GPR64 MUC5B.","code":""},{"path":"results.html","id":"two-step-algorithm-1","chapter":"4 Results","heading":"4.2.2 Two-Step Algorithm","text":"\nFigure 4.10: Gene Optimization Two-Step Classifier\nSince second step classifier fits multinomial model, use macro F1-score measure analyze gene entry. two-step classifier, see Step 2, F1-score stabilizes around 0.85 reach 12 added. optimal number genes used n=28+12=40. added genes : CYP2C18, MUC5B, HNF1B, SLC3A1, IGFBP1, WT1, EGFL6, TFF3, MET, KLK7, CPNE8 STC1.","code":""},{"path":"results.html","id":"rank-aggregation","chapter":"4 Results","heading":"4.3 Rank Aggregation","text":"18 workflows ordered table aggregated ranks using Genetic Algorithm. see best performing methods involve sequential two-step algorithms.","code":""},{"path":"results.html","id":"top-workflows","chapter":"4 Results","heading":"4.3.1 Top Workflows","text":"look per-class evaluation metrics top 4 workflows.\nFigure 4.11: Top 4 Workflow Per-Class Evaluation Metrics\n\nFigure 4.12: Top 4 Workflow Per-Class F1-Scores\nMisclassified cases previous step sequence classifiers included subsequent steps training set CV folds. Thus, piece together test set predictions sequential two-step algorithms obtain overall metrics.","code":""},{"path":"results.html","id":"test-set-performance","chapter":"4 Results","heading":"4.4 Test Set Performance","text":"Now ’d like see best methods perform confirmation validation sets. class-specific F1-scores used.top 2 methods :sequential: sequential algorithm hybrid subsampling every step. sequence algorithms used :\nHGSC vs. non-HGSC using random forest\nCCOC vs. non-CCOC using XGBoost\nENOC vs. non-ENOC using support vector machine\nLGSC vs. MUC using support vector machine\nHGSC vs. non-HGSC using random forestCCOC vs. non-CCOC using XGBoostENOC vs. non-ENOC using support vector machineLGSC vs. MUC using support vector machinetwo_step: two-step algorithm hybrid subsampling steps. sequence algorithms used :\nHGSC vs. non-HGSC using random forest\nCCOC vs. ENOC vs. MUC vs. LGSC support vector machine\nHGSC vs. non-HGSC using random forestCCOC vs. ENOC vs. MUC vs. LGSC support vector machineWe can test 2 additional methods using either full set genes optimal set genes methods.","code":""},{"path":"results.html","id":"confirmation-set","chapter":"4 Results","heading":"4.4.1 Confirmation Set","text":"\nTable 4.9: Overall Evaluation Metrics Confirmation Set Models\n\nFigure 4.13: Confusion Matrices Confirmation Set Models\n\nTable 4.10: Per-Class Eevaluation Metrics Confirmation Set Model\n","code":""},{"path":"results.html","id":"validation-set","chapter":"4 Results","heading":"4.4.2 Validation Set","text":"\nTable 4.11: Overall Evaluation Metrics Validation Set Model\n\nFigure 4.14: Confusion Matrix Validation Set Model\n\nTable 4.12: Per-Class Eevaluation Metrics Validation Set Model\n","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
