[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"report statistical findings describes classification ovarian cancer histotypes using data NanoString CodeSets.Marina Pavanello conducted initial exploratory data analysis, Cathy Tang implemented class imbalance techniques, Derek Chiu conducted normalization statistical analysis, Lauren Tindale Aline Talhouk project leads.","code":""},{"path":"introduction.html","id":"introduction","chapter":"1 Introduction","heading":"1 Introduction","text":"Ovarian cancer five major histotypes: high-grade serous carcinoma (HGSC), low-grade serous carcinoma (LGSC), endometrioid carcinoma (ENOC), mucinous carcinoma (MUC), clear cell carcinoma (CCOC). common problem classifying histotypes class imbalance issue. HGSC dominates distribution, commonly accounting 70% cases many patient cohorts, four histotypes spread rest cases. Subsampling methods like -sampling, -sampling, SMOTE can used mitigate problem.supervised learning performed consensus framework: consider various classification algorithms use evaluation metrics like accuracy, F1-score, Kappa, G-mean inform decision methods carry forward prediction confirmation validation sets.","code":""},{"path":"methods.html","id":"methods","chapter":"2 Methods","heading":"2 Methods","text":"","code":""},{"path":"methods.html","id":"pre-processing","chapter":"2 Methods","heading":"2.1 Pre-Processing","text":"","code":""},{"path":"methods.html","id":"case-selection","chapter":"2 Methods","heading":"2.1.1 Case Selection","text":"Raw data comes three NanoString CodeSets (CS): CS1, CS2, CS3. divide data training, confirmation, validation sets using samples sets cohorts:Training\nCS1: MAYO, OOU, OOUE, VOA, MTL\nCS2: MAYO, OOU, OOUE, OVAR3, VOA, ICON7, JAPAN, MTL, POOL-CTRL\nCS3: OOU, OOUE, VOA, POOL-1, POOL-2, POOL-3\nCS1: MAYO, OOU, OOUE, VOA, MTLCS2: MAYO, OOU, OOUE, OVAR3, VOA, ICON7, JAPAN, MTL, POOL-CTRLCS3: OOU, OOUE, VOA, POOL-1, POOL-2, POOL-3Confirmation:\nCS3: TNCO\nCS3: TNCOValidation:\nCS3: DOVE4\nCS3: DOVE4","code":""},{"path":"methods.html","id":"quality-control","chapter":"2 Methods","heading":"2.1.2 Quality Control","text":"Samples failed following NanoString quality control conditions removed:linFlag: linearity positive controls positive control concentrations less 0.95, linearity measures unknownimagingFlag: percent field view less 75%spcFlag: smallest positive control less lower limit detection (negative control average expression less two times negative control standard deviation), negative control average expression equals zeronormFlag: signal noise ratio less 100, percent genes detected less 50. Note: thresholds determined examining %GD vs. SNR relationship .","code":""},{"path":"methods.html","id":"normalization","chapter":"2 Methods","heading":"2.1.3 Normalization","text":"full training set (n=1246) comprised data CodeSets (CS) 1, 2, 3. CodeSets first normalized housekeeping genes, different approaches taken subsequent normalizations CodeSet.CS1 normalized CS3 using five “Random1” reference samples. reference samples randomly selected CS1 among samples three CodeSets share common otta IDs, obtain one sample five histotypes. , use reference-based method normalize CS1 CS3 across common genes, remaining expression samples Talhouk et al. (2016).Similarly, CS2 normalized CS3 using “Random1” reference samples, now taken CS2. Normalization performed across common genes CS2 CS3.CS3, first split dataset three sites: Vancouver, USC, AOC. use CS3-Vancouver subset “reference standard”, normalized CS3-USC CS3-AOC CS3-Vancouver using “Random1” reference set randomly selected among samples common Vancouver, USC, AOC. Finally, CS3-Vancouver expression samples included training set without normalization.","code":""},{"path":"methods.html","id":"final-processing","chapter":"2 Methods","heading":"2.1.4 Final Processing","text":"map ovarian histotypes remaining samples keep major histotypes building predictive model: high-grade serous carcinoma (HGSC), clear cell ovarian caricoma (CCOC), endometrioid ovarian carcinoma (ENOC), low-grade serous carcinoma (LGSC), mucinous carcinoma (MUC).Duplicate cases (two samples ottaID) removed generating final training set use fitting classification models. CS3 cases preferred CS1 CS2, CS3-Vancouver cases preferred CS3-AOC CS3-USC selecting duplicates.final training set used genes common across three CodeSets.","code":""},{"path":"methods.html","id":"classifiers","chapter":"2 Methods","heading":"2.2 Classifiers","text":"use 4 classification algorithms supervised learning framework Training Set. pipeline run using SLURM batch jobs submitted partition CentOS 7 server. resampling techniques, pre-processing, model specification, hyperparameter tuning, evaluation metrics implemented using tidymodels suite packages. classifiers used :Random Forest (rf)Support Vector Machine (svm)XGBoost (xgb)Regularized Multinomial Regression (mr)","code":""},{"path":"methods.html","id":"resampling-of-training-set","chapter":"2 Methods","heading":"2.2.1 Resampling of Training Set","text":"used nested cross-validation design assess classifier also performing hyperparameter tuning. outer 5-fold CV stratified histotype used together inner 5-fold CV 2 repeats stratified histotype. design chosen test sets inner resamples still reasonable number samples belonging smallest minority class.outer resampling method bootstrap, inner training inner test sets likely contain samples result sampling replacement outer training set. phenomenon might result inflated performance observations used train evaluate hyperparameter tuning inner loop.","code":""},{"path":"methods.html","id":"hyperparameter-tuning","chapter":"2 Methods","heading":"2.2.2 Hyperparameter Tuning","text":"following specifications classifier used tuning hyperparameters:rf xgb: number trees fixed 500. hyperparameters tuned across 10 randomly selected points latin hypercube design.svm: cost sigma hyperparameters tuned across 10 randomly selected points latin hypercube design. tuned cost parameter range [1, 8]. range tuning sigma parameter obtained 10% 90% quantiles estimation using kernlab::sigest() function.mr: generated 10 randomly selected points latin hypercube design penalty (lambda) parameter. , generated 10 evenly spaced points [0, 1] mixture (alpha) parameter regularized multinomial regression model. two sets 10 points crossed generate tuning grid 100 points.hyperparameter combination resulted highest average F1-score across inner training sets selected classifier use model assessing prediction performance outer training loop.","code":""},{"path":"methods.html","id":"subsampling","chapter":"2 Methods","heading":"2.2.3 Subsampling","text":"specifications subsampling methods used handle class imbalance:None: subsampling performedDown-sampling: levels except minority class sampled frequency minority classUp-sampling: levels except majority class sampled frequency majority classSMOTE: levels except majority class synthetic data generated frequency majority classHybrid: levels except majority class synthetic data generated 50% frequency majority class, majority class sampled frequency rest.figure helps visualize distribution classes changes apply subsampling techniques handle class imbalance:\nFigure 2.1: Visualization Subsampling Techniques\n","code":""},{"path":"methods.html","id":"workflows","chapter":"2 Methods","heading":"2.2.4 Workflows","text":"4 algorithms 5 subsampling methods crossed create 20 different classification workflows. example, hybrid_xgb workflow classifier first pre-processes training set applying hybrid subsampling method, proceeds use XGBoost algorithm classify ovarian histotypes.","code":""},{"path":"methods.html","id":"two-step-algorithm","chapter":"2 Methods","heading":"2.3 Two-Step Algorithm","text":"HGSC histotype comprises approximately 80% cases among ovarian carcinoma patients, remaining 20% cases relatively, evenly distributed among ENOC, CCOC, LGSC, MUC histotypes. can implement two-step algorithm :Step 1: use binary classification HGSC vs. non-HGSCStep 2: use multinomial classification remaining non-HGSC classesLet\\[\n\\begin{aligned}\n& X_k = \\text{Training data k classes}  \\\\\n& C_k = \\text{Class highest}\\;F_1\\;\\text{score training}\\;X_k \\\\\n& W_k = \\text{Workflow associated }\\;C_k\n\\end{aligned}\n\\tag{2.1}\n\\]Figure 2.2 shows two-step algorithm works:\nFigure 2.2: Two-Step Algorithm\nAlthough class imbalance problem mostly eliminated Step 2 removing HGSC cases, still use subsampling method Step 2 used Step 1 keep algorithm consistent.","code":""},{"path":"methods.html","id":"aggregating-predictions","chapter":"2 Methods","heading":"2.3.1 Aggregating Predictions","text":"aggregation two-step predictions quite straightforward:Predict HGSC vs. non-HGSCAmong non-HGSC cases, predict CCOC vs. LGSC vs. MUC vs. ENOC\nFigure 2.3: Aggregating Predictions Two-Step Algorithm\n","code":""},{"path":"methods.html","id":"sequential-algorithm","chapter":"2 Methods","heading":"2.4 Sequential Algorithm","text":"Instead training k classes simultaneously using multinomial classifiers, can use sequential algorithm performs k-1 one-vs-binary classifications iteratively obtain final prediction cases. step sequence, classify one class vs. classes, classes make “” class equal current “one” class excluding “one” classes previous steps. example, “one” class step 1 HGSC, “” classes include CCOC, ENOC, LGSC, MUC. “one” class step 2 CCOC, “” classes include ENOC, LGSC, MUC.order classes workflows use step sequential algorithm must determined using retraining procedure. removing data associated particular class, retrain using remaining data using multinomial classifiers described . class workflow use next step sequence selected based best per-class evaluation metric value (e.g. F1-score).Figure 2.4 illustrates sequential algorithm works K=5, using ovarian histotypes example classes.\nFigure 2.4: Sequential Algorithm\nsubsampling method used first step sequential algorithm used subsequent steps order maintain data pre-processing consistency. result, comparing classification algorithms within one subsampling method across entire sequential algorithm.","code":""},{"path":"methods.html","id":"aggregating-predictions-1","chapter":"2 Methods","heading":"2.4.1 Aggregating Predictions","text":"aggregate one-vs-predictions sequential algorithm workflows order obtain final class prediction holdout test set. sequential workflow assessed every sample ensure cases classified “” class previous step sequence eventually assigned predicted class. example, say based certain class-specific metrics determined order classes sequential algorithm predict HGSC vs. non-HGSC, CCOC vs. non-CCOC, LGSC vs. non-LGSC, MUC vs. ENOC. Figure 2.5 illustrates final predictions assigned:\nFigure 2.5: Aggregating Predictions Sequential Algorithm\n","code":""},{"path":"methods.html","id":"gene-optimization","chapter":"2 Methods","heading":"2.5 Gene Optimization","text":"want discover optimal set genes classifiers including specific genes studies PrOTYPE SPOT. total 72 genes used classifier training set.16 genes classifier set overlap PrOTYPE classifier: COL11A1, CD74, CD2, TIMP3, LUM, CYTIP, COL3A1, THBS2, TCF7L1, HMGA2, FN1, POSTN, COL1A2, COL5A2, PDZK1IP1, FBN1.also 13 genes classifier set overlap SPOT signature: HIF1A, CXCL10, DUSP4, SOX17, MITF, CDKN3, BRCA2, CEACAM5, ANXA4, SERPINE1, TCF7L1, CRABP2, DNAJC9.obtain total 28 genes union PrOTYPE SPOT genes want include final classifier, regardless model performance. incrementally add genes one time remaining 44 candidate genes based overall variable importance rank set 28 base genes recalculate performance metrics. number genes performance peaks starts plateau may indicate optimal gene set model us compare full set model.","code":""},{"path":"methods.html","id":"variable-importance","chapter":"2 Methods","heading":"2.5.1 Variable Importance","text":"Variable importance calculated using either model-based approach available, permutation-based VI score otherwise. variable importance scores averaged across outer training folds, ranked highest lowest.sequential two-step classifiers, calculate overall VI rank taking cumulative union genes variable importance rank across sequences, genes included.variable importance measures :Random Forest: impurity measure (Gini index)Random Forest: impurity measure (Gini index)XGBoost: gain (fractional contribution feature model based total gain corresponding features’s splits)XGBoost: gain (fractional contribution feature model based total gain corresponding features’s splits)SVM: permutation based p-valuesSVM: permutation based p-valuesMultinomial regression: absolute value estimated coefficients cross-validated lambda valueMultinomial regression: absolute value estimated coefficients cross-validated lambda value","code":""},{"path":"methods.html","id":"performance-evaluation","chapter":"2 Methods","heading":"2.6 Performance Evaluation","text":"","code":""},{"path":"methods.html","id":"class-metrics","chapter":"2 Methods","heading":"2.6.1 Class Metrics","text":"use accuracy, sensitivity, specificity, F1-score, kappa, balanced accuracy, geometric mean, class metrics measure training test performance different workflows. Multiclass extensions metrics can calculated except F1-score, use macro-averaging obtain overall metric. Class-specific metrics calculated recoding classes one-vs-categories class.","code":""},{"path":"methods.html","id":"accuracy","chapter":"2 Methods","heading":"2.6.1.1 Accuracy","text":"accuracy defined proportion correct predictions cases:\\[\n\\text{accuracy} = \\frac{TP}{TP + FP + FN + TN}\n\\tag{2.2}\n\\]","code":""},{"path":"methods.html","id":"sensitivity","chapter":"2 Methods","heading":"2.6.1.2 Sensitivity","text":"Sensitivity proportional correctly predicted positive cases, cases truly positive\\[\n\\text{sensitivity} = \\frac{TP}{TP + FN}\n\\tag{2.3}\n\\]","code":""},{"path":"methods.html","id":"specificity","chapter":"2 Methods","heading":"2.6.1.3 Specificity","text":"Specificity proportional correctly predicted negative cases, cases truly negative.\\[\n\\text{specificity} = \\frac{TN}{TN + FP}\n\\tag{2.4}\n\\]","code":""},{"path":"methods.html","id":"f1-score","chapter":"2 Methods","heading":"2.6.1.4 F1-Score","text":"F-measure can thought harmonic mean precision recall:\\[\nF_{meas} = \\frac{(1 + \\beta^2) \\times precision \\times recall}{(\\beta^2 \\times precision) + recall}\n\\tag{2.5}\n\\]\\(\\beta\\) value can adjusted place weight upon precision recall. common value \\(\\beta\\) 1, also commonly known F1-score. multiclass extension doesn’t exist F1-score, use macro-averaging calculate metric two classes. example, \\(k\\) classes, macro-averaged F1-score equal :\\[\n{F_1}_{macro} = \\frac{1}{k} \\sum_{=1}^{k}{F_1}_{}\n\\tag{2.6}\n\\] \\({F_1}_{}\\) F1-score computed frrom recoding classes \\(k=\\) vs. \\(k \\neq \\).situations least one predicted case classes (e.g. poor classifier), \\({F_1}_{}\\) undefined per-class precision class \\(\\) undefined. \\({F_1}_{}\\) terms removed \\({F_1}_{macro}\\) equation resulting value may inflated. Interpreting F1-score case misleading.","code":""},{"path":"methods.html","id":"kappa","chapter":"2 Methods","heading":"2.6.1.5 Kappa","text":"Kappa defined :\\[\n\\text{kappa} = \\frac{p_0 - p_e}{1 - p_e}\n\\tag{2.7}\n\\]\\(p_0\\) observed agreement among raters \\(p_e\\) hypothetical probability agreement due random chance.","code":""},{"path":"methods.html","id":"balanced-accuracy","chapter":"2 Methods","heading":"2.6.1.6 Balanced Accuracy","text":"Balanced accuracy arithmetic mean sensitivity specificity.\\[\n\\text{Balanced Accuracy} = \\frac{\\text{Sensitivity} + \\text{Specificity}}{2}\n\\tag{2.8}\n\\]","code":""},{"path":"methods.html","id":"geometric-mean","chapter":"2 Methods","heading":"2.6.1.7 Geometric Mean","text":"geometric mean (G-mean) \\(k^{th}\\) root product class-specific sensitivities \\(k\\) classes:\\[\n\\text{G-mean} = \\sqrt[k]{\\prod_{=1}^{k}{\\text{Sensitivity}_k}}\n\\tag{2.9}\n\\] G-mean generalizes easily multiclass scenario.","code":""},{"path":"methods.html","id":"auc","chapter":"2 Methods","heading":"2.6.2 AUC","text":"area receiver operating curve (AUC) calculated adding area curve formed plotting sensitivity vs. 1 - specificity. Hand-till method used multiclass extension AUC.use AUC measure class-specific training set performance combining predicted probabilities one-vs-fashion might potentially misleading. sum probabilities add “” class equivalent predicted probability “” class using multiclass classifier.Instead, reported ROC curves associated AUCs test set performance sequential two-step algorithms.","code":""},{"path":"distributions.html","id":"distributions","chapter":"3 Distributions","heading":"3 Distributions","text":"","code":""},{"path":"distributions.html","id":"histotypes-in-classifier-data","chapter":"3 Distributions","heading":"3.1 Histotypes in Classifier Data","text":"\nTable 3.1: Pre-QC Training Set Histotype Distribution CodeSet\n\nTable 3.2: Training Set (duplicates) Histotype Distribution CodeSet\n\nTable 3.3: Final Training Set Histotype Distribution CodeSet\n\nTable 3.4: Histotype Distribution Confirmation Validation Sets\n","code":""},{"path":"distributions.html","id":"cohort-counts","chapter":"3 Distributions","heading":"3.2 Cohort Counts","text":"\nTable 3.5: Training Set counts CodeSet Processing Stage\n","code":""},{"path":"distributions.html","id":"cohorts-in-classifier-data","chapter":"3 Distributions","heading":"3.3 Cohorts in Classifier Data","text":"\nTable 3.6: Cohort Distribution Training, Confirmation, Validation Sets\n","code":""},{"path":"distributions.html","id":"quality-control-1","chapter":"3 Distributions","heading":"3.4 Quality Control","text":"","code":""},{"path":"distributions.html","id":"failed-samples","chapter":"3 Distributions","heading":"3.4.1 Failed Samples","text":"use aggregated QCFlag considers sample failed QC following conditions true:linFlag: linearity positive controls positive control concentrations less 0.95, linearity measures unknownimagingFlag: percent field view less 75%spcFlag: smallest positive control less lower limit detection (negative control average expression less two times negative control standard deviation), negative control average expression equals zeronormFlag: signal noise ratio less 100, percent genes detected less 50. Note: thresholds determined examining %GD vs. SNR relationship .\nTable 3.7: Number failed samples CodeSet fail condition\n","code":""},{"path":"distributions.html","id":"gd-vs.-snr","chapter":"3 Distributions","heading":"3.4.2 %GD vs. SNR","text":"\nFigure 3.1: % Genes Detected vs. Signal Noise Ratio\n\nFigure 3.2: % Genes Detected vs. Signal Noise Ratio (Zoomed)\n","code":""},{"path":"distributions.html","id":"pairwise-gene-expression","chapter":"3 Distributions","heading":"3.5 Pairwise Gene Expression","text":"\nFigure 3.3: Random1-Normalized CS1 vs. CS3 Gene Expression\n\nFigure 3.4: Random1-Normalized CS2 vs. CS3 Gene Expression\n\nFigure 3.5: HKgenes-Normalized CS1 vs. CS3 Gene Expression\n\nFigure 3.6: HKgenes-Normalized CS2 vs. CS3 Gene Expression\n","code":""},{"path":"results.html","id":"results","chapter":"4 Results","heading":"4 Results","text":"summarize cross-validated training performance class metrics training set. accuracy, F1-score, kappa, G-mean metrics interest. Workflows ordered mean estimates across outer folds nested CV metric.","code":""},{"path":"results.html","id":"training-set","chapter":"4 Results","heading":"4.1 Training Set","text":"","code":""},{"path":"results.html","id":"accuracy-1","chapter":"4 Results","heading":"4.1.1 Accuracy","text":"\nFigure 4.1: Training Set Mean Accuracy\n\nTable 4.1: Training Set Mean Accuracy\n\nFigure 4.2: Training Set Class-Specific Mean Accuracy\n\nTable 4.2: Training Set Class-Specific Mean Accuracy\n","code":""},{"path":"results.html","id":"sensitivity-1","chapter":"4 Results","heading":"4.1.2 Sensitivity","text":"\nFigure 4.3: Training Set Mean Sensitivity\n\nTable 4.3: Training Set Mean Sensitivity\n\nFigure 4.4: Training Set Class-Specific Mean Sensitivity\n\nTable 4.4: Cross-Validated Training Set Class-Specific Mean Sensitivity\n","code":""},{"path":"results.html","id":"specificity-1","chapter":"4 Results","heading":"4.1.3 Specificity","text":"\nFigure 4.5: Training Set Mean Specificity\n\nTable 4.5: Training Set Mean Specificity\n\nFigure 4.6: Training Set Class-Specific Mean Specificity\n\nTable 4.6: Cross-Validated Training Set Class-Specific Mean Specificity\n","code":""},{"path":"results.html","id":"f1-score-1","chapter":"4 Results","heading":"4.1.4 F1-Score","text":"\nFigure 4.7: Training Set Mean F1-Score\n\nTable 4.7: Training Set Mean F1-Score\n\nFigure 4.8: Training Set Class-Specific Mean F1-Score\n\nTable 4.8: Cross-Validated Training Set Class-Specific Mean F1-Score\n","code":""},{"path":"results.html","id":"balanced-accuracy-1","chapter":"4 Results","heading":"4.1.5 Balanced Accuracy","text":"\nFigure 4.9: Training Set Mean Balanced Accuracy\n\nTable 4.9: Training Set Mean Balanced Accuracy\n\nFigure 4.10: Training Set Class-Specific Mean Balanced Accuracy\n\nTable 4.10: Training Set Class-Specific Mean Balanced Accuracy\n","code":""},{"path":"results.html","id":"kappa-1","chapter":"4 Results","heading":"4.1.6 Kappa","text":"\nFigure 4.11: Training Set Mean Kappa\n\nTable 4.11: Training Set Mean Kappa\n\nFigure 4.12: Training Set Class-Specific Mean Kappa\n\nTable 4.12: Training Set Class-Specific Mean Kappa\n","code":""},{"path":"results.html","id":"g-mean","chapter":"4 Results","heading":"4.1.7 G-mean","text":"\nFigure 4.13: Training Set Mean G-mean\n\nTable 4.13: Training Set Mean G-mean\n\nFigure 4.14: Training Set Class-Specific Mean G-mean\n\nTable 4.14: Training Set Class-Specific Mean G-mean\n","code":""},{"path":"results.html","id":"rank-aggregation","chapter":"4 Results","heading":"4.2 Rank Aggregation","text":"18 workflows ordered table aggregated ranks using Genetic Algorithm. see best performing methods involve sequential two-step algorithms.","code":""},{"path":"results.html","id":"top-workflows","chapter":"4 Results","heading":"4.2.1 Top Workflows","text":"look per-class evaluation metrics top 4 workflows.\nFigure 4.15: Top 4 Workflow Per-Class Evaluation Metrics\n\nFigure 4.16: Top 4 Workflow Per-Class F1-Scores\nMisclassified cases previous step sequence classifiers included subsequent steps training set CV folds. Thus, piece together test set predictions sequential two-step algorithms obtain overall metrics.","code":""},{"path":"results.html","id":"optimal-gene-sets","chapter":"4 Results","heading":"4.3 Optimal Gene Sets","text":"","code":""},{"path":"results.html","id":"sequential-algorithm-1","chapter":"4 Results","heading":"4.3.1 Sequential Algorithm","text":"\nFigure 4.17: Gene Optimization Sequential Classifier\nsequential algorithm, sequences 1, 2, 4 relatively flat average F1-scores across number genes added. However, can observe sequence 3, F1-score stabilizes around 0.9 reach 13 genes added, hence optimal number genes used n=28+13=41 added genes : CYP2C18, TFF3, KLK7, HNF1B, IL6, IGFBP1, SLC3A1, SERPINA5, WT1, CPNE8, EGFL6, GPR64 MUC5B.","code":""},{"path":"results.html","id":"two-step-algorithm-1","chapter":"4 Results","heading":"4.3.2 Two-Step Algorithm","text":"\nFigure 4.18: Gene Optimization Two-Step Classifier\nSince second step classifier fits multinomial model, use macro F1-score measure analyze gene entry. two-step classifier, see Step 2, F1-score stabilizes around 0.85 reach 12 added. optimal number genes used n=28+12=40. added genes : CYP2C18, MUC5B, HNF1B, SLC3A1, IGFBP1, WT1, EGFL6, TFF3, MET, KLK7, CPNE8 STC1.","code":""},{"path":"results.html","id":"test-set-performance","chapter":"4 Results","heading":"4.4 Test Set Performance","text":"Now ’d like see best methods perform confirmation validation sets. class-specific F1-scores used.top 2 methods :sequential: sequential algorithm hybrid subsampling every step. sequence algorithms used :\nHGSC vs. non-HGSC using random forest\nCCOC vs. non-CCOC using XGBoost\nENOC vs. non-ENOC using support vector machine\nLGSC vs. MUC using support vector machine\nHGSC vs. non-HGSC using random forestCCOC vs. non-CCOC using XGBoostENOC vs. non-ENOC using support vector machineLGSC vs. MUC using support vector machinetwo_step: two-step algorithm hybrid subsampling steps. sequence algorithms used :\nHGSC vs. non-HGSC using random forest\nCCOC vs. ENOC vs. MUC vs. LGSC support vector machine\nHGSC vs. non-HGSC using random forestCCOC vs. ENOC vs. MUC vs. LGSC support vector machineWe can test 2 additional methods using either full set genes optimal set genes methods.","code":""},{"path":"results.html","id":"confirmation-set","chapter":"4 Results","heading":"4.4.1 Confirmation Set","text":"\nTable 4.15: Overall Evaluation Metrics Confirmation Set Models\n\nFigure 4.19: Confusion Matrices Confirmation Set Models\n\nTable 4.16: Per-Class Evaluation Metrics Confirmation Set Model\n\nFigure 4.20: ROC Curves Sequential Full Model Confirmation Set\n\nFigure 4.21: ROC Curves Sequential Optimal Model Confirmation Set\n\nFigure 4.22: ROC Curves Two-Step Full Model Confirmation Set\n\nFigure 4.23: ROC Curves Two-Step Optimal Model Confirmation Set\n","code":""},{"path":"results.html","id":"validation-set","chapter":"4 Results","heading":"4.4.2 Validation Set","text":"\nTable 4.17: Overall Evaluation Metrics Validation Set Model\n\nFigure 4.24: Confusion Matrix Validation Set Model\n\nTable 4.18: Per-Class Eevaluation Metrics Validation Set Model\n","code":""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
